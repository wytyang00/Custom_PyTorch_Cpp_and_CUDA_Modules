{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peephole LSTM Test & Performance Comparison (Speed & Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imports](#Importing-necessary-modules)\n",
    "* [Load & Definition](#Loading-and-defining-modules)\n",
    "    * [Autograd Functions](#Autograd-Functions)\n",
    "    * [Module Classes](#Module-classes-(C++,-CUDA,-PyTorch))\n",
    "* [Models](#Defining-models)\n",
    "    * [Definition](#Definition)\n",
    "    * [Instantiation](#Instantiation)\n",
    "    * [Parameter Synchronization](#Parameter-Synchronization)\n",
    "* [Fake Dataset](#Creating-a-fake-dataset)\n",
    "* [Sanity Check](#Sanity-check:-output-comparison)\n",
    "    * [Forward Outputs](#Forward-Outputs)\n",
    "    * [Backward Gradients](#Backward-Gradients)\n",
    "* [Forward Performance](#Forward-time-comparison)\n",
    "* [+Backward Performance](#+Backward-time-comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing necessary modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T22:48:19.919550Z",
     "start_time": "2019-02-06T22:48:18.554589Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#imports"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "if 'initialized' not in globals():\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from torch.utils.cpp_extension import load\n",
    "    from torch.nn import functional as F\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "    import math\n",
    "    from collections import OrderedDict\n",
    "    from time import sleep\n",
    "\n",
    "    initialized = [False] * 7\n",
    "    print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and defining modules\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd Functions\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T22:48:28.658794Z",
     "start_time": "2019-02-06T22:48:19.922554Z"
    },
    "code_folding": [
     10,
     49,
     88
    ],
    "scrolled": true,
    "tags": [
     "=>imports",
     "#C-autograd-define"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py:184: UserWarning: Error checking compiler version for c++: Command 'c++' returned non-zero exit status 1.\n",
      "  warnings.warn('Error checking compiler version for {}: {}'.format(compiler, error))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error building extension 'ln_peephole_lstm_layer_cuda_less_mem': [1/3] C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\nvcc -DTORCH_EXTENSION_NAME=ln_peephole_lstm_layer_cuda_less_mem -DTORCH_API_INCLUDE_EXTENSION_H -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\torch\\csrc\\api\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\TH -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\" -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\Include -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -c C:\\Users\\0107w\\Anaconda3\\envs\\pytorch\\vs_project\\Pytorch_Project\\Pytorch_Project\\ln_peephole_lstm_layer_cuda_kernel_less_mem.cu -o ln_peephole_lstm_layer_cuda_kernel_less_mem.cuda.o\r\nFAILED: ln_peephole_lstm_layer_cuda_kernel_less_mem.cuda.o \r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\nvcc -DTORCH_EXTENSION_NAME=ln_peephole_lstm_layer_cuda_less_mem -DTORCH_API_INCLUDE_EXTENSION_H -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\torch\\csrc\\api\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\TH -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\" -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\Include -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -c C:\\Users\\0107w\\Anaconda3\\envs\\pytorch\\vs_project\\Pytorch_Project\\Pytorch_Project\\ln_peephole_lstm_layer_cuda_kernel_less_mem.cu -o ln_peephole_lstm_layer_cuda_kernel_less_mem.cuda.o\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(27): warning: base class dllexport/dllimport specification differs from that of the derived class\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(28): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(29): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(34): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(35): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/Allocator.h(126): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/TensorTypeIdRegistration.h(32): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/TensorTypeIdRegistration.h(45): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/TensorTypeIdRegistration.h(46): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(449): warning: dllexport/dllimport conflict with \"caffe2::TypeMeta::_typeMetaDataInstance [with T=caffe2::detail::_Uninitialized]\"\r\n(445): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(560): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=uint8_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(561): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int8_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(562): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int16_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(563): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(564): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int64_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(565): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=c10::Half]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(566): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=float]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(567): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=double]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(568): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=c10::ComplexHalf]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(569): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::complex<float>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(570): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::complex<double>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(573): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::string]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(574): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=__nv_bool]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(575): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=uint16_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(576): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=char]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(577): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::unique_ptr<std::mutex, std::default_delete<std::mutex>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(578): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::unique_ptr<std::atomic<__nv_bool>, std::default_delete<std::atomic<__nv_bool>>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(579): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::vector<int32_t, std::allocator<int32_t>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(580): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::vector<int64_t, std::allocator<int64_t>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(581): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::vector<unsigned long, std::allocator<unsigned long>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(582): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=__nv_bool *]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(583): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=char *]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(584): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int *]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(604): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=caffe2::detail::_guard_long_unique<long>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(605): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=caffe2::detail::_guard_long_unique<std::vector<long, std::allocator<long>>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(609): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=caffe2::_CaffeHighestPreallocatedTypeId]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/intrusive_ptr.h(58): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/intrusive_ptr.h(59): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/StorageImpl.h(215): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/Storage.h(184): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/logging_is_not_google_glog.h(47): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/TensorImpl.h(115): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/TensorImpl.h(1434): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/TensorImpl.h(1435): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/Tensor.h(692): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/Tensor.h(720): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(145): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(146): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(147): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(151): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(152): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(153): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/TensorGeometry.h(56): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/TensorGeometry.h(57): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(937): error: identifier \"gates_fig\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(939): error: identifier \"tanh_new_cells\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: identifier \"gates_o\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: identifier \"gates_o\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(448): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(461): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(475): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(487): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(505): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(448): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(461): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(475): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(487): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(505): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\n30 errors detected in the compilation of \"C:/Users/0107w/AppData/Local/Temp/tmpxft_00001ec8_00000000-10_ln_peephole_lstm_layer_cuda_kernel_less_mem.cpp1.ii\".\r\nln_peephole_lstm_layer_cuda_kernel_less_mem.cu\r\n[2/3] cl /showIncludes -DTORCH_EXTENSION_NAME=ln_peephole_lstm_layer_cuda_less_mem -DTORCH_API_INCLUDE_EXTENSION_H -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\torch\\csrc\\api\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\TH -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\" -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\Include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c C:\\Users\\0107w\\Anaconda3\\envs\\pytorch\\vs_project\\Pytorch_Project\\Pytorch_Project\\ln_peephole_lstm_layer_cuda_less_mem.cpp /Foln_peephole_lstm_layer_cuda_less_mem.o\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.11.25548.2 for x64\nCopyright (C) Microsoft Corporation.  All rights reserved.\n\ncl : Command line warning D9002 : ignoring unknown option '-fPIC'\ncl : Command line warning D9002 : ignoring unknown option '-std=c++11'\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.11.25503\\include\\xlocale(314): warning C4530: C++ exception handler used, but unwind semantics are not enabled. Specify /EHsc\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(433): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(434): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(435): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(436): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(438): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(75): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(76): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(77): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(78): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(79): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(86): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(80): warning C4297: 'c10::intrusive_ptr_target::~intrusive_ptr_target': function assumed not to throw an exception but does\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(80): note: destructor or deallocator has a (possibly implicit) non-throwing exception specification\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(83): warning C4297: 'c10::intrusive_ptr_target::~intrusive_ptr_target': function assumed not to throw an exception but does\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(83): note: destructor or deallocator has a (possibly implicit) non-throwing exception specification\nIncluding torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.11.25503\\include\\iosfwd(292): warning C4577: 'noexcept' used with no exception handling mode specified; termination on exception is not guaranteed. Specify /EHsc\nninja: build stopped: subcommand failed.\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_build_extension_module\u001b[1;34m(name, build_directory, verbose)\u001b[0m\n\u001b[0;32m    945\u001b[0m                 \u001b[0mcwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m                 check=True)\n\u001b[0m\u001b[0;32m    947\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[1;32m--> 418\u001b[1;33m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[0;32m    419\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['ninja', '-v']' returned non-zero exit status 1.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7954ff436fcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                         ['./ln_peephole_lstm_layer_cuda.cpp', './ln_peephole_lstm_layer_cuda_kernel.cu'])\n\u001b[0;32m      6\u001b[0m     _ln_peephole_lstm_layer_cuda_less_mem = load('ln_peephole_lstm_layer_cuda_less_mem',\n\u001b[1;32m----> 7\u001b[1;33m                                                  ['./ln_peephole_lstm_layer_cuda_less_mem.cpp', './ln_peephole_lstm_layer_cuda_kernel_less_mem.cu'])\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m########################################################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module)\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[0mwith_cuda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         is_python_module)\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module)\u001b[0m\n\u001b[0;32m    812\u001b[0m                     \u001b[0mbuild_directory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m                     with_cuda=with_cuda)\n\u001b[0m\u001b[0;32m    815\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                 \u001b[0mbaton\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_write_ninja_file_and_build\u001b[1;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda)\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Building extension module {}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m     \u001b[0m_build_extension_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\utils\\cpp_extension.py\u001b[0m in \u001b[0;36m_build_extension_module\u001b[1;34m(name, build_directory, verbose)\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\": {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 959\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error building extension 'ln_peephole_lstm_layer_cuda_less_mem': [1/3] C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\nvcc -DTORCH_EXTENSION_NAME=ln_peephole_lstm_layer_cuda_less_mem -DTORCH_API_INCLUDE_EXTENSION_H -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\torch\\csrc\\api\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\TH -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\" -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\Include -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -c C:\\Users\\0107w\\Anaconda3\\envs\\pytorch\\vs_project\\Pytorch_Project\\Pytorch_Project\\ln_peephole_lstm_layer_cuda_kernel_less_mem.cu -o ln_peephole_lstm_layer_cuda_kernel_less_mem.cuda.o\r\nFAILED: ln_peephole_lstm_layer_cuda_kernel_less_mem.cuda.o \r\nC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\nvcc -DTORCH_EXTENSION_NAME=ln_peephole_lstm_layer_cuda_less_mem -DTORCH_API_INCLUDE_EXTENSION_H -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\torch\\csrc\\api\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\TH -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\" -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\Include -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -c C:\\Users\\0107w\\Anaconda3\\envs\\pytorch\\vs_project\\Pytorch_Project\\Pytorch_Project\\ln_peephole_lstm_layer_cuda_kernel_less_mem.cu -o ln_peephole_lstm_layer_cuda_kernel_less_mem.cuda.o\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(27): warning: base class dllexport/dllimport specification differs from that of the derived class\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(28): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(29): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(34): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/Exception.h(35): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/Allocator.h(126): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/TensorTypeIdRegistration.h(32): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/TensorTypeIdRegistration.h(45): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/TensorTypeIdRegistration.h(46): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(449): warning: dllexport/dllimport conflict with \"caffe2::TypeMeta::_typeMetaDataInstance [with T=caffe2::detail::_Uninitialized]\"\r\n(445): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(560): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=uint8_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(561): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int8_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(562): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int16_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(563): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(564): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int64_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(565): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=c10::Half]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(566): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=float]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(567): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=double]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(568): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=c10::ComplexHalf]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(569): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::complex<float>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(570): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::complex<double>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(573): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::string]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(574): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=__nv_bool]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(575): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=uint16_t]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(576): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=char]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(577): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::unique_ptr<std::mutex, std::default_delete<std::mutex>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(578): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::unique_ptr<std::atomic<__nv_bool>, std::default_delete<std::atomic<__nv_bool>>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(579): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::vector<int32_t, std::allocator<int32_t>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(580): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::vector<int64_t, std::allocator<int64_t>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(581): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=std::vector<unsigned long, std::allocator<unsigned long>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(582): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=__nv_bool *]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(583): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=char *]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(584): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=int *]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(604): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=caffe2::detail::_guard_long_unique<long>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(605): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=caffe2::detail::_guard_long_unique<std::vector<long, std::allocator<long>>>]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/typeid.h(609): warning: dllexport/dllimport conflict with \"caffe2::TypeIdentifier::Get [with T=caffe2::_CaffeHighestPreallocatedTypeId]\"\r\n(83): here; dllexport assumed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/intrusive_ptr.h(58): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/intrusive_ptr.h(59): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/StorageImpl.h(215): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/core/Storage.h(184): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\c10/util/logging_is_not_google_glog.h(47): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/TensorImpl.h(115): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/TensorImpl.h(1434): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/TensorImpl.h(1435): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/Tensor.h(692): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/core/Tensor.h(720): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(145): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(146): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(147): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(151): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(152): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/Context.h(153): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/TensorGeometry.h(56): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch1.0/lib/site-packages/torch/lib/include\\ATen/TensorGeometry.h(57): warning: field of class type without a DLL interface used in a class with a DLL interface\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(937): error: identifier \"gates_fig\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(939): error: identifier \"tanh_new_cells\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: identifier \"gates_o\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: identifier \"gates_o\" is undefined\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: type name is not allowed\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(963): error: expected an expression\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(448): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(461): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(475): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(487): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(505): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=double]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(448): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(461): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(475): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(487): error: identifier \"d_sigmoid_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\nC:/Users/0107w/Anaconda3/envs/pytorch/vs_project/Pytorch_Project/Pytorch_Project/ln_peephole_lstm_layer_cuda_kernel_less_mem.cu(505): error: identifier \"d_tanh_with_output\" is undefined\r\n          detected during instantiation of \"void backward_preparation(scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, const scalar_t *, scalar_t *, scalar_t *, scalar_t *, scalar_t *, const scalar_t *, scalar_t *, int64_t, int64_t, int64_t, int64_t, int64_t) [with scalar_t=float]\" \r\n(963): here\r\n\r\n30 errors detected in the compilation of \"C:/Users/0107w/AppData/Local/Temp/tmpxft_00001ec8_00000000-10_ln_peephole_lstm_layer_cuda_kernel_less_mem.cpp1.ii\".\r\nln_peephole_lstm_layer_cuda_kernel_less_mem.cu\r\n[2/3] cl /showIncludes -DTORCH_EXTENSION_NAME=ln_peephole_lstm_layer_cuda_less_mem -DTORCH_API_INCLUDE_EXTENSION_H -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\torch\\csrc\\api\\include -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\TH -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\" -IC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\Include -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++11 -c C:\\Users\\0107w\\Anaconda3\\envs\\pytorch\\vs_project\\Pytorch_Project\\Pytorch_Project\\ln_peephole_lstm_layer_cuda_less_mem.cpp /Foln_peephole_lstm_layer_cuda_less_mem.o\r\nMicrosoft (R) C/C++ Optimizing Compiler Version 19.11.25548.2 for x64\nCopyright (C) Microsoft Corporation.  All rights reserved.\n\ncl : Command line warning D9002 : ignoring unknown option '-fPIC'\ncl : Command line warning D9002 : ignoring unknown option '-std=c++11'\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.11.25503\\include\\xlocale(314): warning C4530: C++ exception handler used, but unwind semantics are not enabled. Specify /EHsc\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(433): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(434): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(435): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(436): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/typeid.h(438): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(75): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(76): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(77): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(78): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(79): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(86): warning C4068: unknown pragma\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(80): warning C4297: 'c10::intrusive_ptr_target::~intrusive_ptr_target': function assumed not to throw an exception but does\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(80): note: destructor or deallocator has a (possibly implicit) non-throwing exception specification\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(83): warning C4297: 'c10::intrusive_ptr_target::~intrusive_ptr_target': function assumed not to throw an exception but does\nC:\\Users\\0107w\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\lib\\include\\c10/util/intrusive_ptr.h(83): note: destructor or deallocator has a (possibly implicit) non-throwing exception specification\nIncluding torch/torch.h for C++ extensions is deprecated. Please include torch/extension.h\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.11.25503\\include\\iosfwd(292): warning C4577: 'noexcept' used with no exception handling mode specified; termination on exception is not guaranteed. Specify /EHsc\nninja: build stopped: subcommand failed.\r\n"
     ]
    }
   ],
   "source": [
    "if not initialized[0]:\n",
    "    _ln_peephole_lstm_layer_cpp = load('ln_peephole_lstm_layer',\n",
    "                                       ['./ln_peephole_lstm_layer.cpp'])\n",
    "    _ln_peephole_lstm_layer_cuda = load('ln_peephole_lstm_layer_cuda',\n",
    "                                        ['./ln_peephole_lstm_layer_cuda.cpp', './ln_peephole_lstm_layer_cuda_kernel.cu'])\n",
    "    _ln_peephole_lstm_layer_cuda_less_mem = load('ln_peephole_lstm_layer_cuda_less_mem',\n",
    "                                                 ['./ln_peephole_lstm_layer_cuda_less_mem.cpp', './ln_peephole_lstm_layer_cuda_kernel_less_mem.cu'])\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMFunctionCPP(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cpp.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDA(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMFunctionCUDALM(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                    gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                    hidden, cell,\n",
    "                    epsilon, dropout_p,\n",
    "                    dropout_output, training):\n",
    "\n",
    "            outputs = _ln_peephole_lstm_layer_cuda_less_mem.forward(input, weight_ih, weight_hh, weight_ch, bias,\n",
    "                                                          gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell, beta_cell,\n",
    "                                                          hidden, cell,\n",
    "                                                          epsilon, dropout_p,\n",
    "                                                          dropout_output, training)\n",
    "\n",
    "            out, new_h, new_cell = outputs[:3]\n",
    "\n",
    "            variables = outputs[3:] + [weight_ih, weight_hh, weight_ch, bias,\n",
    "                                       gamma_f, gamma_i, gamma_g, gamma_o, gamma_cell]\n",
    "            ctx.save_for_backward(*variables)\n",
    "\n",
    "            return out, new_h, new_cell\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output, grad_h, grad_cell):\n",
    "            outputs = _ln_peephole_lstm_layer_cuda_less_mem.backward(\n",
    "                grad_output.contiguous(), grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "\n",
    "            (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "             d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "             d_hidden, d_cell) = outputs\n",
    "\n",
    "            return (d_input, d_weight_ih, d_weight_hh, d_weight_ch, d_bias,\n",
    "                    d_gamma_f, d_gamma_i, d_gamma_o, d_gamma_g, d_gamma_cell, d_beta_cell,\n",
    "                    d_hidden, d_cell,\n",
    "                    None, None,\n",
    "                    None, None)\n",
    "        \n",
    "    initialized[0] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Module classes (PyTorch, C++, CUDA)\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:33.960582Z",
     "start_time": "2019-02-06T21:13:33.913589Z"
    },
    "code_folding": [
     1,
     111,
     112,
     139,
     155,
     170,
     203,
     219,
     234
    ],
    "hidden": true,
    "tags": [
     "#base-modules-define",
     "=>C-autograd-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[1]:\n",
    "    class LNPeepholeLSTMTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "            super(LNPeepholeLSTMTorch, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, states):\n",
    "            assert input.dim() == 3, \"expected a 3 dimensional tensor as `input`, but te given tensor has {} dimension(s)\".format(input.dim())\n",
    "            assert len(states) == 2, \"expected a (hidden, cell) pair as `states`, but the length of the given states is {}\".format(len(states))\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "            assert states[0].size() == (input.size(1), self.hidden_size), \"expected a hidden state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[0].size()), [input.size(1), self.hidden_size])\n",
    "            assert states[1].size() == (input.size(1), self.hidden_size), \"expected a cell state tensor with dimensionality {}, but the given tensor has dimensionality []\".format(list(states[1].size()), [input.size(1), self.hidden_size])\n",
    "\n",
    "            hidden, cell = states\n",
    "\n",
    "            hidden_size = self.hidden_size\n",
    "            hidden_size_2 = 2 * hidden_size\n",
    "            hidden_size_3 = hidden_size_2 + hidden_size\n",
    "\n",
    "            norm_shape = torch.Size((hidden_size,))\n",
    "\n",
    "            outputs = input.new_empty((input.size(0), input.size(1), hidden_size))\n",
    "            \n",
    "            ih = input.matmul(self.weight_ih.t())\n",
    "\n",
    "            weight_hc_h = torch.cat((self.weight_hh.t(),\n",
    "                                     torch.cat((self.weight_ch[:hidden_size].diag(),\n",
    "                                                self.weight_ch[hidden_size:hidden_size_2].diag(),\n",
    "                                                self.weight_ch.new_zeros(hidden_size_2, hidden_size))).t()))\n",
    "            weight_co = self.weight_ch[hidden_size_2:]\n",
    "            \n",
    "            gamma_fig = torch.stack((self.gamma_f, self.gamma_i, self.gamma_g))\n",
    "\n",
    "            bias_fig = torch.stack(self.bias[:hidden_size_3].chunk(3, dim=0))\n",
    "            bias_o = self.bias[hidden_size_3:]\n",
    "\n",
    "            for i in range(input.size(0)):\n",
    "                gates = torch.addmm(ih[i], torch.cat((hidden, cell), dim=1), weight_hc_h).view(-1, 4, hidden_size)\n",
    "                gates_fig = gates[:, :3]\n",
    "\n",
    "\n",
    "                gates_fig = F.layer_norm(gates_fig, norm_shape, eps=self.eps)\n",
    "                gates_fig = torch.addcmul(bias_fig, gates_fig, gamma_fig)\n",
    "                forget_input_gates = gates_fig[:, :2].sigmoid()\n",
    "                candidate_cell = F.dropout(gates_fig[:, 2].tanh(), p=self.dropout, training=self.training)\n",
    "\n",
    "\n",
    "                cell = F.layer_norm(torch.addcmul(forget_input_gates[:, 0] * cell,\n",
    "                                                  forget_input_gates[:, 1], candidate_cell),\n",
    "                                    norm_shape, self.gamma_cell, self.beta_cell, self.eps)\n",
    "\n",
    "                output_gate = torch.addcmul(gates[:, 3], cell, weight_co)\n",
    "\n",
    "                output_gate = F.layer_norm(output_gate, norm_shape, self.gamma_o, bias_o, self.eps).sigmoid()\n",
    "\n",
    "                hidden = output_gate * cell.tanh()\n",
    "\n",
    "                outputs[i] = hidden\n",
    "\n",
    "            if self.dropout_on_output:\n",
    "                outputs = F.dropout(outputs, p=self.dropout, training=self.training)\n",
    "                \n",
    "            if self.batch_first:\n",
    "                outputs = outputs.transpose(0, 1).contiguous()\n",
    "\n",
    "            return outputs, (hidden, cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMTorch(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeLSTMCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCPP, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCPP.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCPP(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeLSTMCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, batch_first=False, dropout=0., dropout_on_output=True, eps=1e-05):\n",
    "            if not 0 <= dropout <= 1:\n",
    "                raise ValueError(f\"Invalid dropout value : {dropout} dropout must be in range [0, 1].\")\n",
    "\n",
    "            super(LNPeepholeLSTMCUDA, self).__init__()\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.batch_first = bool(batch_first)\n",
    "            self.dropout = float(dropout)\n",
    "            self.dropout_on_output = bool(dropout_on_output)\n",
    "            self.eps = eps\n",
    "\n",
    "            self.register_parameter('weight_ih', nn.Parameter(torch.empty(4 * hidden_size, input_size)))\n",
    "            self.register_parameter('weight_hh', nn.Parameter(torch.empty(4 * hidden_size, hidden_size)))\n",
    "            self.register_parameter('weight_ch', nn.Parameter(torch.empty(3 * hidden_size)))\n",
    "            self.register_parameter('bias', nn.Parameter(torch.empty(4 * hidden_size)))\n",
    "\n",
    "            self.register_parameter('gamma_f', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_i', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_g', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_o', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('gamma_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "            self.register_parameter('beta_cell', nn.Parameter(torch.empty(hidden_size)))\n",
    "\n",
    "            self.reset_parameters()\n",
    "\n",
    "        def reset_parameters(self):\n",
    "            stdv = 1.0 / math.sqrt(self.input_size + 2 * self.hidden_size)\n",
    "            self.weight_ih.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_hh.data.uniform_(-stdv, +stdv)\n",
    "            self.weight_ch.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "            self.bias.data.zero_()\n",
    "            self.bias.data[:self.hidden_size].fill_(1.)\n",
    "\n",
    "            self.gamma_f.data.uniform_()\n",
    "            self.gamma_i.data.uniform_()\n",
    "            self.gamma_g.data.uniform_()\n",
    "            self.gamma_o.data.uniform_()\n",
    "            self.gamma_cell.data.uniform_()\n",
    "            self.beta_cell.data.zero_()\n",
    "\n",
    "        def forward(self, input, state):\n",
    "            if self.batch_first:\n",
    "                input = input.transpose(0, 1).contiguous()\n",
    "\n",
    "            output, new_h, new_cell = LNPeepholeLSTMFunctionCUDA.apply(\n",
    "                input, self.weight_ih, self.weight_hh, self.weight_ch, self.bias,\n",
    "                self.gamma_f, self.gamma_i, self.gamma_g, self.gamma_o, self.gamma_cell, self.beta_cell,\n",
    "                state[0], state[1],\n",
    "                self.eps, self.dropout, self.dropout_on_output, self.training)\n",
    "            \n",
    "            if self.batch_first:\n",
    "                output = output.transpose(0, 1).contiguous()\n",
    "\n",
    "            return output, (new_h, new_cell)\n",
    "\n",
    "        def __repr__(self):\n",
    "            return f\"LNPeepholeLSTMCUDA(input_size={self.input_size}, hidden_size={self.hidden_size}, batch_first={self.batch_first}, dropout={self.dropout}, dropout_on_output={self.dropout_on_output}, eps={self.eps})\"\n",
    "    \n",
    "    initialized[1] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining models\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Definition\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:33.985573Z",
     "start_time": "2019-02-06T21:13:33.962594Z"
    },
    "code_folding": [
     1,
     35,
     69
    ],
    "hidden": true,
    "tags": [
     "#models-define",
     "=>base-modules-define"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[2]:\n",
    "    class LNPeepholeTorch(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMTorch(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMTorch(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "\n",
    "    ########################################################################################################################\n",
    "\n",
    "    class LNPeepholeCPP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCPP(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCPP(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    ########################################################################################################################\n",
    "    \n",
    "    class LNPeepholeCUDA(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0, dropout_on_output=True, eps=1e-05):\n",
    "            super().__init__()\n",
    "            assert isinstance(n_layers, int)\n",
    "            assert n_layers > 0\n",
    "\n",
    "            self.lstm0 = LNPeepholeLSTMCUDA(input_size, hidden_size, True, dropout, dropout_on_output, eps)\n",
    "            for n in range(1, n_layers):\n",
    "                self.add_module(\"lstm{}\".format(n), LNPeepholeLSTMCUDA(hidden_size, hidden_size, True, dropout, dropout_on_output, eps))\n",
    "            self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size = hidden_size\n",
    "            self.output_size = output_size\n",
    "            self.n_layers = n_layers\n",
    "\n",
    "        def forward(self, x, states):\n",
    "            assert states[0].dim() == 3\n",
    "            assert states[0].size(0) == self.n_layers\n",
    "            assert states[0].size(1) == x.size(0)\n",
    "            assert states[0].size(2) == self.hidden_size\n",
    "            assert states[0].size() == states[1].size()\n",
    "\n",
    "            new_hidden = torch.empty_like(states[0])\n",
    "            new_cell = torch.empty_like(states[1])\n",
    "\n",
    "            for n in range(self.n_layers):\n",
    "                x, (new_hidden[n], new_cell[n]) = getattr(self, \"lstm{}\".format(n))(x, (states[0][n], states[1][n]))\n",
    "            x = self.fc(x)\n",
    "\n",
    "            return x, (new_hidden, new_cell)\n",
    "    \n",
    "    initialized[2] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:33.994572Z",
     "start_time": "2019-02-06T21:13:33.988575Z"
    },
    "code_folding": [],
    "tags": [
     "=>models-define",
     "#models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[3]:\n",
    "    device = ('cpu', 'cuda')[1]\n",
    "\n",
    "    input_size = 200 #TEST 5\n",
    "    hidden_size = 500 #TEST 8\n",
    "    output_size = 100 #TEST 6\n",
    "    n_layers = 4 #TEST 3\n",
    "    dropout = 0. #TEST 0\n",
    "    eps = 1e-05 #TEST 1e-05\n",
    "\n",
    "    model_torch = LNPeepholeTorch(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cpp = LNPeepholeCPP(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "    model_cuda = LNPeepholeCUDA(input_size, hidden_size, output_size, n_layers, dropout, eps)\n",
    "\n",
    "    model_torch.to(device)\n",
    "    model_cpp.to(device)\n",
    "    model_cuda.to(device)\n",
    "\n",
    "    models = (model_torch, model_cpp, model_cuda)\n",
    "    \n",
    "    initialized[3] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Parameter Synchronization\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:34.005582Z",
     "start_time": "2019-02-06T21:13:33.997613Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#param-sync",
     "=>models-init"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[4]:\n",
    "    named_parameter_dicts = [\n",
    "        dict(model_torch.named_parameters()),\n",
    "        dict(model_cpp.named_parameters()),\n",
    "        dict(model_cuda.named_parameters())\n",
    "    ]\n",
    "\n",
    "    print(\"Synchronized Parameters:\\n\")\n",
    "    for common_param_name in set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(common_param_name))\n",
    "        for i in range(1, len(named_parameter_dicts)):\n",
    "            if named_parameter_dicts[i][common_param_name].size() == named_parameter_dicts[0][common_param_name].size():\n",
    "                named_parameter_dicts[i][common_param_name].data = named_parameter_dicts[0][common_param_name].data\n",
    "            else:\n",
    "                raise RuntimeError(\"Size mismatch\\n0:{}\\n{i}:{}\".format(named_parameter_dicts[0][common_param_name].size(),\n",
    "                                                                        named_parameter_dicts[i][common_param_name].size()))\n",
    "    print()\n",
    "    print(\"Exclusive Parameters (Not Synchronized):\\n\")\n",
    "    for exclusive_param_name in set.union(*(set(npd.keys()) for npd in named_parameter_dicts)) - set.intersection(*(set(npd.keys()) for npd in named_parameter_dicts)):\n",
    "        print(\"\\t{}\".format(exclusive_param_name))\n",
    "        \n",
    "    initialized[4] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Creating a fake dataset\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:34.015573Z",
     "start_time": "2019-02-06T21:13:34.007572Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "tags": [
     "#fake-generator",
     "=>param-sync"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[5]:\n",
    "    def create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True):\n",
    "        fake_inputs = torch.randn(dataset_size, sequence_length, input_size)\n",
    "        fake_targets = torch.randint(high=output_size, size=(dataset_size, sequence_length), dtype=torch.int64)\n",
    "\n",
    "        fake_dataset = TensorDataset(fake_inputs, fake_targets)\n",
    "\n",
    "        fake_loader = DataLoader(fake_dataset, batch_size=batch_size, drop_last=drop_last)\n",
    "\n",
    "        return fake_loader\n",
    "    \n",
    "    initialized[5] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:34.025574Z",
     "start_time": "2019-02-06T21:13:34.017588Z"
    },
    "code_folding": [],
    "hidden": true,
    "tags": [
     "#generate-fake",
     "=>fake-generator"
    ]
   },
   "outputs": [],
   "source": [
    "if not initialized[6]:\n",
    "    dataset_size = 1000\n",
    "    sequence_length = 20 #TEST 20\n",
    "    batch_size = 8 #TEST 8\n",
    "\n",
    "    fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size)\n",
    "    print(next(iter(fake_loader))[0].size(), next(iter(fake_loader))[1].size())\n",
    "    \n",
    "    initialized[6] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check: output comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Forward Outputs\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:20.033324Z",
     "start_time": "2019-02-06T20:06:20.025350Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))\n",
    "\n",
    "inputs = next(iter(fake_loader))[0].to(device)\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "del model # Removing temporary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:21.031348Z",
     "start_time": "2019-02-06T20:06:20.676319Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_torch]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[ 2.1202e-01,  2.8098e-01, -1.6853e-01,  1.5387e-01,  1.8006e-01,\n",
      "          -1.8520e-01],\n",
      "         [ 3.6610e-01,  2.3259e-01, -9.6601e-02,  1.8165e-01,  1.6299e-01,\n",
      "          -2.6788e-01],\n",
      "         [ 4.3691e-01,  1.9658e-01, -6.7583e-02,  2.0776e-01,  1.5565e-01,\n",
      "          -2.6871e-01],\n",
      "         [ 4.6849e-01,  1.7438e-01, -4.7811e-02,  2.3025e-01,  1.5583e-01,\n",
      "          -2.6347e-01],\n",
      "         [ 4.6763e-01,  1.6628e-01, -4.6389e-02,  2.3983e-01,  1.6276e-01,\n",
      "          -2.5412e-01],\n",
      "         [ 4.6391e-01,  1.6435e-01, -4.9311e-02,  2.4512e-01,  1.7111e-01,\n",
      "          -2.4879e-01],\n",
      "         [ 4.6622e-01,  1.6598e-01, -4.9185e-02,  2.4759e-01,  1.7508e-01,\n",
      "          -2.4846e-01],\n",
      "         [ 4.5785e-01,  1.6126e-01, -5.4186e-02,  2.4772e-01,  1.7651e-01,\n",
      "          -2.4020e-01],\n",
      "         [ 4.6395e-01,  1.6431e-01, -4.9389e-02,  2.4981e-01,  1.7715e-01,\n",
      "          -2.4493e-01],\n",
      "         [ 4.4696e-01,  1.5937e-01, -5.8403e-02,  2.4697e-01,  1.7707e-01,\n",
      "          -2.3171e-01],\n",
      "         [ 4.3715e-01,  1.5956e-01, -6.4309e-02,  2.4957e-01,  1.8379e-01,\n",
      "          -2.2624e-01],\n",
      "         [ 4.3677e-01,  1.6202e-01, -6.2144e-02,  2.4916e-01,  1.8253e-01,\n",
      "          -2.2797e-01],\n",
      "         [ 4.2525e-01,  1.5950e-01, -6.6306e-02,  2.4665e-01,  1.8143e-01,\n",
      "          -2.2177e-01],\n",
      "         [ 4.1706e-01,  1.6003e-01, -7.0583e-02,  2.4757e-01,  1.8622e-01,\n",
      "          -2.1896e-01],\n",
      "         [ 4.2491e-01,  1.6187e-01, -6.5836e-02,  2.4912e-01,  1.8573e-01,\n",
      "          -2.2387e-01],\n",
      "         [ 4.3065e-01,  1.6309e-01, -6.2393e-02,  2.4811e-01,  1.8275e-01,\n",
      "          -2.2740e-01],\n",
      "         [ 4.3335e-01,  1.6181e-01, -6.1557e-02,  2.4775e-01,  1.8176e-01,\n",
      "          -2.2866e-01],\n",
      "         [ 4.3092e-01,  1.5790e-01, -6.3379e-02,  2.4791e-01,  1.8200e-01,\n",
      "          -2.2544e-01],\n",
      "         [ 4.1507e-01,  1.5316e-01, -7.1929e-02,  2.4764e-01,  1.8675e-01,\n",
      "          -2.1580e-01],\n",
      "         [ 4.0529e-01,  1.5573e-01, -7.9799e-02,  2.5039e-01,  1.9688e-01,\n",
      "          -2.1126e-01]],\n",
      "\n",
      "        [[ 4.3450e-01,  2.5443e-01, -1.3955e-03,  1.9211e-01,  1.0384e-01,\n",
      "          -3.1586e-01],\n",
      "         [ 4.7106e-01,  1.9112e-01, -5.9357e-03,  2.0327e-01,  9.7310e-02,\n",
      "          -2.8643e-01],\n",
      "         [ 4.6110e-01,  1.6241e-01, -2.3523e-02,  2.2683e-01,  1.2757e-01,\n",
      "          -2.5723e-01],\n",
      "         [ 4.5262e-01,  1.4960e-01, -3.8429e-02,  2.4172e-01,  1.5184e-01,\n",
      "          -2.3904e-01],\n",
      "         [ 4.4334e-01,  1.4718e-01, -4.8474e-02,  2.4701e-01,  1.6505e-01,\n",
      "          -2.2908e-01],\n",
      "         [ 4.4253e-01,  1.4830e-01, -5.4296e-02,  2.5204e-01,  1.7610e-01,\n",
      "          -2.2611e-01],\n",
      "         [ 4.2512e-01,  1.4746e-01, -6.6988e-02,  2.5030e-01,  1.8363e-01,\n",
      "          -2.1433e-01],\n",
      "         [ 4.2092e-01,  1.4914e-01, -7.3216e-02,  2.5444e-01,  1.9404e-01,\n",
      "          -2.1190e-01],\n",
      "         [ 4.1656e-01,  1.5006e-01, -7.5993e-02,  2.5420e-01,  1.9658e-01,\n",
      "          -2.1030e-01],\n",
      "         [ 4.0644e-01,  1.5293e-01, -8.0778e-02,  2.5181e-01,  1.9929e-01,\n",
      "          -2.0822e-01],\n",
      "         [ 4.0638e-01,  1.5620e-01, -8.2206e-02,  2.5367e-01,  2.0353e-01,\n",
      "          -2.0951e-01],\n",
      "         [ 4.0470e-01,  1.5822e-01, -8.2856e-02,  2.5214e-01,  2.0315e-01,\n",
      "          -2.1015e-01],\n",
      "         [ 4.0133e-01,  1.6149e-01, -8.4791e-02,  2.5037e-01,  2.0401e-01,\n",
      "          -2.1082e-01],\n",
      "         [ 4.0520e-01,  1.6233e-01, -8.0376e-02,  2.4931e-01,  1.9934e-01,\n",
      "          -2.1437e-01],\n",
      "         [ 4.2600e-01,  1.6695e-01, -6.7824e-02,  2.5110e-01,  1.9308e-01,\n",
      "          -2.2693e-01],\n",
      "         [ 4.3096e-01,  1.6013e-01, -6.2100e-02,  2.4878e-01,  1.8304e-01,\n",
      "          -2.2788e-01],\n",
      "         [ 4.1743e-01,  1.5835e-01, -6.9868e-02,  2.4680e-01,  1.8573e-01,\n",
      "          -2.1987e-01],\n",
      "         [ 4.2830e-01,  1.6132e-01, -6.6729e-02,  2.5165e-01,  1.8941e-01,\n",
      "          -2.2407e-01],\n",
      "         [ 4.4176e-01,  1.6643e-01, -5.9469e-02,  2.5053e-01,  1.8533e-01,\n",
      "          -2.3329e-01],\n",
      "         [ 4.4057e-01,  1.6107e-01, -5.7732e-02,  2.4605e-01,  1.7705e-01,\n",
      "          -2.3085e-01]],\n",
      "\n",
      "        [[ 4.6840e-01,  2.2062e-01,  1.9255e-02,  2.1534e-01,  1.1753e-01,\n",
      "          -3.3529e-01],\n",
      "         [ 4.7425e-01,  1.5995e-01,  5.3549e-04,  2.1358e-01,  9.7841e-02,\n",
      "          -2.7746e-01],\n",
      "         [ 4.4217e-01,  1.4495e-01, -3.0257e-02,  2.3041e-01,  1.3527e-01,\n",
      "          -2.4508e-01],\n",
      "         [ 4.0490e-01,  1.4032e-01, -5.8504e-02,  2.3764e-01,  1.6289e-01,\n",
      "          -2.1888e-01],\n",
      "         [ 4.1153e-01,  1.4055e-01, -6.4384e-02,  2.5259e-01,  1.8178e-01,\n",
      "          -2.1385e-01],\n",
      "         [ 3.8692e-01,  1.5034e-01, -8.0376e-02,  2.4844e-01,  1.9382e-01,\n",
      "          -2.0431e-01],\n",
      "         [ 3.8379e-01,  1.5741e-01, -8.6446e-02,  2.5087e-01,  2.0435e-01,\n",
      "          -2.0494e-01],\n",
      "         [ 4.0043e-01,  1.6608e-01, -7.7077e-02,  2.5046e-01,  1.9979e-01,\n",
      "          -2.1788e-01],\n",
      "         [ 4.1293e-01,  1.6619e-01, -6.7539e-02,  2.4532e-01,  1.8622e-01,\n",
      "          -2.2527e-01],\n",
      "         [ 4.1556e-01,  1.6525e-01, -6.5362e-02,  2.4151e-01,  1.7963e-01,\n",
      "          -2.2576e-01],\n",
      "         [ 4.1441e-01,  1.6806e-01, -6.4037e-02,  2.3894e-01,  1.7777e-01,\n",
      "          -2.2975e-01],\n",
      "         [ 4.2114e-01,  1.6407e-01, -6.3518e-02,  2.4318e-01,  1.7867e-01,\n",
      "          -2.2803e-01],\n",
      "         [ 4.5119e-01,  1.6819e-01, -5.0313e-02,  2.5078e-01,  1.7763e-01,\n",
      "          -2.4110e-01],\n",
      "         [ 4.4709e-01,  1.6515e-01, -5.5112e-02,  2.4663e-01,  1.7469e-01,\n",
      "          -2.3456e-01],\n",
      "         [ 4.5665e-01,  1.6614e-01, -4.6779e-02,  2.4839e-01,  1.7164e-01,\n",
      "          -2.4335e-01],\n",
      "         [ 4.6231e-01,  1.6551e-01, -4.6535e-02,  2.4839e-01,  1.7050e-01,\n",
      "          -2.4199e-01],\n",
      "         [ 4.4855e-01,  1.6192e-01, -5.6937e-02,  2.4671e-01,  1.7550e-01,\n",
      "          -2.3163e-01],\n",
      "         [ 4.5712e-01,  1.6754e-01, -5.3690e-02,  2.4971e-01,  1.8035e-01,\n",
      "          -2.4010e-01],\n",
      "         [ 4.5504e-01,  1.6424e-01, -5.4519e-02,  2.4740e-01,  1.7692e-01,\n",
      "          -2.3724e-01],\n",
      "         [ 4.6516e-01,  1.6862e-01, -4.9356e-02,  2.4876e-01,  1.7779e-01,\n",
      "          -2.4573e-01]],\n",
      "\n",
      "        [[ 4.6592e-01,  1.7700e-01,  2.1524e-02,  2.1369e-01,  1.0126e-01,\n",
      "          -3.3526e-01],\n",
      "         [ 4.9712e-01,  1.0885e-01,  1.6223e-02,  2.2714e-01,  8.4737e-02,\n",
      "          -2.7873e-01],\n",
      "         [ 4.5728e-01,  1.0385e-01, -2.5952e-02,  2.4707e-01,  1.3237e-01,\n",
      "          -2.3642e-01],\n",
      "         [ 4.1873e-01,  1.0406e-01, -5.3965e-02,  2.6444e-01,  1.7135e-01,\n",
      "          -2.1160e-01],\n",
      "         [ 3.6251e-01,  1.1207e-01, -9.7091e-02,  2.7932e-01,  2.2769e-01,\n",
      "          -1.7927e-01],\n",
      "         [ 3.0522e-01,  1.2335e-01, -1.5011e-01,  2.9190e-01,  2.9313e-01,\n",
      "          -1.4795e-01],\n",
      "         [ 2.6539e-01,  1.4026e-01, -1.9653e-01,  2.9591e-01,  3.4193e-01,\n",
      "          -1.2836e-01],\n",
      "         [ 2.4545e-01,  1.3313e-01, -2.2271e-01,  3.0436e-01,  3.5339e-01,\n",
      "          -1.0911e-01],\n",
      "         [ 2.2561e-01,  9.0008e-02, -2.4809e-01,  3.2700e-01,  3.3421e-01,\n",
      "          -6.4811e-02],\n",
      "         [ 1.8656e-01,  1.7022e-02, -2.7849e-01,  3.5507e-01,  2.7972e-01,\n",
      "           4.8411e-03],\n",
      "         [ 1.3452e-01, -4.8022e-02, -3.0187e-01,  3.6369e-01,  2.1270e-01,\n",
      "           7.0424e-02],\n",
      "         [ 5.1747e-02, -8.9411e-02, -3.2117e-01,  3.2713e-01,  1.3077e-01,\n",
      "           1.2596e-01],\n",
      "         [-3.7645e-02, -1.2236e-01, -3.3579e-01,  2.7810e-01,  4.8571e-02,\n",
      "           1.7350e-01],\n",
      "         [-1.0613e-01, -1.3518e-01, -3.4256e-01,  2.4007e-01, -6.4320e-03,\n",
      "           2.0228e-01],\n",
      "         [-1.4052e-01, -1.4439e-01, -3.4574e-01,  2.1965e-01, -3.9777e-02,\n",
      "           2.1868e-01],\n",
      "         [-1.6744e-01, -1.4128e-01, -3.4460e-01,  2.0353e-01, -6.2078e-02,\n",
      "           2.2615e-01],\n",
      "         [-1.7245e-01, -1.4517e-01, -3.4148e-01,  1.9754e-01, -7.7335e-02,\n",
      "           2.2920e-01],\n",
      "         [-1.7578e-01, -1.4597e-01, -3.3568e-01,  1.9056e-01, -9.3735e-02,\n",
      "           2.2943e-01],\n",
      "         [-1.6851e-01, -1.4686e-01, -3.2568e-01,  1.8556e-01, -1.1097e-01,\n",
      "           2.2503e-01],\n",
      "         [-1.5122e-01, -1.4629e-01, -3.0731e-01,  1.7871e-01, -1.3639e-01,\n",
      "           2.1343e-01]],\n",
      "\n",
      "        [[ 6.4525e-01, -1.6214e-01,  1.3720e-02,  4.4732e-01,  3.2534e-02,\n",
      "          -1.0508e-01],\n",
      "         [ 6.1822e-01, -1.3716e-01, -1.7359e-02,  4.3485e-01,  6.8790e-02,\n",
      "          -9.0163e-02],\n",
      "         [ 5.7426e-01, -1.3188e-01, -4.5124e-02,  4.4201e-01,  1.0093e-01,\n",
      "          -6.3760e-02],\n",
      "         [ 5.0128e-01, -1.4995e-01, -9.6107e-02,  4.5546e-01,  1.3267e-01,\n",
      "          -1.2635e-02],\n",
      "         [ 4.3042e-01, -1.7068e-01, -1.5243e-01,  4.7624e-01,  1.7419e-01,\n",
      "           4.0620e-02],\n",
      "         [ 3.6144e-01, -1.9209e-01, -2.0434e-01,  4.9151e-01,  2.0382e-01,\n",
      "           9.0906e-02],\n",
      "         [ 3.1570e-01, -1.9396e-01, -2.3556e-01,  4.9330e-01,  2.1945e-01,\n",
      "           1.1503e-01],\n",
      "         [ 2.7798e-01, -1.8648e-01, -2.5433e-01,  4.8385e-01,  2.1971e-01,\n",
      "           1.2713e-01],\n",
      "         [ 2.5142e-01, -1.7156e-01, -2.6660e-01,  4.7121e-01,  2.1873e-01,\n",
      "           1.2945e-01],\n",
      "         [ 2.3019e-01, -1.6502e-01, -2.7370e-01,  4.6014e-01,  2.1166e-01,\n",
      "           1.3282e-01],\n",
      "         [ 2.1480e-01, -1.6387e-01, -2.7787e-01,  4.5155e-01,  2.0257e-01,\n",
      "           1.3691e-01],\n",
      "         [ 2.0227e-01, -1.6412e-01, -2.8122e-01,  4.4376e-01,  1.9361e-01,\n",
      "           1.4055e-01],\n",
      "         [ 1.9521e-01, -1.6235e-01, -2.8355e-01,  4.3884e-01,  1.8970e-01,\n",
      "           1.4134e-01],\n",
      "         [ 1.9052e-01, -1.6097e-01, -2.8522e-01,  4.3505e-01,  1.8679e-01,\n",
      "           1.4156e-01],\n",
      "         [ 1.8280e-01, -1.6287e-01, -2.8718e-01,  4.2987e-01,  1.7993e-01,\n",
      "           1.4435e-01],\n",
      "         [ 1.7841e-01, -1.6348e-01, -2.8822e-01,  4.2694e-01,  1.7639e-01,\n",
      "           1.4543e-01],\n",
      "         [ 1.7403e-01, -1.6327e-01, -2.8962e-01,  4.2346e-01,  1.7282e-01,\n",
      "           1.4640e-01],\n",
      "         [ 1.7817e-01, -1.6504e-01, -2.8736e-01,  4.2728e-01,  1.7513e-01,\n",
      "           1.4663e-01],\n",
      "         [ 1.8004e-01, -1.6566e-01, -2.8661e-01,  4.2914e-01,  1.7651e-01,\n",
      "           1.4671e-01],\n",
      "         [ 1.8215e-01, -1.6482e-01, -2.8618e-01,  4.3024e-01,  1.7816e-01,\n",
      "           1.4587e-01]],\n",
      "\n",
      "        [[ 4.4112e-01, -1.8030e-01, -1.2446e-01,  4.8199e-01,  8.6323e-02,\n",
      "           8.5147e-02],\n",
      "         [ 3.9244e-01, -2.1852e-01, -1.7820e-01,  4.9711e-01,  1.4616e-01,\n",
      "           1.0443e-01],\n",
      "         [ 3.4535e-01, -2.1185e-01, -2.1760e-01,  4.9471e-01,  1.8894e-01,\n",
      "           1.1258e-01],\n",
      "         [ 3.1482e-01, -1.9777e-01, -2.3963e-01,  4.8887e-01,  2.1018e-01,\n",
      "           1.1623e-01],\n",
      "         [ 2.8618e-01, -1.8564e-01, -2.5431e-01,  4.8064e-01,  2.1687e-01,\n",
      "           1.2157e-01],\n",
      "         [ 2.5442e-01, -1.7480e-01, -2.6703e-01,  4.6755e-01,  2.1288e-01,\n",
      "           1.2844e-01],\n",
      "         [ 2.3856e-01, -1.6264e-01, -2.7284e-01,  4.6148e-01,  2.1560e-01,\n",
      "           1.2812e-01],\n",
      "         [ 2.2637e-01, -1.5527e-01, -2.7690e-01,  4.5536e-01,  2.1456e-01,\n",
      "           1.2827e-01],\n",
      "         [ 2.1579e-01, -1.5299e-01, -2.8002e-01,  4.4966e-01,  2.0984e-01,\n",
      "           1.3061e-01],\n",
      "         [ 2.1232e-01, -1.4828e-01, -2.8176e-01,  4.4666e-01,  2.1029e-01,\n",
      "           1.2873e-01],\n",
      "         [ 2.0961e-01, -1.4670e-01, -2.8270e-01,  4.4481e-01,  2.0947e-01,\n",
      "           1.2859e-01],\n",
      "         [ 2.1146e-01, -1.4326e-01, -2.8238e-01,  4.4615e-01,  2.1358e-01,\n",
      "           1.2612e-01],\n",
      "         [ 2.1062e-01, -1.4170e-01, -2.8285e-01,  4.4548e-01,  2.1421e-01,\n",
      "           1.2580e-01],\n",
      "         [ 2.1130e-01, -1.4084e-01, -2.8269e-01,  4.4586e-01,  2.1542e-01,\n",
      "           1.2510e-01],\n",
      "         [ 2.0771e-01, -1.4584e-01, -2.8290e-01,  4.4456e-01,  2.0984e-01,\n",
      "           1.2899e-01],\n",
      "         [ 2.0260e-01, -1.5039e-01, -2.8379e-01,  4.4171e-01,  2.0286e-01,\n",
      "           1.3296e-01],\n",
      "         [ 1.9692e-01, -1.5409e-01, -2.8488e-01,  4.3810e-01,  1.9598e-01,\n",
      "           1.3619e-01],\n",
      "         [ 1.9290e-01, -1.5517e-01, -2.8600e-01,  4.3503e-01,  1.9158e-01,\n",
      "           1.3785e-01],\n",
      "         [ 1.9006e-01, -1.5701e-01, -2.8636e-01,  4.3322e-01,  1.8807e-01,\n",
      "           1.3947e-01],\n",
      "         [ 1.9527e-01, -1.5288e-01, -2.8557e-01,  4.3607e-01,  1.9433e-01,\n",
      "           1.3574e-01]],\n",
      "\n",
      "        [[-3.5541e-02, -2.3164e-01, -3.1866e-01,  2.6505e-01, -7.5461e-02,\n",
      "           2.2146e-01],\n",
      "         [-1.0208e-01, -2.1016e-01, -3.2724e-01,  2.0986e-01, -1.1532e-01,\n",
      "           2.2017e-01],\n",
      "         [-9.0782e-02, -1.9266e-01, -3.1994e-01,  2.1213e-01, -1.0733e-01,\n",
      "           2.0557e-01],\n",
      "         [-9.0149e-02, -1.7505e-01, -3.1226e-01,  2.1021e-01, -1.0462e-01,\n",
      "           1.9591e-01],\n",
      "         [-9.8352e-02, -1.4513e-01, -3.0209e-01,  1.9160e-01, -1.0864e-01,\n",
      "           1.7733e-01],\n",
      "         [-8.1634e-02, -1.0648e-01, -2.8208e-01,  1.7862e-01, -1.0234e-01,\n",
      "           1.4133e-01],\n",
      "         [-5.2067e-02, -6.7449e-02, -2.5128e-01,  1.6399e-01, -1.0472e-01,\n",
      "           9.8503e-02],\n",
      "         [-2.1432e-03, -2.9439e-02, -2.1075e-01,  1.4726e-01, -1.1386e-01,\n",
      "           4.0811e-02],\n",
      "         [ 5.6691e-02, -1.6995e-03, -1.6494e-01,  1.4082e-01, -1.2570e-01,\n",
      "          -1.1849e-02],\n",
      "         [ 1.0507e-01,  1.3362e-02, -1.2724e-01,  1.3005e-01, -1.4547e-01,\n",
      "          -5.3463e-02],\n",
      "         [ 1.3639e-01,  2.1565e-02, -9.9238e-02,  1.1722e-01, -1.6814e-01,\n",
      "          -8.0590e-02],\n",
      "         [ 1.5576e-01,  2.6393e-02, -8.0262e-02,  1.0689e-01, -1.8504e-01,\n",
      "          -9.7919e-02],\n",
      "         [ 1.6736e-01,  2.7711e-02, -6.8294e-02,  1.0125e-01, -1.9623e-01,\n",
      "          -1.0716e-01],\n",
      "         [ 1.7451e-01,  2.4912e-02, -6.2205e-02,  1.0136e-01, -2.0183e-01,\n",
      "          -1.0948e-01],\n",
      "         [ 1.7744e-01,  2.0911e-02, -6.0504e-02,  1.0244e-01, -2.0512e-01,\n",
      "          -1.0824e-01],\n",
      "         [ 1.7785e-01,  1.7767e-02, -6.0458e-02,  1.0350e-01, -2.0727e-01,\n",
      "          -1.0594e-01],\n",
      "         [ 1.7746e-01,  1.7075e-02, -6.0556e-02,  1.0362e-01, -2.0810e-01,\n",
      "          -1.0509e-01],\n",
      "         [ 1.7802e-01,  1.7019e-02, -5.9821e-02,  1.0239e-01, -2.0954e-01,\n",
      "          -1.0601e-01],\n",
      "         [ 1.7818e-01,  1.9930e-02, -5.8476e-02,  9.9997e-02, -2.0983e-01,\n",
      "          -1.0885e-01],\n",
      "         [ 1.7952e-01,  1.9210e-02, -5.7629e-02,  1.0000e-01, -2.1050e-01,\n",
      "          -1.0931e-01]],\n",
      "\n",
      "        [[-1.6777e-02, -2.8378e-01, -3.0636e-01,  3.1363e-01, -6.0659e-02,\n",
      "           2.6118e-01],\n",
      "         [-9.4732e-02, -2.4382e-01, -3.3111e-01,  2.3193e-01, -1.0308e-01,\n",
      "           2.4658e-01],\n",
      "         [-1.0057e-01, -2.2876e-01, -3.3220e-01,  2.1420e-01, -1.1165e-01,\n",
      "           2.3592e-01],\n",
      "         [-9.5374e-02, -2.3372e-01, -3.2670e-01,  2.0839e-01, -1.2527e-01,\n",
      "           2.3481e-01],\n",
      "         [-8.8823e-02, -2.3850e-01, -3.2099e-01,  2.0350e-01, -1.3875e-01,\n",
      "           2.3306e-01],\n",
      "         [-8.2716e-02, -2.3981e-01, -3.1426e-01,  1.9357e-01, -1.5717e-01,\n",
      "           2.2711e-01],\n",
      "         [-7.0495e-02, -2.4126e-01, -3.0081e-01,  1.7878e-01, -1.8639e-01,\n",
      "           2.1496e-01],\n",
      "         [-4.0449e-02, -2.4683e-01, -2.7008e-01,  1.6140e-01, -2.3752e-01,\n",
      "           1.9349e-01],\n",
      "         [ 2.3610e-02, -2.4678e-01, -2.1086e-01,  1.3883e-01, -3.1595e-01,\n",
      "           1.4918e-01],\n",
      "         [ 9.9199e-02, -2.4600e-01, -1.4115e-01,  1.2788e-01, -3.7875e-01,\n",
      "           1.0407e-01],\n",
      "         [ 1.4582e-01, -2.2123e-01, -9.6754e-02,  1.1681e-01, -3.8819e-01,\n",
      "           6.1786e-02],\n",
      "         [ 1.7198e-01, -1.9887e-01, -7.6960e-02,  1.1196e-01, -3.7617e-01,\n",
      "           3.4282e-02],\n",
      "         [ 1.8848e-01, -1.9417e-01, -6.8135e-02,  1.1345e-01, -3.6992e-01,\n",
      "           2.4233e-02],\n",
      "         [ 1.9242e-01, -1.9808e-01, -6.6794e-02,  1.1742e-01, -3.6801e-01,\n",
      "           2.5291e-02],\n",
      "         [ 1.9343e-01, -1.9995e-01, -6.6390e-02,  1.1837e-01, -3.6819e-01,\n",
      "           2.6110e-02],\n",
      "         [ 1.9475e-01, -2.0312e-01, -6.4460e-02,  1.1804e-01, -3.7150e-01,\n",
      "           2.7128e-02],\n",
      "         [ 1.9949e-01, -1.9876e-01, -6.2860e-02,  1.1669e-01, -3.6772e-01,\n",
      "           2.1422e-02],\n",
      "         [ 2.0005e-01, -2.0059e-01, -6.2846e-02,  1.1811e-01, -3.6786e-01,\n",
      "           2.2735e-02],\n",
      "         [ 2.0619e-01, -1.9861e-01, -5.8679e-02,  1.1433e-01, -3.6928e-01,\n",
      "           1.7595e-02],\n",
      "         [ 2.1467e-01, -1.9514e-01, -5.4832e-02,  1.1252e-01, -3.6597e-01,\n",
      "           1.0362e-02]]], device='cuda:0'), (tensor([[[ 1.4355e-01,  7.3157e-02,  2.4381e-01, -5.7062e-02, -8.8234e-02,\n",
      "          -8.1890e-01, -2.0661e-03,  1.0936e-01],\n",
      "         [ 2.4036e-02,  3.1140e-02,  2.4730e-01,  5.1976e-02,  1.7896e-01,\n",
      "          -8.0178e-01, -3.4870e-02,  2.3666e-01],\n",
      "         [ 9.2375e-02, -9.3913e-02,  1.3000e-01, -1.6158e-02,  1.3607e-01,\n",
      "          -8.0519e-01, -1.3406e-04,  3.3821e-01],\n",
      "         [-3.0236e-02, -3.6125e-02, -1.2155e-01, -5.0207e-02,  1.3495e-01,\n",
      "          -5.0369e-01,  5.6519e-02,  5.2339e-01],\n",
      "         [ 9.2993e-02,  5.8096e-02, -4.5478e-01, -7.0031e-03, -1.7744e-01,\n",
      "           1.8902e-01,  3.7692e-02, -3.5866e-01],\n",
      "         [-1.2117e-01,  7.9728e-02, -1.8769e-02, -1.3057e-01, -1.1782e-01,\n",
      "           1.7488e-01,  6.1004e-02, -4.0322e-01],\n",
      "         [-1.9751e-01,  1.1838e-01,  4.7639e-01,  1.4704e-02, -2.0707e-01,\n",
      "           2.5813e-01, -1.0858e-02, -4.2310e-01],\n",
      "         [-1.6513e-01, -1.5501e-02, -2.4231e-01, -1.1711e-01, -1.7202e-01,\n",
      "           1.5605e-01,  3.9352e-02, -8.8438e-02]],\n",
      "\n",
      "        [[-4.1490e-02, -2.6011e-01, -4.3467e-04,  1.2990e-02,  1.5525e-01,\n",
      "          -2.0018e-01,  5.3712e-02,  4.7088e-01],\n",
      "         [-1.2541e-02, -2.3248e-01, -1.3798e-02,  2.9317e-03,  3.0077e-01,\n",
      "          -2.2560e-01,  5.7703e-02,  4.3423e-01],\n",
      "         [-1.3042e-02, -2.1067e-01, -2.1303e-02, -2.3006e-04,  4.3946e-01,\n",
      "          -2.0731e-01,  8.4655e-02,  1.9529e-01],\n",
      "         [ 3.7206e-04, -2.4379e-01, -4.1743e-02, -1.1777e-02,  5.3492e-01,\n",
      "          -2.6731e-02,  1.1059e-01, -1.6689e-01],\n",
      "         [-4.0812e-02,  7.6629e-01, -2.7627e-03, -4.9842e-02, -3.8651e-01,\n",
      "          -1.3479e-02, -4.8992e-02, -1.1862e-01],\n",
      "         [-3.8234e-02,  7.2341e-01,  6.3881e-03, -5.6831e-02, -2.7117e-01,\n",
      "          -1.9150e-01, -4.1136e-02, -1.2643e-01],\n",
      "         [-1.5456e-02, -3.6294e-01,  4.1601e-02,  4.9590e-02,  1.3260e-02,\n",
      "          -4.8776e-02,  6.3377e-03,  5.6171e-01],\n",
      "         [-3.1391e-02,  7.4719e-01, -1.4108e-02, -5.6622e-02, -3.7818e-01,\n",
      "          -3.3958e-03, -3.8752e-02, -1.2872e-01]],\n",
      "\n",
      "        [[ 1.0461e-01,  1.4496e-02,  3.7368e-01, -4.1091e-01, -1.3006e-02,\n",
      "          -5.0762e-02, -5.2057e-03, -7.0911e-04],\n",
      "         [ 1.0344e-01,  9.5762e-02,  3.8666e-01, -4.1607e-01, -1.3635e-02,\n",
      "          -5.4060e-02, -1.3819e-02, -3.9533e-03],\n",
      "         [ 9.4939e-02,  1.2686e-01,  4.2123e-01, -4.1889e-01, -1.0535e-02,\n",
      "          -4.3641e-02, -1.8642e-02, -3.2148e-03],\n",
      "         [ 2.9943e-01, -3.4118e-01, -5.6306e-01,  4.1816e-01, -1.2353e-02,\n",
      "           6.5070e-02,  1.9658e-02,  1.0625e-03],\n",
      "         [-4.6329e-02, -4.8967e-01,  3.3369e-01,  4.8212e-01,  1.2060e-04,\n",
      "          -5.3316e-02, -2.2805e-02, -5.0766e-03],\n",
      "         [-3.8453e-02, -4.9093e-01,  3.7586e-01,  4.7545e-01, -1.1801e-03,\n",
      "          -4.5532e-02, -2.7066e-02, -5.5630e-03],\n",
      "         [ 2.4378e-01,  3.0438e-01, -3.3684e-01, -1.0569e-01,  4.0801e-04,\n",
      "           5.7141e-02,  8.5074e-02,  7.7525e-03],\n",
      "         [-1.7686e-01,  3.8439e-01, -5.9264e-01,  1.1272e-01,  4.1509e-02,\n",
      "          -6.2473e-02,  4.1380e-02,  5.5231e-03]]], device='cuda:0'), tensor([[[ 5.2470e-01,  1.5692e-01,  1.3693e+00, -1.0298e-01, -1.6534e-01,\n",
      "          -2.1580e+00, -5.2717e-03,  2.2846e-01],\n",
      "         [ 6.3645e-02,  6.4709e-02,  5.7450e-01,  1.4506e-01,  3.2434e-01,\n",
      "          -2.5186e+00, -8.9868e-02,  5.4987e-01],\n",
      "         [ 3.8728e-01, -1.7823e-01,  8.0360e-01, -3.4145e-02,  2.7712e-01,\n",
      "          -2.3483e+00, -2.7621e-04,  7.8373e-01],\n",
      "         [-1.4791e-01, -8.0476e-02, -4.2331e-01, -7.8926e-02,  3.0353e-01,\n",
      "          -1.7192e+00,  8.4277e-02,  1.8840e+00],\n",
      "         [ 1.6104e-01,  1.3226e-01, -9.0014e-01, -1.0003e-02, -4.0897e-01,\n",
      "           2.2358e+00,  5.8939e-02, -8.9055e-01],\n",
      "         [-2.1500e-01,  1.5493e-01, -3.4745e-02, -1.9102e-01, -2.6120e-01,\n",
      "           2.2979e+00,  9.0730e-02, -1.1864e+00],\n",
      "         [-2.5073e-01,  2.4151e-01,  7.9321e-01,  3.0746e-02, -3.9803e-01,\n",
      "           1.5814e+00, -2.6811e-02, -1.7046e+00],\n",
      "         [-2.5668e-01, -3.0407e-02, -4.5618e-01, -1.8578e-01, -4.0129e-01,\n",
      "           2.5049e+00,  7.4418e-02, -1.6859e-01]],\n",
      "\n",
      "        [[-5.4880e-02, -1.9332e+00, -9.7291e-04,  2.3784e-02,  7.9732e-01,\n",
      "          -4.2326e-01,  1.0068e-01,  7.8477e-01],\n",
      "         [-1.7083e-02, -1.7731e+00, -3.3025e-02,  4.8776e-03,  9.8462e-01,\n",
      "          -4.9112e-01,  1.0424e-01,  7.3975e-01],\n",
      "         [-1.6513e-02, -1.6795e+00, -4.7760e-02, -4.4206e-04,  1.3549e+00,\n",
      "          -4.4390e-01,  1.2959e-01,  3.8199e-01],\n",
      "         [ 5.7143e-04, -9.7467e-01, -8.0331e-02, -2.5994e-02,  1.7085e+00,\n",
      "          -5.4238e-02,  1.2743e-01, -5.1021e-01],\n",
      "         [-9.4745e-02,  2.4225e+00, -8.3544e-03, -9.6470e-02, -6.0329e-01,\n",
      "          -2.7073e-02, -1.4055e-01, -3.6145e-01],\n",
      "         [-9.4799e-02,  2.4213e+00,  2.0984e-02, -9.8194e-02, -3.8357e-01,\n",
      "          -4.0704e-01, -1.1267e-01, -3.4667e-01],\n",
      "         [-3.2222e-02, -2.1824e+00,  8.3416e-02,  8.4195e-02,  6.8832e-02,\n",
      "          -9.7250e-02,  1.8496e-02,  8.1244e-01],\n",
      "         [-8.7256e-02,  2.4429e+00, -3.8327e-02, -1.0831e-01, -5.3227e-01,\n",
      "          -6.8594e-03, -9.4249e-02, -3.8801e-01]],\n",
      "\n",
      "        [[ 2.1035e-01,  2.9091e-02,  1.9399e+00, -1.6682e+00, -2.5485e-02,\n",
      "          -9.4876e-02, -7.4918e-03, -1.2157e-03],\n",
      "         [ 2.0120e-01,  1.9893e-01,  1.9134e+00, -1.6758e+00, -2.6522e-02,\n",
      "          -1.0628e-01, -1.9855e-02, -7.3033e-03],\n",
      "         [ 1.6621e-01,  2.7161e-01,  1.8661e+00, -1.7283e+00, -2.0398e-02,\n",
      "          -9.6936e-02, -2.8332e-02, -5.5704e-03],\n",
      "         [ 4.8682e-01, -7.6670e-01, -1.8438e+00,  1.2846e+00, -2.4413e-02,\n",
      "           2.5258e-01,  6.6120e-02,  2.0854e-03],\n",
      "         [-1.4183e-01, -1.5669e+00,  6.7200e-01,  1.7585e+00,  2.5013e-04,\n",
      "          -7.5829e-02, -5.1628e-02, -1.4469e-02],\n",
      "         [-1.1615e-01, -1.5919e+00,  7.9249e-01,  1.6817e+00, -2.4428e-03,\n",
      "          -6.3546e-02, -6.0233e-02, -1.7540e-02],\n",
      "         [ 4.1895e-01,  7.4043e-01, -2.2979e+00, -2.1337e-01,  7.8458e-04,\n",
      "           1.7554e-01,  1.4076e-01,  1.6667e-02],\n",
      "         [-3.7744e-01,  1.1725e+00, -2.0475e+00,  2.3033e-01,  8.0841e-02,\n",
      "          -1.0048e-01,  8.2292e-02,  3.3913e-02]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_torch]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out0 = model_torch(inputs, hidden)\n",
    "    print(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:20.674353Z",
     "start_time": "2019-02-06T20:06:20.037322Z"
    },
    "hidden": true,
    "scrolled": true,
    "tags": [
     "#forward-test-2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cpp]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[ 2.1202e-01,  2.8098e-01, -1.6853e-01,  1.5387e-01,  1.8006e-01,\n",
      "          -1.8520e-01],\n",
      "         [ 3.6610e-01,  2.3259e-01, -9.6601e-02,  1.8165e-01,  1.6299e-01,\n",
      "          -2.6788e-01],\n",
      "         [ 4.3691e-01,  1.9658e-01, -6.7583e-02,  2.0776e-01,  1.5565e-01,\n",
      "          -2.6871e-01],\n",
      "         [ 4.6849e-01,  1.7438e-01, -4.7811e-02,  2.3025e-01,  1.5583e-01,\n",
      "          -2.6347e-01],\n",
      "         [ 4.6763e-01,  1.6628e-01, -4.6389e-02,  2.3983e-01,  1.6276e-01,\n",
      "          -2.5412e-01],\n",
      "         [ 4.6391e-01,  1.6435e-01, -4.9311e-02,  2.4512e-01,  1.7111e-01,\n",
      "          -2.4879e-01],\n",
      "         [ 4.6622e-01,  1.6598e-01, -4.9184e-02,  2.4759e-01,  1.7508e-01,\n",
      "          -2.4846e-01],\n",
      "         [ 4.5785e-01,  1.6126e-01, -5.4186e-02,  2.4772e-01,  1.7651e-01,\n",
      "          -2.4020e-01],\n",
      "         [ 4.6395e-01,  1.6431e-01, -4.9389e-02,  2.4981e-01,  1.7715e-01,\n",
      "          -2.4493e-01],\n",
      "         [ 4.4696e-01,  1.5937e-01, -5.8403e-02,  2.4697e-01,  1.7707e-01,\n",
      "          -2.3171e-01],\n",
      "         [ 4.3715e-01,  1.5956e-01, -6.4309e-02,  2.4957e-01,  1.8379e-01,\n",
      "          -2.2624e-01],\n",
      "         [ 4.3677e-01,  1.6202e-01, -6.2144e-02,  2.4916e-01,  1.8253e-01,\n",
      "          -2.2797e-01],\n",
      "         [ 4.2525e-01,  1.5950e-01, -6.6306e-02,  2.4665e-01,  1.8143e-01,\n",
      "          -2.2177e-01],\n",
      "         [ 4.1706e-01,  1.6003e-01, -7.0583e-02,  2.4757e-01,  1.8622e-01,\n",
      "          -2.1896e-01],\n",
      "         [ 4.2491e-01,  1.6187e-01, -6.5836e-02,  2.4912e-01,  1.8573e-01,\n",
      "          -2.2387e-01],\n",
      "         [ 4.3065e-01,  1.6309e-01, -6.2393e-02,  2.4811e-01,  1.8275e-01,\n",
      "          -2.2740e-01],\n",
      "         [ 4.3335e-01,  1.6181e-01, -6.1557e-02,  2.4775e-01,  1.8176e-01,\n",
      "          -2.2866e-01],\n",
      "         [ 4.3092e-01,  1.5790e-01, -6.3379e-02,  2.4791e-01,  1.8200e-01,\n",
      "          -2.2544e-01],\n",
      "         [ 4.1507e-01,  1.5316e-01, -7.1929e-02,  2.4764e-01,  1.8675e-01,\n",
      "          -2.1580e-01],\n",
      "         [ 4.0529e-01,  1.5573e-01, -7.9799e-02,  2.5039e-01,  1.9688e-01,\n",
      "          -2.1126e-01]],\n",
      "\n",
      "        [[ 4.3450e-01,  2.5443e-01, -1.3955e-03,  1.9211e-01,  1.0384e-01,\n",
      "          -3.1586e-01],\n",
      "         [ 4.7106e-01,  1.9112e-01, -5.9357e-03,  2.0327e-01,  9.7310e-02,\n",
      "          -2.8643e-01],\n",
      "         [ 4.6110e-01,  1.6241e-01, -2.3523e-02,  2.2683e-01,  1.2757e-01,\n",
      "          -2.5723e-01],\n",
      "         [ 4.5262e-01,  1.4960e-01, -3.8429e-02,  2.4172e-01,  1.5184e-01,\n",
      "          -2.3904e-01],\n",
      "         [ 4.4334e-01,  1.4718e-01, -4.8474e-02,  2.4701e-01,  1.6505e-01,\n",
      "          -2.2908e-01],\n",
      "         [ 4.4253e-01,  1.4830e-01, -5.4296e-02,  2.5204e-01,  1.7610e-01,\n",
      "          -2.2611e-01],\n",
      "         [ 4.2512e-01,  1.4746e-01, -6.6988e-02,  2.5030e-01,  1.8363e-01,\n",
      "          -2.1433e-01],\n",
      "         [ 4.2092e-01,  1.4914e-01, -7.3216e-02,  2.5444e-01,  1.9404e-01,\n",
      "          -2.1190e-01],\n",
      "         [ 4.1656e-01,  1.5006e-01, -7.5993e-02,  2.5420e-01,  1.9658e-01,\n",
      "          -2.1030e-01],\n",
      "         [ 4.0644e-01,  1.5293e-01, -8.0778e-02,  2.5181e-01,  1.9929e-01,\n",
      "          -2.0822e-01],\n",
      "         [ 4.0638e-01,  1.5620e-01, -8.2206e-02,  2.5367e-01,  2.0353e-01,\n",
      "          -2.0951e-01],\n",
      "         [ 4.0470e-01,  1.5822e-01, -8.2856e-02,  2.5214e-01,  2.0315e-01,\n",
      "          -2.1015e-01],\n",
      "         [ 4.0133e-01,  1.6149e-01, -8.4791e-02,  2.5037e-01,  2.0401e-01,\n",
      "          -2.1082e-01],\n",
      "         [ 4.0520e-01,  1.6233e-01, -8.0376e-02,  2.4931e-01,  1.9934e-01,\n",
      "          -2.1437e-01],\n",
      "         [ 4.2600e-01,  1.6695e-01, -6.7824e-02,  2.5110e-01,  1.9308e-01,\n",
      "          -2.2693e-01],\n",
      "         [ 4.3096e-01,  1.6013e-01, -6.2100e-02,  2.4878e-01,  1.8304e-01,\n",
      "          -2.2788e-01],\n",
      "         [ 4.1743e-01,  1.5835e-01, -6.9868e-02,  2.4680e-01,  1.8573e-01,\n",
      "          -2.1987e-01],\n",
      "         [ 4.2830e-01,  1.6132e-01, -6.6729e-02,  2.5165e-01,  1.8941e-01,\n",
      "          -2.2407e-01],\n",
      "         [ 4.4176e-01,  1.6643e-01, -5.9469e-02,  2.5053e-01,  1.8533e-01,\n",
      "          -2.3329e-01],\n",
      "         [ 4.4057e-01,  1.6107e-01, -5.7732e-02,  2.4605e-01,  1.7705e-01,\n",
      "          -2.3085e-01]],\n",
      "\n",
      "        [[ 4.6840e-01,  2.2062e-01,  1.9255e-02,  2.1534e-01,  1.1753e-01,\n",
      "          -3.3529e-01],\n",
      "         [ 4.7425e-01,  1.5995e-01,  5.3550e-04,  2.1358e-01,  9.7841e-02,\n",
      "          -2.7746e-01],\n",
      "         [ 4.4217e-01,  1.4495e-01, -3.0257e-02,  2.3041e-01,  1.3527e-01,\n",
      "          -2.4508e-01],\n",
      "         [ 4.0490e-01,  1.4032e-01, -5.8504e-02,  2.3764e-01,  1.6289e-01,\n",
      "          -2.1888e-01],\n",
      "         [ 4.1153e-01,  1.4055e-01, -6.4384e-02,  2.5259e-01,  1.8178e-01,\n",
      "          -2.1385e-01],\n",
      "         [ 3.8692e-01,  1.5034e-01, -8.0376e-02,  2.4844e-01,  1.9382e-01,\n",
      "          -2.0431e-01],\n",
      "         [ 3.8379e-01,  1.5741e-01, -8.6446e-02,  2.5087e-01,  2.0435e-01,\n",
      "          -2.0494e-01],\n",
      "         [ 4.0043e-01,  1.6608e-01, -7.7077e-02,  2.5046e-01,  1.9979e-01,\n",
      "          -2.1788e-01],\n",
      "         [ 4.1293e-01,  1.6619e-01, -6.7539e-02,  2.4532e-01,  1.8622e-01,\n",
      "          -2.2527e-01],\n",
      "         [ 4.1556e-01,  1.6525e-01, -6.5362e-02,  2.4151e-01,  1.7963e-01,\n",
      "          -2.2576e-01],\n",
      "         [ 4.1441e-01,  1.6806e-01, -6.4037e-02,  2.3894e-01,  1.7777e-01,\n",
      "          -2.2975e-01],\n",
      "         [ 4.2114e-01,  1.6407e-01, -6.3518e-02,  2.4318e-01,  1.7867e-01,\n",
      "          -2.2803e-01],\n",
      "         [ 4.5119e-01,  1.6819e-01, -5.0313e-02,  2.5078e-01,  1.7763e-01,\n",
      "          -2.4110e-01],\n",
      "         [ 4.4709e-01,  1.6515e-01, -5.5112e-02,  2.4663e-01,  1.7469e-01,\n",
      "          -2.3456e-01],\n",
      "         [ 4.5665e-01,  1.6614e-01, -4.6779e-02,  2.4839e-01,  1.7164e-01,\n",
      "          -2.4335e-01],\n",
      "         [ 4.6231e-01,  1.6551e-01, -4.6535e-02,  2.4839e-01,  1.7050e-01,\n",
      "          -2.4199e-01],\n",
      "         [ 4.4855e-01,  1.6192e-01, -5.6937e-02,  2.4671e-01,  1.7550e-01,\n",
      "          -2.3163e-01],\n",
      "         [ 4.5712e-01,  1.6754e-01, -5.3690e-02,  2.4971e-01,  1.8035e-01,\n",
      "          -2.4010e-01],\n",
      "         [ 4.5504e-01,  1.6424e-01, -5.4519e-02,  2.4740e-01,  1.7692e-01,\n",
      "          -2.3724e-01],\n",
      "         [ 4.6516e-01,  1.6862e-01, -4.9356e-02,  2.4876e-01,  1.7779e-01,\n",
      "          -2.4573e-01]],\n",
      "\n",
      "        [[ 4.6592e-01,  1.7700e-01,  2.1524e-02,  2.1369e-01,  1.0126e-01,\n",
      "          -3.3526e-01],\n",
      "         [ 4.9712e-01,  1.0885e-01,  1.6223e-02,  2.2714e-01,  8.4737e-02,\n",
      "          -2.7873e-01],\n",
      "         [ 4.5728e-01,  1.0385e-01, -2.5952e-02,  2.4707e-01,  1.3237e-01,\n",
      "          -2.3642e-01],\n",
      "         [ 4.1873e-01,  1.0406e-01, -5.3965e-02,  2.6444e-01,  1.7135e-01,\n",
      "          -2.1160e-01],\n",
      "         [ 3.6251e-01,  1.1207e-01, -9.7091e-02,  2.7932e-01,  2.2769e-01,\n",
      "          -1.7927e-01],\n",
      "         [ 3.0522e-01,  1.2335e-01, -1.5011e-01,  2.9190e-01,  2.9313e-01,\n",
      "          -1.4795e-01],\n",
      "         [ 2.6539e-01,  1.4026e-01, -1.9653e-01,  2.9591e-01,  3.4193e-01,\n",
      "          -1.2836e-01],\n",
      "         [ 2.4545e-01,  1.3313e-01, -2.2271e-01,  3.0436e-01,  3.5339e-01,\n",
      "          -1.0911e-01],\n",
      "         [ 2.2561e-01,  9.0008e-02, -2.4809e-01,  3.2700e-01,  3.3421e-01,\n",
      "          -6.4811e-02],\n",
      "         [ 1.8656e-01,  1.7022e-02, -2.7849e-01,  3.5507e-01,  2.7972e-01,\n",
      "           4.8410e-03],\n",
      "         [ 1.3452e-01, -4.8022e-02, -3.0187e-01,  3.6369e-01,  2.1270e-01,\n",
      "           7.0424e-02],\n",
      "         [ 5.1747e-02, -8.9411e-02, -3.2117e-01,  3.2713e-01,  1.3077e-01,\n",
      "           1.2596e-01],\n",
      "         [-3.7645e-02, -1.2236e-01, -3.3579e-01,  2.7810e-01,  4.8571e-02,\n",
      "           1.7350e-01],\n",
      "         [-1.0613e-01, -1.3518e-01, -3.4256e-01,  2.4007e-01, -6.4320e-03,\n",
      "           2.0228e-01],\n",
      "         [-1.4052e-01, -1.4439e-01, -3.4574e-01,  2.1965e-01, -3.9777e-02,\n",
      "           2.1868e-01],\n",
      "         [-1.6744e-01, -1.4128e-01, -3.4460e-01,  2.0353e-01, -6.2078e-02,\n",
      "           2.2615e-01],\n",
      "         [-1.7245e-01, -1.4517e-01, -3.4148e-01,  1.9754e-01, -7.7335e-02,\n",
      "           2.2920e-01],\n",
      "         [-1.7578e-01, -1.4597e-01, -3.3568e-01,  1.9056e-01, -9.3735e-02,\n",
      "           2.2943e-01],\n",
      "         [-1.6851e-01, -1.4686e-01, -3.2568e-01,  1.8556e-01, -1.1097e-01,\n",
      "           2.2503e-01],\n",
      "         [-1.5122e-01, -1.4629e-01, -3.0731e-01,  1.7871e-01, -1.3639e-01,\n",
      "           2.1343e-01]],\n",
      "\n",
      "        [[ 6.4525e-01, -1.6214e-01,  1.3720e-02,  4.4732e-01,  3.2534e-02,\n",
      "          -1.0508e-01],\n",
      "         [ 6.1822e-01, -1.3716e-01, -1.7359e-02,  4.3485e-01,  6.8790e-02,\n",
      "          -9.0163e-02],\n",
      "         [ 5.7426e-01, -1.3188e-01, -4.5124e-02,  4.4201e-01,  1.0093e-01,\n",
      "          -6.3760e-02],\n",
      "         [ 5.0128e-01, -1.4995e-01, -9.6107e-02,  4.5546e-01,  1.3267e-01,\n",
      "          -1.2635e-02],\n",
      "         [ 4.3042e-01, -1.7068e-01, -1.5243e-01,  4.7624e-01,  1.7419e-01,\n",
      "           4.0620e-02],\n",
      "         [ 3.6144e-01, -1.9209e-01, -2.0434e-01,  4.9151e-01,  2.0382e-01,\n",
      "           9.0906e-02],\n",
      "         [ 3.1570e-01, -1.9396e-01, -2.3556e-01,  4.9330e-01,  2.1945e-01,\n",
      "           1.1503e-01],\n",
      "         [ 2.7798e-01, -1.8648e-01, -2.5433e-01,  4.8385e-01,  2.1971e-01,\n",
      "           1.2713e-01],\n",
      "         [ 2.5142e-01, -1.7156e-01, -2.6660e-01,  4.7121e-01,  2.1873e-01,\n",
      "           1.2945e-01],\n",
      "         [ 2.3019e-01, -1.6502e-01, -2.7370e-01,  4.6014e-01,  2.1166e-01,\n",
      "           1.3282e-01],\n",
      "         [ 2.1480e-01, -1.6387e-01, -2.7787e-01,  4.5155e-01,  2.0257e-01,\n",
      "           1.3691e-01],\n",
      "         [ 2.0227e-01, -1.6412e-01, -2.8122e-01,  4.4376e-01,  1.9361e-01,\n",
      "           1.4055e-01],\n",
      "         [ 1.9521e-01, -1.6235e-01, -2.8355e-01,  4.3884e-01,  1.8970e-01,\n",
      "           1.4134e-01],\n",
      "         [ 1.9052e-01, -1.6097e-01, -2.8522e-01,  4.3505e-01,  1.8679e-01,\n",
      "           1.4156e-01],\n",
      "         [ 1.8280e-01, -1.6287e-01, -2.8718e-01,  4.2987e-01,  1.7993e-01,\n",
      "           1.4435e-01],\n",
      "         [ 1.7841e-01, -1.6348e-01, -2.8822e-01,  4.2694e-01,  1.7639e-01,\n",
      "           1.4543e-01],\n",
      "         [ 1.7403e-01, -1.6327e-01, -2.8962e-01,  4.2346e-01,  1.7282e-01,\n",
      "           1.4640e-01],\n",
      "         [ 1.7817e-01, -1.6504e-01, -2.8736e-01,  4.2728e-01,  1.7513e-01,\n",
      "           1.4663e-01],\n",
      "         [ 1.8004e-01, -1.6566e-01, -2.8661e-01,  4.2914e-01,  1.7651e-01,\n",
      "           1.4671e-01],\n",
      "         [ 1.8215e-01, -1.6482e-01, -2.8618e-01,  4.3024e-01,  1.7815e-01,\n",
      "           1.4587e-01]],\n",
      "\n",
      "        [[ 4.4112e-01, -1.8030e-01, -1.2446e-01,  4.8199e-01,  8.6323e-02,\n",
      "           8.5146e-02],\n",
      "         [ 3.9244e-01, -2.1852e-01, -1.7820e-01,  4.9711e-01,  1.4616e-01,\n",
      "           1.0443e-01],\n",
      "         [ 3.4535e-01, -2.1185e-01, -2.1760e-01,  4.9471e-01,  1.8894e-01,\n",
      "           1.1258e-01],\n",
      "         [ 3.1482e-01, -1.9777e-01, -2.3963e-01,  4.8887e-01,  2.1018e-01,\n",
      "           1.1623e-01],\n",
      "         [ 2.8618e-01, -1.8564e-01, -2.5431e-01,  4.8064e-01,  2.1687e-01,\n",
      "           1.2157e-01],\n",
      "         [ 2.5442e-01, -1.7480e-01, -2.6703e-01,  4.6755e-01,  2.1288e-01,\n",
      "           1.2844e-01],\n",
      "         [ 2.3856e-01, -1.6264e-01, -2.7284e-01,  4.6148e-01,  2.1560e-01,\n",
      "           1.2812e-01],\n",
      "         [ 2.2637e-01, -1.5527e-01, -2.7690e-01,  4.5536e-01,  2.1456e-01,\n",
      "           1.2827e-01],\n",
      "         [ 2.1579e-01, -1.5299e-01, -2.8002e-01,  4.4966e-01,  2.0984e-01,\n",
      "           1.3061e-01],\n",
      "         [ 2.1232e-01, -1.4828e-01, -2.8176e-01,  4.4666e-01,  2.1029e-01,\n",
      "           1.2873e-01],\n",
      "         [ 2.0961e-01, -1.4670e-01, -2.8270e-01,  4.4481e-01,  2.0947e-01,\n",
      "           1.2859e-01],\n",
      "         [ 2.1146e-01, -1.4326e-01, -2.8238e-01,  4.4615e-01,  2.1358e-01,\n",
      "           1.2612e-01],\n",
      "         [ 2.1062e-01, -1.4170e-01, -2.8285e-01,  4.4548e-01,  2.1421e-01,\n",
      "           1.2580e-01],\n",
      "         [ 2.1130e-01, -1.4084e-01, -2.8269e-01,  4.4586e-01,  2.1542e-01,\n",
      "           1.2510e-01],\n",
      "         [ 2.0771e-01, -1.4584e-01, -2.8290e-01,  4.4456e-01,  2.0984e-01,\n",
      "           1.2899e-01],\n",
      "         [ 2.0260e-01, -1.5039e-01, -2.8379e-01,  4.4171e-01,  2.0286e-01,\n",
      "           1.3296e-01],\n",
      "         [ 1.9692e-01, -1.5409e-01, -2.8488e-01,  4.3810e-01,  1.9598e-01,\n",
      "           1.3619e-01],\n",
      "         [ 1.9290e-01, -1.5517e-01, -2.8600e-01,  4.3503e-01,  1.9158e-01,\n",
      "           1.3785e-01],\n",
      "         [ 1.9006e-01, -1.5701e-01, -2.8636e-01,  4.3322e-01,  1.8807e-01,\n",
      "           1.3947e-01],\n",
      "         [ 1.9527e-01, -1.5288e-01, -2.8557e-01,  4.3607e-01,  1.9433e-01,\n",
      "           1.3574e-01]],\n",
      "\n",
      "        [[-3.5541e-02, -2.3164e-01, -3.1866e-01,  2.6505e-01, -7.5461e-02,\n",
      "           2.2146e-01],\n",
      "         [-1.0208e-01, -2.1016e-01, -3.2724e-01,  2.0986e-01, -1.1532e-01,\n",
      "           2.2017e-01],\n",
      "         [-9.0782e-02, -1.9266e-01, -3.1994e-01,  2.1213e-01, -1.0733e-01,\n",
      "           2.0557e-01],\n",
      "         [-9.0148e-02, -1.7505e-01, -3.1226e-01,  2.1021e-01, -1.0463e-01,\n",
      "           1.9591e-01],\n",
      "         [-9.8352e-02, -1.4513e-01, -3.0209e-01,  1.9160e-01, -1.0864e-01,\n",
      "           1.7733e-01],\n",
      "         [-8.1634e-02, -1.0648e-01, -2.8208e-01,  1.7862e-01, -1.0234e-01,\n",
      "           1.4133e-01],\n",
      "         [-5.2067e-02, -6.7449e-02, -2.5128e-01,  1.6399e-01, -1.0472e-01,\n",
      "           9.8503e-02],\n",
      "         [-2.1434e-03, -2.9439e-02, -2.1075e-01,  1.4726e-01, -1.1386e-01,\n",
      "           4.0811e-02],\n",
      "         [ 5.6691e-02, -1.6996e-03, -1.6494e-01,  1.4082e-01, -1.2570e-01,\n",
      "          -1.1849e-02],\n",
      "         [ 1.0507e-01,  1.3361e-02, -1.2724e-01,  1.3005e-01, -1.4547e-01,\n",
      "          -5.3463e-02],\n",
      "         [ 1.3639e-01,  2.1565e-02, -9.9238e-02,  1.1722e-01, -1.6814e-01,\n",
      "          -8.0589e-02],\n",
      "         [ 1.5576e-01,  2.6393e-02, -8.0262e-02,  1.0689e-01, -1.8504e-01,\n",
      "          -9.7919e-02],\n",
      "         [ 1.6736e-01,  2.7711e-02, -6.8294e-02,  1.0125e-01, -1.9623e-01,\n",
      "          -1.0716e-01],\n",
      "         [ 1.7451e-01,  2.4912e-02, -6.2205e-02,  1.0136e-01, -2.0183e-01,\n",
      "          -1.0948e-01],\n",
      "         [ 1.7744e-01,  2.0911e-02, -6.0504e-02,  1.0244e-01, -2.0512e-01,\n",
      "          -1.0824e-01],\n",
      "         [ 1.7785e-01,  1.7767e-02, -6.0458e-02,  1.0350e-01, -2.0727e-01,\n",
      "          -1.0594e-01],\n",
      "         [ 1.7746e-01,  1.7075e-02, -6.0556e-02,  1.0362e-01, -2.0810e-01,\n",
      "          -1.0509e-01],\n",
      "         [ 1.7802e-01,  1.7019e-02, -5.9821e-02,  1.0239e-01, -2.0954e-01,\n",
      "          -1.0601e-01],\n",
      "         [ 1.7818e-01,  1.9930e-02, -5.8476e-02,  9.9997e-02, -2.0983e-01,\n",
      "          -1.0885e-01],\n",
      "         [ 1.7952e-01,  1.9210e-02, -5.7629e-02,  1.0000e-01, -2.1050e-01,\n",
      "          -1.0931e-01]],\n",
      "\n",
      "        [[-1.6777e-02, -2.8378e-01, -3.0636e-01,  3.1363e-01, -6.0659e-02,\n",
      "           2.6118e-01],\n",
      "         [-9.4732e-02, -2.4382e-01, -3.3111e-01,  2.3193e-01, -1.0308e-01,\n",
      "           2.4658e-01],\n",
      "         [-1.0057e-01, -2.2876e-01, -3.3220e-01,  2.1420e-01, -1.1165e-01,\n",
      "           2.3592e-01],\n",
      "         [-9.5374e-02, -2.3372e-01, -3.2670e-01,  2.0839e-01, -1.2527e-01,\n",
      "           2.3481e-01],\n",
      "         [-8.8823e-02, -2.3850e-01, -3.2099e-01,  2.0350e-01, -1.3875e-01,\n",
      "           2.3306e-01],\n",
      "         [-8.2716e-02, -2.3981e-01, -3.1426e-01,  1.9357e-01, -1.5717e-01,\n",
      "           2.2711e-01],\n",
      "         [-7.0495e-02, -2.4126e-01, -3.0081e-01,  1.7878e-01, -1.8639e-01,\n",
      "           2.1496e-01],\n",
      "         [-4.0449e-02, -2.4683e-01, -2.7008e-01,  1.6140e-01, -2.3752e-01,\n",
      "           1.9349e-01],\n",
      "         [ 2.3610e-02, -2.4678e-01, -2.1086e-01,  1.3883e-01, -3.1595e-01,\n",
      "           1.4918e-01],\n",
      "         [ 9.9199e-02, -2.4600e-01, -1.4115e-01,  1.2788e-01, -3.7875e-01,\n",
      "           1.0407e-01],\n",
      "         [ 1.4582e-01, -2.2123e-01, -9.6754e-02,  1.1681e-01, -3.8819e-01,\n",
      "           6.1786e-02],\n",
      "         [ 1.7198e-01, -1.9887e-01, -7.6960e-02,  1.1196e-01, -3.7617e-01,\n",
      "           3.4282e-02],\n",
      "         [ 1.8848e-01, -1.9417e-01, -6.8135e-02,  1.1345e-01, -3.6992e-01,\n",
      "           2.4233e-02],\n",
      "         [ 1.9242e-01, -1.9808e-01, -6.6794e-02,  1.1742e-01, -3.6801e-01,\n",
      "           2.5291e-02],\n",
      "         [ 1.9343e-01, -1.9995e-01, -6.6390e-02,  1.1837e-01, -3.6819e-01,\n",
      "           2.6110e-02],\n",
      "         [ 1.9475e-01, -2.0312e-01, -6.4460e-02,  1.1804e-01, -3.7150e-01,\n",
      "           2.7128e-02],\n",
      "         [ 1.9949e-01, -1.9876e-01, -6.2860e-02,  1.1669e-01, -3.6772e-01,\n",
      "           2.1422e-02],\n",
      "         [ 2.0005e-01, -2.0059e-01, -6.2846e-02,  1.1811e-01, -3.6786e-01,\n",
      "           2.2735e-02],\n",
      "         [ 2.0619e-01, -1.9861e-01, -5.8679e-02,  1.1433e-01, -3.6928e-01,\n",
      "           1.7595e-02],\n",
      "         [ 2.1467e-01, -1.9514e-01, -5.4832e-02,  1.1252e-01, -3.6597e-01,\n",
      "           1.0362e-02]]], device='cuda:0'), (tensor([[[ 1.4355e-01,  7.3157e-02,  2.4381e-01, -5.7062e-02, -8.8234e-02,\n",
      "          -8.1890e-01, -2.0661e-03,  1.0936e-01],\n",
      "         [ 2.4036e-02,  3.1140e-02,  2.4730e-01,  5.1976e-02,  1.7896e-01,\n",
      "          -8.0178e-01, -3.4870e-02,  2.3666e-01],\n",
      "         [ 9.2375e-02, -9.3913e-02,  1.3000e-01, -1.6158e-02,  1.3607e-01,\n",
      "          -8.0519e-01, -1.3407e-04,  3.3821e-01],\n",
      "         [-3.0236e-02, -3.6125e-02, -1.2155e-01, -5.0207e-02,  1.3495e-01,\n",
      "          -5.0369e-01,  5.6519e-02,  5.2339e-01],\n",
      "         [ 9.2993e-02,  5.8096e-02, -4.5478e-01, -7.0031e-03, -1.7744e-01,\n",
      "           1.8902e-01,  3.7692e-02, -3.5866e-01],\n",
      "         [-1.2117e-01,  7.9728e-02, -1.8769e-02, -1.3057e-01, -1.1782e-01,\n",
      "           1.7488e-01,  6.1004e-02, -4.0322e-01],\n",
      "         [-1.9751e-01,  1.1838e-01,  4.7639e-01,  1.4704e-02, -2.0707e-01,\n",
      "           2.5813e-01, -1.0858e-02, -4.2310e-01],\n",
      "         [-1.6513e-01, -1.5501e-02, -2.4231e-01, -1.1711e-01, -1.7202e-01,\n",
      "           1.5605e-01,  3.9352e-02, -8.8439e-02]],\n",
      "\n",
      "        [[-4.1490e-02, -2.6011e-01, -4.3467e-04,  1.2990e-02,  1.5525e-01,\n",
      "          -2.0018e-01,  5.3712e-02,  4.7088e-01],\n",
      "         [-1.2541e-02, -2.3248e-01, -1.3798e-02,  2.9317e-03,  3.0077e-01,\n",
      "          -2.2560e-01,  5.7703e-02,  4.3423e-01],\n",
      "         [-1.3042e-02, -2.1067e-01, -2.1303e-02, -2.3004e-04,  4.3946e-01,\n",
      "          -2.0731e-01,  8.4655e-02,  1.9529e-01],\n",
      "         [ 3.7207e-04, -2.4379e-01, -4.1743e-02, -1.1777e-02,  5.3492e-01,\n",
      "          -2.6731e-02,  1.1059e-01, -1.6689e-01],\n",
      "         [-4.0812e-02,  7.6629e-01, -2.7627e-03, -4.9842e-02, -3.8651e-01,\n",
      "          -1.3479e-02, -4.8992e-02, -1.1862e-01],\n",
      "         [-3.8234e-02,  7.2341e-01,  6.3881e-03, -5.6831e-02, -2.7117e-01,\n",
      "          -1.9150e-01, -4.1136e-02, -1.2643e-01],\n",
      "         [-1.5456e-02, -3.6294e-01,  4.1601e-02,  4.9590e-02,  1.3260e-02,\n",
      "          -4.8776e-02,  6.3377e-03,  5.6171e-01],\n",
      "         [-3.1391e-02,  7.4719e-01, -1.4107e-02, -5.6622e-02, -3.7818e-01,\n",
      "          -3.3961e-03, -3.8752e-02, -1.2872e-01]],\n",
      "\n",
      "        [[ 1.0461e-01,  1.4496e-02,  3.7368e-01, -4.1091e-01, -1.3005e-02,\n",
      "          -5.0762e-02, -5.2057e-03, -7.0911e-04],\n",
      "         [ 1.0344e-01,  9.5762e-02,  3.8666e-01, -4.1607e-01, -1.3635e-02,\n",
      "          -5.4060e-02, -1.3819e-02, -3.9533e-03],\n",
      "         [ 9.4939e-02,  1.2686e-01,  4.2123e-01, -4.1889e-01, -1.0535e-02,\n",
      "          -4.3641e-02, -1.8642e-02, -3.2148e-03],\n",
      "         [ 2.9943e-01, -3.4118e-01, -5.6306e-01,  4.1816e-01, -1.2353e-02,\n",
      "           6.5070e-02,  1.9658e-02,  1.0625e-03],\n",
      "         [-4.6329e-02, -4.8967e-01,  3.3369e-01,  4.8212e-01,  1.2060e-04,\n",
      "          -5.3316e-02, -2.2805e-02, -5.0766e-03],\n",
      "         [-3.8453e-02, -4.9093e-01,  3.7586e-01,  4.7545e-01, -1.1801e-03,\n",
      "          -4.5532e-02, -2.7066e-02, -5.5630e-03],\n",
      "         [ 2.4378e-01,  3.0438e-01, -3.3684e-01, -1.0569e-01,  4.0801e-04,\n",
      "           5.7141e-02,  8.5074e-02,  7.7525e-03],\n",
      "         [-1.7686e-01,  3.8439e-01, -5.9264e-01,  1.1272e-01,  4.1509e-02,\n",
      "          -6.2473e-02,  4.1380e-02,  5.5231e-03]]], device='cuda:0'), tensor([[[ 5.2470e-01,  1.5692e-01,  1.3693e+00, -1.0298e-01, -1.6534e-01,\n",
      "          -2.1580e+00, -5.2717e-03,  2.2846e-01],\n",
      "         [ 6.3645e-02,  6.4709e-02,  5.7450e-01,  1.4506e-01,  3.2434e-01,\n",
      "          -2.5186e+00, -8.9868e-02,  5.4987e-01],\n",
      "         [ 3.8728e-01, -1.7823e-01,  8.0360e-01, -3.4145e-02,  2.7712e-01,\n",
      "          -2.3483e+00, -2.7621e-04,  7.8373e-01],\n",
      "         [-1.4791e-01, -8.0476e-02, -4.2331e-01, -7.8926e-02,  3.0353e-01,\n",
      "          -1.7192e+00,  8.4277e-02,  1.8840e+00],\n",
      "         [ 1.6104e-01,  1.3226e-01, -9.0014e-01, -1.0003e-02, -4.0897e-01,\n",
      "           2.2358e+00,  5.8939e-02, -8.9055e-01],\n",
      "         [-2.1500e-01,  1.5493e-01, -3.4745e-02, -1.9102e-01, -2.6120e-01,\n",
      "           2.2979e+00,  9.0730e-02, -1.1864e+00],\n",
      "         [-2.5073e-01,  2.4151e-01,  7.9321e-01,  3.0746e-02, -3.9803e-01,\n",
      "           1.5814e+00, -2.6811e-02, -1.7046e+00],\n",
      "         [-2.5668e-01, -3.0407e-02, -4.5618e-01, -1.8578e-01, -4.0129e-01,\n",
      "           2.5049e+00,  7.4418e-02, -1.6859e-01]],\n",
      "\n",
      "        [[-5.4880e-02, -1.9332e+00, -9.7292e-04,  2.3784e-02,  7.9732e-01,\n",
      "          -4.2326e-01,  1.0068e-01,  7.8477e-01],\n",
      "         [-1.7083e-02, -1.7731e+00, -3.3025e-02,  4.8776e-03,  9.8462e-01,\n",
      "          -4.9112e-01,  1.0424e-01,  7.3975e-01],\n",
      "         [-1.6513e-02, -1.6795e+00, -4.7760e-02, -4.4203e-04,  1.3549e+00,\n",
      "          -4.4390e-01,  1.2959e-01,  3.8199e-01],\n",
      "         [ 5.7145e-04, -9.7467e-01, -8.0331e-02, -2.5994e-02,  1.7085e+00,\n",
      "          -5.4238e-02,  1.2743e-01, -5.1021e-01],\n",
      "         [-9.4745e-02,  2.4225e+00, -8.3544e-03, -9.6470e-02, -6.0329e-01,\n",
      "          -2.7073e-02, -1.4055e-01, -3.6145e-01],\n",
      "         [-9.4799e-02,  2.4213e+00,  2.0984e-02, -9.8194e-02, -3.8357e-01,\n",
      "          -4.0704e-01, -1.1267e-01, -3.4667e-01],\n",
      "         [-3.2222e-02, -2.1824e+00,  8.3416e-02,  8.4195e-02,  6.8832e-02,\n",
      "          -9.7250e-02,  1.8496e-02,  8.1244e-01],\n",
      "         [-8.7256e-02,  2.4429e+00, -3.8327e-02, -1.0831e-01, -5.3227e-01,\n",
      "          -6.8600e-03, -9.4249e-02, -3.8801e-01]],\n",
      "\n",
      "        [[ 2.1035e-01,  2.9091e-02,  1.9399e+00, -1.6682e+00, -2.5485e-02,\n",
      "          -9.4876e-02, -7.4918e-03, -1.2157e-03],\n",
      "         [ 2.0120e-01,  1.9893e-01,  1.9134e+00, -1.6758e+00, -2.6522e-02,\n",
      "          -1.0628e-01, -1.9855e-02, -7.3033e-03],\n",
      "         [ 1.6621e-01,  2.7161e-01,  1.8661e+00, -1.7283e+00, -2.0398e-02,\n",
      "          -9.6936e-02, -2.8332e-02, -5.5704e-03],\n",
      "         [ 4.8682e-01, -7.6670e-01, -1.8438e+00,  1.2846e+00, -2.4413e-02,\n",
      "           2.5258e-01,  6.6120e-02,  2.0854e-03],\n",
      "         [-1.4183e-01, -1.5669e+00,  6.7200e-01,  1.7585e+00,  2.5012e-04,\n",
      "          -7.5829e-02, -5.1628e-02, -1.4469e-02],\n",
      "         [-1.1615e-01, -1.5919e+00,  7.9249e-01,  1.6817e+00, -2.4428e-03,\n",
      "          -6.3546e-02, -6.0233e-02, -1.7540e-02],\n",
      "         [ 4.1895e-01,  7.4043e-01, -2.2979e+00, -2.1337e-01,  7.8458e-04,\n",
      "           1.7554e-01,  1.4076e-01,  1.6667e-02],\n",
      "         [-3.7744e-01,  1.1725e+00, -2.0475e+00,  2.3033e-01,  8.0841e-02,\n",
      "          -1.0048e-01,  8.2292e-02,  3.3913e-02]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cpp]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out1 = model_cpp(inputs, hidden)\n",
    "    print(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:21.041320Z",
     "start_time": "2019-02-06T20:06:21.033322Z"
    },
    "hidden": true,
    "tags": [
     "#forward-test-3"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2938e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out1[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:21.328366Z",
     "start_time": "2019-02-06T20:06:21.043318Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[model_cuda]\n",
      "\n",
      "{partial output}\n",
      "(tensor([[[ 2.1202e-01,  2.8098e-01, -1.6853e-01,  1.5387e-01,  1.8006e-01,\n",
      "          -1.8520e-01],\n",
      "         [ 3.6610e-01,  2.3259e-01, -9.6601e-02,  1.8165e-01,  1.6299e-01,\n",
      "          -2.6788e-01],\n",
      "         [ 4.3691e-01,  1.9658e-01, -6.7583e-02,  2.0776e-01,  1.5565e-01,\n",
      "          -2.6871e-01],\n",
      "         [ 4.6849e-01,  1.7438e-01, -4.7811e-02,  2.3025e-01,  1.5583e-01,\n",
      "          -2.6347e-01],\n",
      "         [ 4.6763e-01,  1.6628e-01, -4.6389e-02,  2.3983e-01,  1.6276e-01,\n",
      "          -2.5412e-01],\n",
      "         [ 4.6391e-01,  1.6435e-01, -4.9311e-02,  2.4512e-01,  1.7111e-01,\n",
      "          -2.4879e-01],\n",
      "         [ 4.6622e-01,  1.6598e-01, -4.9184e-02,  2.4759e-01,  1.7508e-01,\n",
      "          -2.4846e-01],\n",
      "         [ 4.5785e-01,  1.6126e-01, -5.4186e-02,  2.4772e-01,  1.7651e-01,\n",
      "          -2.4020e-01],\n",
      "         [ 4.6395e-01,  1.6431e-01, -4.9389e-02,  2.4981e-01,  1.7715e-01,\n",
      "          -2.4493e-01],\n",
      "         [ 4.4696e-01,  1.5937e-01, -5.8403e-02,  2.4697e-01,  1.7707e-01,\n",
      "          -2.3171e-01],\n",
      "         [ 4.3715e-01,  1.5956e-01, -6.4309e-02,  2.4957e-01,  1.8379e-01,\n",
      "          -2.2624e-01],\n",
      "         [ 4.3677e-01,  1.6202e-01, -6.2144e-02,  2.4916e-01,  1.8253e-01,\n",
      "          -2.2797e-01],\n",
      "         [ 4.2525e-01,  1.5950e-01, -6.6306e-02,  2.4665e-01,  1.8143e-01,\n",
      "          -2.2177e-01],\n",
      "         [ 4.1706e-01,  1.6003e-01, -7.0583e-02,  2.4757e-01,  1.8622e-01,\n",
      "          -2.1896e-01],\n",
      "         [ 4.2491e-01,  1.6187e-01, -6.5836e-02,  2.4912e-01,  1.8573e-01,\n",
      "          -2.2387e-01],\n",
      "         [ 4.3065e-01,  1.6309e-01, -6.2393e-02,  2.4811e-01,  1.8275e-01,\n",
      "          -2.2740e-01],\n",
      "         [ 4.3335e-01,  1.6181e-01, -6.1557e-02,  2.4775e-01,  1.8176e-01,\n",
      "          -2.2866e-01],\n",
      "         [ 4.3092e-01,  1.5790e-01, -6.3379e-02,  2.4791e-01,  1.8200e-01,\n",
      "          -2.2544e-01],\n",
      "         [ 4.1507e-01,  1.5316e-01, -7.1929e-02,  2.4764e-01,  1.8675e-01,\n",
      "          -2.1580e-01],\n",
      "         [ 4.0529e-01,  1.5573e-01, -7.9799e-02,  2.5039e-01,  1.9688e-01,\n",
      "          -2.1126e-01]],\n",
      "\n",
      "        [[ 4.3450e-01,  2.5443e-01, -1.3955e-03,  1.9211e-01,  1.0384e-01,\n",
      "          -3.1586e-01],\n",
      "         [ 4.7106e-01,  1.9112e-01, -5.9357e-03,  2.0327e-01,  9.7310e-02,\n",
      "          -2.8643e-01],\n",
      "         [ 4.6110e-01,  1.6241e-01, -2.3523e-02,  2.2683e-01,  1.2757e-01,\n",
      "          -2.5723e-01],\n",
      "         [ 4.5262e-01,  1.4960e-01, -3.8429e-02,  2.4172e-01,  1.5184e-01,\n",
      "          -2.3904e-01],\n",
      "         [ 4.4334e-01,  1.4718e-01, -4.8474e-02,  2.4701e-01,  1.6505e-01,\n",
      "          -2.2908e-01],\n",
      "         [ 4.4253e-01,  1.4830e-01, -5.4296e-02,  2.5204e-01,  1.7610e-01,\n",
      "          -2.2611e-01],\n",
      "         [ 4.2512e-01,  1.4746e-01, -6.6988e-02,  2.5030e-01,  1.8363e-01,\n",
      "          -2.1433e-01],\n",
      "         [ 4.2092e-01,  1.4914e-01, -7.3216e-02,  2.5444e-01,  1.9404e-01,\n",
      "          -2.1190e-01],\n",
      "         [ 4.1656e-01,  1.5006e-01, -7.5993e-02,  2.5420e-01,  1.9658e-01,\n",
      "          -2.1030e-01],\n",
      "         [ 4.0644e-01,  1.5293e-01, -8.0778e-02,  2.5181e-01,  1.9929e-01,\n",
      "          -2.0822e-01],\n",
      "         [ 4.0638e-01,  1.5620e-01, -8.2206e-02,  2.5367e-01,  2.0353e-01,\n",
      "          -2.0951e-01],\n",
      "         [ 4.0470e-01,  1.5822e-01, -8.2856e-02,  2.5214e-01,  2.0315e-01,\n",
      "          -2.1015e-01],\n",
      "         [ 4.0133e-01,  1.6149e-01, -8.4791e-02,  2.5037e-01,  2.0401e-01,\n",
      "          -2.1082e-01],\n",
      "         [ 4.0520e-01,  1.6233e-01, -8.0376e-02,  2.4931e-01,  1.9934e-01,\n",
      "          -2.1437e-01],\n",
      "         [ 4.2600e-01,  1.6695e-01, -6.7824e-02,  2.5110e-01,  1.9308e-01,\n",
      "          -2.2693e-01],\n",
      "         [ 4.3096e-01,  1.6013e-01, -6.2100e-02,  2.4878e-01,  1.8304e-01,\n",
      "          -2.2788e-01],\n",
      "         [ 4.1743e-01,  1.5835e-01, -6.9868e-02,  2.4680e-01,  1.8573e-01,\n",
      "          -2.1987e-01],\n",
      "         [ 4.2830e-01,  1.6132e-01, -6.6729e-02,  2.5165e-01,  1.8941e-01,\n",
      "          -2.2407e-01],\n",
      "         [ 4.4176e-01,  1.6643e-01, -5.9469e-02,  2.5053e-01,  1.8533e-01,\n",
      "          -2.3329e-01],\n",
      "         [ 4.4057e-01,  1.6107e-01, -5.7732e-02,  2.4605e-01,  1.7705e-01,\n",
      "          -2.3085e-01]],\n",
      "\n",
      "        [[ 4.6840e-01,  2.2062e-01,  1.9255e-02,  2.1534e-01,  1.1753e-01,\n",
      "          -3.3529e-01],\n",
      "         [ 4.7425e-01,  1.5995e-01,  5.3547e-04,  2.1358e-01,  9.7841e-02,\n",
      "          -2.7746e-01],\n",
      "         [ 4.4217e-01,  1.4495e-01, -3.0257e-02,  2.3041e-01,  1.3527e-01,\n",
      "          -2.4508e-01],\n",
      "         [ 4.0490e-01,  1.4032e-01, -5.8504e-02,  2.3764e-01,  1.6289e-01,\n",
      "          -2.1888e-01],\n",
      "         [ 4.1153e-01,  1.4055e-01, -6.4384e-02,  2.5259e-01,  1.8178e-01,\n",
      "          -2.1385e-01],\n",
      "         [ 3.8692e-01,  1.5034e-01, -8.0376e-02,  2.4844e-01,  1.9382e-01,\n",
      "          -2.0431e-01],\n",
      "         [ 3.8379e-01,  1.5741e-01, -8.6446e-02,  2.5087e-01,  2.0435e-01,\n",
      "          -2.0494e-01],\n",
      "         [ 4.0043e-01,  1.6608e-01, -7.7077e-02,  2.5046e-01,  1.9979e-01,\n",
      "          -2.1788e-01],\n",
      "         [ 4.1293e-01,  1.6619e-01, -6.7539e-02,  2.4532e-01,  1.8622e-01,\n",
      "          -2.2527e-01],\n",
      "         [ 4.1556e-01,  1.6525e-01, -6.5362e-02,  2.4151e-01,  1.7963e-01,\n",
      "          -2.2576e-01],\n",
      "         [ 4.1441e-01,  1.6806e-01, -6.4037e-02,  2.3894e-01,  1.7777e-01,\n",
      "          -2.2975e-01],\n",
      "         [ 4.2114e-01,  1.6407e-01, -6.3518e-02,  2.4318e-01,  1.7867e-01,\n",
      "          -2.2803e-01],\n",
      "         [ 4.5119e-01,  1.6819e-01, -5.0313e-02,  2.5078e-01,  1.7763e-01,\n",
      "          -2.4110e-01],\n",
      "         [ 4.4709e-01,  1.6515e-01, -5.5112e-02,  2.4663e-01,  1.7469e-01,\n",
      "          -2.3456e-01],\n",
      "         [ 4.5665e-01,  1.6614e-01, -4.6779e-02,  2.4839e-01,  1.7164e-01,\n",
      "          -2.4335e-01],\n",
      "         [ 4.6231e-01,  1.6551e-01, -4.6535e-02,  2.4839e-01,  1.7050e-01,\n",
      "          -2.4199e-01],\n",
      "         [ 4.4855e-01,  1.6192e-01, -5.6937e-02,  2.4671e-01,  1.7550e-01,\n",
      "          -2.3163e-01],\n",
      "         [ 4.5712e-01,  1.6754e-01, -5.3690e-02,  2.4971e-01,  1.8035e-01,\n",
      "          -2.4010e-01],\n",
      "         [ 4.5504e-01,  1.6424e-01, -5.4519e-02,  2.4740e-01,  1.7692e-01,\n",
      "          -2.3724e-01],\n",
      "         [ 4.6516e-01,  1.6862e-01, -4.9356e-02,  2.4876e-01,  1.7779e-01,\n",
      "          -2.4573e-01]],\n",
      "\n",
      "        [[ 4.6592e-01,  1.7700e-01,  2.1524e-02,  2.1369e-01,  1.0126e-01,\n",
      "          -3.3526e-01],\n",
      "         [ 4.9712e-01,  1.0885e-01,  1.6223e-02,  2.2714e-01,  8.4737e-02,\n",
      "          -2.7873e-01],\n",
      "         [ 4.5728e-01,  1.0385e-01, -2.5952e-02,  2.4707e-01,  1.3237e-01,\n",
      "          -2.3642e-01],\n",
      "         [ 4.1873e-01,  1.0406e-01, -5.3965e-02,  2.6444e-01,  1.7135e-01,\n",
      "          -2.1160e-01],\n",
      "         [ 3.6251e-01,  1.1207e-01, -9.7091e-02,  2.7932e-01,  2.2769e-01,\n",
      "          -1.7927e-01],\n",
      "         [ 3.0522e-01,  1.2335e-01, -1.5011e-01,  2.9190e-01,  2.9313e-01,\n",
      "          -1.4795e-01],\n",
      "         [ 2.6539e-01,  1.4026e-01, -1.9653e-01,  2.9591e-01,  3.4193e-01,\n",
      "          -1.2836e-01],\n",
      "         [ 2.4545e-01,  1.3313e-01, -2.2271e-01,  3.0436e-01,  3.5339e-01,\n",
      "          -1.0911e-01],\n",
      "         [ 2.2561e-01,  9.0008e-02, -2.4809e-01,  3.2700e-01,  3.3421e-01,\n",
      "          -6.4810e-02],\n",
      "         [ 1.8656e-01,  1.7022e-02, -2.7849e-01,  3.5507e-01,  2.7972e-01,\n",
      "           4.8411e-03],\n",
      "         [ 1.3452e-01, -4.8022e-02, -3.0187e-01,  3.6369e-01,  2.1270e-01,\n",
      "           7.0425e-02],\n",
      "         [ 5.1746e-02, -8.9411e-02, -3.2117e-01,  3.2713e-01,  1.3077e-01,\n",
      "           1.2596e-01],\n",
      "         [-3.7645e-02, -1.2236e-01, -3.3579e-01,  2.7810e-01,  4.8570e-02,\n",
      "           1.7350e-01],\n",
      "         [-1.0614e-01, -1.3518e-01, -3.4256e-01,  2.4007e-01, -6.4321e-03,\n",
      "           2.0228e-01],\n",
      "         [-1.4052e-01, -1.4439e-01, -3.4574e-01,  2.1965e-01, -3.9777e-02,\n",
      "           2.1868e-01],\n",
      "         [-1.6744e-01, -1.4128e-01, -3.4460e-01,  2.0353e-01, -6.2078e-02,\n",
      "           2.2615e-01],\n",
      "         [-1.7245e-01, -1.4517e-01, -3.4148e-01,  1.9754e-01, -7.7335e-02,\n",
      "           2.2920e-01],\n",
      "         [-1.7578e-01, -1.4597e-01, -3.3568e-01,  1.9056e-01, -9.3735e-02,\n",
      "           2.2943e-01],\n",
      "         [-1.6851e-01, -1.4686e-01, -3.2568e-01,  1.8556e-01, -1.1097e-01,\n",
      "           2.2503e-01],\n",
      "         [-1.5122e-01, -1.4629e-01, -3.0731e-01,  1.7871e-01, -1.3639e-01,\n",
      "           2.1343e-01]],\n",
      "\n",
      "        [[ 6.4525e-01, -1.6214e-01,  1.3720e-02,  4.4733e-01,  3.2534e-02,\n",
      "          -1.0508e-01],\n",
      "         [ 6.1822e-01, -1.3716e-01, -1.7359e-02,  4.3485e-01,  6.8790e-02,\n",
      "          -9.0162e-02],\n",
      "         [ 5.7426e-01, -1.3188e-01, -4.5124e-02,  4.4201e-01,  1.0093e-01,\n",
      "          -6.3760e-02],\n",
      "         [ 5.0128e-01, -1.4995e-01, -9.6107e-02,  4.5546e-01,  1.3267e-01,\n",
      "          -1.2635e-02],\n",
      "         [ 4.3042e-01, -1.7068e-01, -1.5243e-01,  4.7624e-01,  1.7419e-01,\n",
      "           4.0620e-02],\n",
      "         [ 3.6144e-01, -1.9209e-01, -2.0434e-01,  4.9151e-01,  2.0382e-01,\n",
      "           9.0906e-02],\n",
      "         [ 3.1570e-01, -1.9396e-01, -2.3556e-01,  4.9330e-01,  2.1945e-01,\n",
      "           1.1503e-01],\n",
      "         [ 2.7798e-01, -1.8648e-01, -2.5433e-01,  4.8385e-01,  2.1971e-01,\n",
      "           1.2713e-01],\n",
      "         [ 2.5142e-01, -1.7156e-01, -2.6660e-01,  4.7121e-01,  2.1873e-01,\n",
      "           1.2945e-01],\n",
      "         [ 2.3019e-01, -1.6502e-01, -2.7370e-01,  4.6014e-01,  2.1166e-01,\n",
      "           1.3282e-01],\n",
      "         [ 2.1480e-01, -1.6387e-01, -2.7787e-01,  4.5155e-01,  2.0257e-01,\n",
      "           1.3691e-01],\n",
      "         [ 2.0227e-01, -1.6412e-01, -2.8122e-01,  4.4376e-01,  1.9361e-01,\n",
      "           1.4055e-01],\n",
      "         [ 1.9521e-01, -1.6235e-01, -2.8355e-01,  4.3884e-01,  1.8970e-01,\n",
      "           1.4134e-01],\n",
      "         [ 1.9052e-01, -1.6097e-01, -2.8522e-01,  4.3505e-01,  1.8679e-01,\n",
      "           1.4156e-01],\n",
      "         [ 1.8280e-01, -1.6287e-01, -2.8718e-01,  4.2987e-01,  1.7993e-01,\n",
      "           1.4435e-01],\n",
      "         [ 1.7841e-01, -1.6348e-01, -2.8822e-01,  4.2694e-01,  1.7639e-01,\n",
      "           1.4543e-01],\n",
      "         [ 1.7403e-01, -1.6327e-01, -2.8962e-01,  4.2346e-01,  1.7282e-01,\n",
      "           1.4640e-01],\n",
      "         [ 1.7817e-01, -1.6504e-01, -2.8736e-01,  4.2728e-01,  1.7513e-01,\n",
      "           1.4663e-01],\n",
      "         [ 1.8004e-01, -1.6566e-01, -2.8661e-01,  4.2914e-01,  1.7651e-01,\n",
      "           1.4671e-01],\n",
      "         [ 1.8215e-01, -1.6482e-01, -2.8618e-01,  4.3024e-01,  1.7816e-01,\n",
      "           1.4587e-01]],\n",
      "\n",
      "        [[ 4.4112e-01, -1.8030e-01, -1.2446e-01,  4.8199e-01,  8.6323e-02,\n",
      "           8.5147e-02],\n",
      "         [ 3.9244e-01, -2.1852e-01, -1.7820e-01,  4.9711e-01,  1.4616e-01,\n",
      "           1.0443e-01],\n",
      "         [ 3.4535e-01, -2.1185e-01, -2.1760e-01,  4.9471e-01,  1.8894e-01,\n",
      "           1.1258e-01],\n",
      "         [ 3.1482e-01, -1.9777e-01, -2.3963e-01,  4.8887e-01,  2.1018e-01,\n",
      "           1.1623e-01],\n",
      "         [ 2.8618e-01, -1.8564e-01, -2.5431e-01,  4.8064e-01,  2.1687e-01,\n",
      "           1.2157e-01],\n",
      "         [ 2.5442e-01, -1.7480e-01, -2.6703e-01,  4.6755e-01,  2.1288e-01,\n",
      "           1.2844e-01],\n",
      "         [ 2.3856e-01, -1.6264e-01, -2.7284e-01,  4.6148e-01,  2.1560e-01,\n",
      "           1.2812e-01],\n",
      "         [ 2.2637e-01, -1.5527e-01, -2.7690e-01,  4.5536e-01,  2.1456e-01,\n",
      "           1.2827e-01],\n",
      "         [ 2.1579e-01, -1.5299e-01, -2.8002e-01,  4.4966e-01,  2.0984e-01,\n",
      "           1.3061e-01],\n",
      "         [ 2.1232e-01, -1.4828e-01, -2.8176e-01,  4.4666e-01,  2.1029e-01,\n",
      "           1.2873e-01],\n",
      "         [ 2.0961e-01, -1.4670e-01, -2.8270e-01,  4.4481e-01,  2.0947e-01,\n",
      "           1.2859e-01],\n",
      "         [ 2.1146e-01, -1.4326e-01, -2.8238e-01,  4.4615e-01,  2.1358e-01,\n",
      "           1.2612e-01],\n",
      "         [ 2.1062e-01, -1.4170e-01, -2.8285e-01,  4.4548e-01,  2.1421e-01,\n",
      "           1.2580e-01],\n",
      "         [ 2.1130e-01, -1.4084e-01, -2.8269e-01,  4.4586e-01,  2.1542e-01,\n",
      "           1.2510e-01],\n",
      "         [ 2.0771e-01, -1.4584e-01, -2.8290e-01,  4.4456e-01,  2.0984e-01,\n",
      "           1.2899e-01],\n",
      "         [ 2.0260e-01, -1.5039e-01, -2.8379e-01,  4.4171e-01,  2.0286e-01,\n",
      "           1.3296e-01],\n",
      "         [ 1.9692e-01, -1.5409e-01, -2.8488e-01,  4.3810e-01,  1.9598e-01,\n",
      "           1.3619e-01],\n",
      "         [ 1.9290e-01, -1.5517e-01, -2.8600e-01,  4.3503e-01,  1.9158e-01,\n",
      "           1.3785e-01],\n",
      "         [ 1.9006e-01, -1.5701e-01, -2.8636e-01,  4.3322e-01,  1.8807e-01,\n",
      "           1.3947e-01],\n",
      "         [ 1.9527e-01, -1.5288e-01, -2.8557e-01,  4.3607e-01,  1.9433e-01,\n",
      "           1.3574e-01]],\n",
      "\n",
      "        [[-3.5541e-02, -2.3164e-01, -3.1866e-01,  2.6505e-01, -7.5461e-02,\n",
      "           2.2146e-01],\n",
      "         [-1.0208e-01, -2.1016e-01, -3.2724e-01,  2.0986e-01, -1.1532e-01,\n",
      "           2.2017e-01],\n",
      "         [-9.0782e-02, -1.9266e-01, -3.1994e-01,  2.1213e-01, -1.0733e-01,\n",
      "           2.0557e-01],\n",
      "         [-9.0149e-02, -1.7505e-01, -3.1226e-01,  2.1021e-01, -1.0462e-01,\n",
      "           1.9591e-01],\n",
      "         [-9.8352e-02, -1.4513e-01, -3.0209e-01,  1.9160e-01, -1.0864e-01,\n",
      "           1.7733e-01],\n",
      "         [-8.1634e-02, -1.0648e-01, -2.8208e-01,  1.7862e-01, -1.0234e-01,\n",
      "           1.4133e-01],\n",
      "         [-5.2067e-02, -6.7449e-02, -2.5128e-01,  1.6399e-01, -1.0472e-01,\n",
      "           9.8503e-02],\n",
      "         [-2.1432e-03, -2.9439e-02, -2.1075e-01,  1.4726e-01, -1.1386e-01,\n",
      "           4.0810e-02],\n",
      "         [ 5.6691e-02, -1.6995e-03, -1.6494e-01,  1.4082e-01, -1.2570e-01,\n",
      "          -1.1849e-02],\n",
      "         [ 1.0507e-01,  1.3362e-02, -1.2724e-01,  1.3005e-01, -1.4547e-01,\n",
      "          -5.3463e-02],\n",
      "         [ 1.3639e-01,  2.1565e-02, -9.9238e-02,  1.1722e-01, -1.6814e-01,\n",
      "          -8.0590e-02],\n",
      "         [ 1.5576e-01,  2.6393e-02, -8.0262e-02,  1.0689e-01, -1.8504e-01,\n",
      "          -9.7919e-02],\n",
      "         [ 1.6736e-01,  2.7711e-02, -6.8294e-02,  1.0125e-01, -1.9623e-01,\n",
      "          -1.0716e-01],\n",
      "         [ 1.7451e-01,  2.4912e-02, -6.2205e-02,  1.0136e-01, -2.0183e-01,\n",
      "          -1.0948e-01],\n",
      "         [ 1.7744e-01,  2.0911e-02, -6.0504e-02,  1.0244e-01, -2.0512e-01,\n",
      "          -1.0824e-01],\n",
      "         [ 1.7785e-01,  1.7767e-02, -6.0458e-02,  1.0350e-01, -2.0727e-01,\n",
      "          -1.0594e-01],\n",
      "         [ 1.7746e-01,  1.7075e-02, -6.0556e-02,  1.0362e-01, -2.0810e-01,\n",
      "          -1.0509e-01],\n",
      "         [ 1.7802e-01,  1.7019e-02, -5.9821e-02,  1.0239e-01, -2.0954e-01,\n",
      "          -1.0601e-01],\n",
      "         [ 1.7818e-01,  1.9930e-02, -5.8476e-02,  9.9997e-02, -2.0983e-01,\n",
      "          -1.0885e-01],\n",
      "         [ 1.7952e-01,  1.9210e-02, -5.7629e-02,  1.0000e-01, -2.1050e-01,\n",
      "          -1.0931e-01]],\n",
      "\n",
      "        [[-1.6777e-02, -2.8378e-01, -3.0636e-01,  3.1363e-01, -6.0659e-02,\n",
      "           2.6118e-01],\n",
      "         [-9.4732e-02, -2.4382e-01, -3.3111e-01,  2.3193e-01, -1.0308e-01,\n",
      "           2.4658e-01],\n",
      "         [-1.0057e-01, -2.2876e-01, -3.3220e-01,  2.1420e-01, -1.1165e-01,\n",
      "           2.3592e-01],\n",
      "         [-9.5374e-02, -2.3372e-01, -3.2670e-01,  2.0839e-01, -1.2527e-01,\n",
      "           2.3481e-01],\n",
      "         [-8.8823e-02, -2.3850e-01, -3.2099e-01,  2.0350e-01, -1.3875e-01,\n",
      "           2.3306e-01],\n",
      "         [-8.2716e-02, -2.3981e-01, -3.1426e-01,  1.9357e-01, -1.5717e-01,\n",
      "           2.2711e-01],\n",
      "         [-7.0494e-02, -2.4126e-01, -3.0081e-01,  1.7878e-01, -1.8639e-01,\n",
      "           2.1496e-01],\n",
      "         [-4.0449e-02, -2.4683e-01, -2.7008e-01,  1.6140e-01, -2.3752e-01,\n",
      "           1.9349e-01],\n",
      "         [ 2.3610e-02, -2.4678e-01, -2.1086e-01,  1.3883e-01, -3.1595e-01,\n",
      "           1.4918e-01],\n",
      "         [ 9.9199e-02, -2.4600e-01, -1.4115e-01,  1.2788e-01, -3.7875e-01,\n",
      "           1.0407e-01],\n",
      "         [ 1.4582e-01, -2.2123e-01, -9.6754e-02,  1.1681e-01, -3.8819e-01,\n",
      "           6.1786e-02],\n",
      "         [ 1.7198e-01, -1.9887e-01, -7.6960e-02,  1.1196e-01, -3.7617e-01,\n",
      "           3.4282e-02],\n",
      "         [ 1.8848e-01, -1.9417e-01, -6.8135e-02,  1.1345e-01, -3.6992e-01,\n",
      "           2.4233e-02],\n",
      "         [ 1.9242e-01, -1.9808e-01, -6.6794e-02,  1.1742e-01, -3.6801e-01,\n",
      "           2.5291e-02],\n",
      "         [ 1.9343e-01, -1.9995e-01, -6.6390e-02,  1.1837e-01, -3.6819e-01,\n",
      "           2.6110e-02],\n",
      "         [ 1.9475e-01, -2.0312e-01, -6.4460e-02,  1.1804e-01, -3.7150e-01,\n",
      "           2.7128e-02],\n",
      "         [ 1.9949e-01, -1.9876e-01, -6.2860e-02,  1.1669e-01, -3.6772e-01,\n",
      "           2.1422e-02],\n",
      "         [ 2.0005e-01, -2.0059e-01, -6.2846e-02,  1.1811e-01, -3.6786e-01,\n",
      "           2.2735e-02],\n",
      "         [ 2.0619e-01, -1.9861e-01, -5.8679e-02,  1.1433e-01, -3.6928e-01,\n",
      "           1.7595e-02],\n",
      "         [ 2.1467e-01, -1.9514e-01, -5.4832e-02,  1.1252e-01, -3.6597e-01,\n",
      "           1.0362e-02]]], device='cuda:0'), (tensor([[[ 1.4355e-01,  7.3157e-02,  2.4381e-01, -5.7062e-02, -8.8234e-02,\n",
      "          -8.1890e-01, -2.0661e-03,  1.0936e-01],\n",
      "         [ 2.4036e-02,  3.1140e-02,  2.4730e-01,  5.1976e-02,  1.7896e-01,\n",
      "          -8.0178e-01, -3.4870e-02,  2.3666e-01],\n",
      "         [ 9.2375e-02, -9.3913e-02,  1.3000e-01, -1.6158e-02,  1.3607e-01,\n",
      "          -8.0519e-01, -1.3405e-04,  3.3821e-01],\n",
      "         [-3.0236e-02, -3.6125e-02, -1.2155e-01, -5.0207e-02,  1.3495e-01,\n",
      "          -5.0369e-01,  5.6519e-02,  5.2339e-01],\n",
      "         [ 9.2993e-02,  5.8096e-02, -4.5478e-01, -7.0031e-03, -1.7744e-01,\n",
      "           1.8902e-01,  3.7692e-02, -3.5866e-01],\n",
      "         [-1.2117e-01,  7.9728e-02, -1.8769e-02, -1.3057e-01, -1.1782e-01,\n",
      "           1.7488e-01,  6.1004e-02, -4.0322e-01],\n",
      "         [-1.9751e-01,  1.1838e-01,  4.7639e-01,  1.4704e-02, -2.0707e-01,\n",
      "           2.5813e-01, -1.0858e-02, -4.2310e-01],\n",
      "         [-1.6513e-01, -1.5501e-02, -2.4231e-01, -1.1711e-01, -1.7202e-01,\n",
      "           1.5605e-01,  3.9352e-02, -8.8439e-02]],\n",
      "\n",
      "        [[-4.1490e-02, -2.6011e-01, -4.3466e-04,  1.2991e-02,  1.5525e-01,\n",
      "          -2.0018e-01,  5.3712e-02,  4.7088e-01],\n",
      "         [-1.2541e-02, -2.3248e-01, -1.3798e-02,  2.9317e-03,  3.0077e-01,\n",
      "          -2.2560e-01,  5.7703e-02,  4.3423e-01],\n",
      "         [-1.3042e-02, -2.1067e-01, -2.1303e-02, -2.3005e-04,  4.3946e-01,\n",
      "          -2.0731e-01,  8.4655e-02,  1.9529e-01],\n",
      "         [ 3.7206e-04, -2.4379e-01, -4.1743e-02, -1.1777e-02,  5.3492e-01,\n",
      "          -2.6731e-02,  1.1059e-01, -1.6689e-01],\n",
      "         [-4.0812e-02,  7.6629e-01, -2.7627e-03, -4.9842e-02, -3.8651e-01,\n",
      "          -1.3479e-02, -4.8992e-02, -1.1862e-01],\n",
      "         [-3.8234e-02,  7.2341e-01,  6.3881e-03, -5.6831e-02, -2.7117e-01,\n",
      "          -1.9150e-01, -4.1136e-02, -1.2643e-01],\n",
      "         [-1.5456e-02, -3.6294e-01,  4.1601e-02,  4.9590e-02,  1.3260e-02,\n",
      "          -4.8776e-02,  6.3377e-03,  5.6171e-01],\n",
      "         [-3.1391e-02,  7.4719e-01, -1.4107e-02, -5.6622e-02, -3.7818e-01,\n",
      "          -3.3962e-03, -3.8752e-02, -1.2872e-01]],\n",
      "\n",
      "        [[ 1.0461e-01,  1.4496e-02,  3.7368e-01, -4.1091e-01, -1.3006e-02,\n",
      "          -5.0762e-02, -5.2056e-03, -7.0911e-04],\n",
      "         [ 1.0344e-01,  9.5762e-02,  3.8666e-01, -4.1607e-01, -1.3635e-02,\n",
      "          -5.4060e-02, -1.3819e-02, -3.9533e-03],\n",
      "         [ 9.4939e-02,  1.2686e-01,  4.2123e-01, -4.1889e-01, -1.0535e-02,\n",
      "          -4.3641e-02, -1.8642e-02, -3.2148e-03],\n",
      "         [ 2.9943e-01, -3.4118e-01, -5.6306e-01,  4.1816e-01, -1.2353e-02,\n",
      "           6.5070e-02,  1.9658e-02,  1.0625e-03],\n",
      "         [-4.6329e-02, -4.8967e-01,  3.3369e-01,  4.8212e-01,  1.2060e-04,\n",
      "          -5.3316e-02, -2.2805e-02, -5.0766e-03],\n",
      "         [-3.8453e-02, -4.9093e-01,  3.7586e-01,  4.7545e-01, -1.1801e-03,\n",
      "          -4.5532e-02, -2.7066e-02, -5.5630e-03],\n",
      "         [ 2.4378e-01,  3.0438e-01, -3.3684e-01, -1.0569e-01,  4.0801e-04,\n",
      "           5.7141e-02,  8.5074e-02,  7.7525e-03],\n",
      "         [-1.7686e-01,  3.8439e-01, -5.9264e-01,  1.1272e-01,  4.1509e-02,\n",
      "          -6.2473e-02,  4.1380e-02,  5.5231e-03]]], device='cuda:0'), tensor([[[ 5.2470e-01,  1.5692e-01,  1.3693e+00, -1.0298e-01, -1.6534e-01,\n",
      "          -2.1580e+00, -5.2717e-03,  2.2846e-01],\n",
      "         [ 6.3645e-02,  6.4709e-02,  5.7450e-01,  1.4506e-01,  3.2434e-01,\n",
      "          -2.5186e+00, -8.9868e-02,  5.4987e-01],\n",
      "         [ 3.8728e-01, -1.7823e-01,  8.0360e-01, -3.4145e-02,  2.7712e-01,\n",
      "          -2.3483e+00, -2.7618e-04,  7.8373e-01],\n",
      "         [-1.4791e-01, -8.0476e-02, -4.2331e-01, -7.8926e-02,  3.0353e-01,\n",
      "          -1.7192e+00,  8.4277e-02,  1.8840e+00],\n",
      "         [ 1.6104e-01,  1.3226e-01, -9.0014e-01, -1.0003e-02, -4.0897e-01,\n",
      "           2.2358e+00,  5.8939e-02, -8.9055e-01],\n",
      "         [-2.1500e-01,  1.5493e-01, -3.4745e-02, -1.9102e-01, -2.6120e-01,\n",
      "           2.2979e+00,  9.0730e-02, -1.1864e+00],\n",
      "         [-2.5073e-01,  2.4151e-01,  7.9321e-01,  3.0746e-02, -3.9803e-01,\n",
      "           1.5814e+00, -2.6811e-02, -1.7046e+00],\n",
      "         [-2.5668e-01, -3.0407e-02, -4.5618e-01, -1.8578e-01, -4.0129e-01,\n",
      "           2.5049e+00,  7.4418e-02, -1.6859e-01]],\n",
      "\n",
      "        [[-5.4880e-02, -1.9332e+00, -9.7291e-04,  2.3784e-02,  7.9732e-01,\n",
      "          -4.2326e-01,  1.0068e-01,  7.8477e-01],\n",
      "         [-1.7083e-02, -1.7731e+00, -3.3025e-02,  4.8776e-03,  9.8462e-01,\n",
      "          -4.9112e-01,  1.0424e-01,  7.3975e-01],\n",
      "         [-1.6513e-02, -1.6795e+00, -4.7760e-02, -4.4205e-04,  1.3549e+00,\n",
      "          -4.4390e-01,  1.2959e-01,  3.8199e-01],\n",
      "         [ 5.7144e-04, -9.7467e-01, -8.0331e-02, -2.5994e-02,  1.7085e+00,\n",
      "          -5.4238e-02,  1.2743e-01, -5.1021e-01],\n",
      "         [-9.4745e-02,  2.4225e+00, -8.3545e-03, -9.6470e-02, -6.0329e-01,\n",
      "          -2.7073e-02, -1.4055e-01, -3.6145e-01],\n",
      "         [-9.4799e-02,  2.4213e+00,  2.0984e-02, -9.8194e-02, -3.8357e-01,\n",
      "          -4.0704e-01, -1.1267e-01, -3.4667e-01],\n",
      "         [-3.2222e-02, -2.1824e+00,  8.3416e-02,  8.4195e-02,  6.8832e-02,\n",
      "          -9.7250e-02,  1.8496e-02,  8.1244e-01],\n",
      "         [-8.7256e-02,  2.4429e+00, -3.8327e-02, -1.0831e-01, -5.3227e-01,\n",
      "          -6.8603e-03, -9.4249e-02, -3.8801e-01]],\n",
      "\n",
      "        [[ 2.1035e-01,  2.9091e-02,  1.9399e+00, -1.6682e+00, -2.5485e-02,\n",
      "          -9.4876e-02, -7.4918e-03, -1.2157e-03],\n",
      "         [ 2.0120e-01,  1.9893e-01,  1.9134e+00, -1.6758e+00, -2.6522e-02,\n",
      "          -1.0628e-01, -1.9855e-02, -7.3033e-03],\n",
      "         [ 1.6621e-01,  2.7161e-01,  1.8661e+00, -1.7283e+00, -2.0398e-02,\n",
      "          -9.6936e-02, -2.8332e-02, -5.5704e-03],\n",
      "         [ 4.8682e-01, -7.6670e-01, -1.8438e+00,  1.2846e+00, -2.4413e-02,\n",
      "           2.5258e-01,  6.6120e-02,  2.0854e-03],\n",
      "         [-1.4183e-01, -1.5669e+00,  6.7200e-01,  1.7585e+00,  2.5013e-04,\n",
      "          -7.5829e-02, -5.1628e-02, -1.4469e-02],\n",
      "         [-1.1615e-01, -1.5919e+00,  7.9249e-01,  1.6817e+00, -2.4428e-03,\n",
      "          -6.3546e-02, -6.0233e-02, -1.7540e-02],\n",
      "         [ 4.1895e-01,  7.4043e-01, -2.2979e+00, -2.1337e-01,  7.8457e-04,\n",
      "           1.7554e-01,  1.4076e-01,  1.6667e-02],\n",
      "         [-3.7744e-01,  1.1725e+00, -2.0475e+00,  2.3033e-01,  8.0841e-02,\n",
      "          -1.0048e-01,  8.2292e-02,  3.3913e-02]]], device='cuda:0')))\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(\"[model_cuda]\")\n",
    "    print(\"\\n{partial output}\")\n",
    "    out2 = model_cuda(inputs, hidden)\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:21.339349Z",
     "start_time": "2019-02-06T20:06:21.330332Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4626e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(out0[0].sub(out2[0]).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Backward Gradients\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:32.298879Z",
     "start_time": "2019-02-06T20:06:31.359872Z"
    },
    "hidden": true,
    "scrolled": false,
    "tags": [
     "#backward-test",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(1.8188, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True), torch.zeros(n_layers, batch_size, hidden_size, device=device, requires_grad=True))\n",
    "\n",
    "inputs, targets = next(iter(fake_loader))\n",
    "inputs = inputs.to(device)\n",
    "inputs.requires_grad_()\n",
    "targets = targets.to(device)\n",
    "\n",
    "inputs_grads = []\n",
    "hidden_grads = []\n",
    "for model in models:\n",
    "    model.train()\n",
    "#     model.eval()\n",
    "    model.zero_grad()\n",
    "    loss = criterion(model(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1))\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    inputs_grads.append(inputs.grad.clone())\n",
    "    inputs.grad.zero_()\n",
    "    hidden_grads.append((hidden[0].grad.clone(), hidden[1].grad.clone()))\n",
    "    hidden[0].grad.zero_()\n",
    "    hidden[1].grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:33.140419Z",
     "start_time": "2019-02-06T20:06:32.896389Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_torch\n",
      "tensor([[[-2.3392e-03, -2.0866e-03,  4.1625e-03,  1.3977e-03, -6.6969e-04],\n",
      "         [ 3.0949e-06, -6.4528e-05, -4.0021e-05, -2.5677e-05, -4.5529e-05],\n",
      "         [-9.9979e-06, -4.5025e-05, -3.8840e-05, -9.1775e-06, -3.5822e-05],\n",
      "         [-1.3572e-05,  3.8747e-06, -3.8844e-05,  2.1861e-05, -4.7407e-05],\n",
      "         [-8.0598e-06, -1.4133e-05, -2.3156e-05,  1.3458e-05, -2.8517e-05],\n",
      "         [-1.5293e-05, -1.5984e-05, -4.8014e-05,  2.4379e-05, -3.9248e-05],\n",
      "         [ 6.6737e-06,  1.6129e-05, -6.1013e-05,  2.5314e-05, -2.6347e-05],\n",
      "         [ 6.0097e-06, -8.5343e-06, -1.9613e-05, -3.6052e-06, -2.2111e-05],\n",
      "         [ 6.9568e-06, -1.2979e-05, -3.1409e-05,  8.0041e-06, -2.7936e-05],\n",
      "         [ 2.1220e-05,  2.2263e-05, -7.3463e-06, -6.5337e-06, -3.5929e-05],\n",
      "         [ 1.8278e-05,  2.1283e-05, -1.6896e-05,  7.5421e-06, -1.5575e-05],\n",
      "         [ 3.8402e-05,  4.7894e-05,  1.6105e-05,  2.6976e-05,  2.1125e-05],\n",
      "         [ 9.9178e-06,  8.8279e-06, -1.7362e-05, -1.7223e-06, -7.8249e-06],\n",
      "         [ 8.0479e-06, -5.5115e-06, -1.1771e-05, -2.4512e-05, -5.5032e-06],\n",
      "         [ 1.6801e-05,  5.5495e-06, -2.1773e-05,  1.4832e-05, -8.5240e-06],\n",
      "         [ 1.5035e-05,  1.4424e-05, -2.3664e-05,  2.7109e-06, -9.2482e-06],\n",
      "         [-6.3830e-06, -7.7751e-07, -1.1653e-05,  9.8675e-07, -1.1835e-05],\n",
      "         [-2.5869e-06, -2.8699e-06, -4.1706e-06, -2.0002e-06, -2.4590e-06],\n",
      "         [ 1.0125e-05, -2.0693e-06, -8.9935e-06, -4.9151e-06,  5.6822e-07],\n",
      "         [ 4.1514e-07,  1.1545e-07, -1.7567e-06, -1.2400e-06, -1.4115e-06]],\n",
      "\n",
      "        [[ 3.6216e-04, -1.2591e-04, -3.4214e-05,  3.2623e-05, -2.6589e-04],\n",
      "         [ 5.3558e-05, -2.6146e-05,  7.1672e-05, -4.2250e-05,  3.8352e-05],\n",
      "         [ 4.0959e-06, -5.6118e-06,  2.1940e-05, -1.3798e-05,  1.3270e-05],\n",
      "         [ 9.3758e-06,  1.0194e-06,  3.3508e-05, -1.6173e-05,  1.1854e-05],\n",
      "         [ 4.3960e-06,  2.6241e-06,  2.2245e-05, -7.3918e-06,  1.9262e-06],\n",
      "         [ 3.5406e-05,  4.2495e-06,  1.2088e-05, -2.6229e-05,  8.7411e-06],\n",
      "         [ 2.7299e-05,  6.3413e-05,  1.5287e-04,  4.2796e-05,  5.3973e-05],\n",
      "         [ 3.5799e-05,  9.4383e-05,  1.8922e-04,  7.1046e-05,  7.6462e-05],\n",
      "         [ 1.6741e-05,  4.4129e-06,  1.8721e-05,  5.6250e-06, -1.7219e-06],\n",
      "         [ 5.3465e-06, -1.7291e-05, -1.0320e-05,  2.5344e-06,  1.2081e-06],\n",
      "         [-2.7839e-06, -3.4675e-06,  1.7255e-05,  3.7039e-06,  1.5067e-05],\n",
      "         [ 2.5432e-05,  3.5282e-05,  3.0678e-05,  3.3708e-05,  1.0224e-05],\n",
      "         [ 2.0974e-06,  8.1348e-07,  4.2058e-06,  1.9381e-06, -1.3289e-07],\n",
      "         [-1.8332e-05, -1.7638e-05, -6.2191e-06, -1.1145e-05, -1.4741e-05],\n",
      "         [-1.1790e-05,  4.1792e-07,  8.5721e-06, -2.3138e-06,  5.0313e-06],\n",
      "         [-1.4579e-05, -9.3607e-06, -3.8186e-05, -3.3165e-05, -2.7052e-05],\n",
      "         [-7.4170e-06,  1.3721e-05,  7.8955e-06, -1.7461e-05, -5.3853e-06],\n",
      "         [-1.1033e-05,  1.6862e-05,  3.8620e-05,  1.2925e-05,  6.4215e-06],\n",
      "         [-8.0691e-06, -2.5828e-06,  2.2202e-05,  1.7181e-05,  2.8541e-08],\n",
      "         [ 6.8577e-06,  1.1428e-05,  1.7558e-05,  1.7058e-05, -1.4939e-06]],\n",
      "\n",
      "        [[-1.3986e-04,  1.0489e-04, -6.3481e-04,  2.0674e-04, -2.5618e-04],\n",
      "         [-2.4054e-04, -1.5231e-04, -4.5791e-04,  8.5643e-05, -1.6192e-04],\n",
      "         [-3.1214e-05, -3.7849e-05, -1.6644e-04,  9.8265e-05, -1.2356e-04],\n",
      "         [-3.8048e-05, -1.4877e-05, -4.4710e-05,  1.8178e-05,  7.7639e-08],\n",
      "         [-4.0256e-05, -1.3709e-05, -7.2727e-05,  1.3682e-05, -9.0629e-06],\n",
      "         [-7.7089e-05,  6.0412e-06, -6.1820e-05,  9.2688e-05,  1.8379e-06],\n",
      "         [-6.4067e-05,  1.9810e-05, -1.4713e-05,  7.4725e-05,  2.9619e-05],\n",
      "         [-1.0907e-05,  2.2324e-04,  1.6261e-04,  7.6922e-05,  8.8309e-05],\n",
      "         [-1.1706e-05,  8.6947e-05,  3.1238e-05,  3.7810e-05,  2.2329e-05],\n",
      "         [ 5.2517e-06,  3.6641e-05, -1.1491e-05, -5.4288e-06,  2.8928e-05],\n",
      "         [-9.2090e-06,  7.0892e-06, -6.3724e-05, -3.9634e-05,  8.1281e-06],\n",
      "         [-1.7957e-05,  2.4004e-06, -3.2209e-05,  1.7014e-05,  2.7710e-05],\n",
      "         [-2.3463e-05, -2.8554e-05, -2.5340e-05,  8.1619e-06,  3.8452e-06],\n",
      "         [-2.0498e-05, -4.6591e-05, -8.8161e-05, -1.2669e-04,  5.4401e-05],\n",
      "         [-2.1529e-05, -2.2201e-05, -3.4177e-05, -7.5269e-06, -1.3445e-05],\n",
      "         [-1.4675e-06, -4.3309e-06, -1.1557e-05, -8.1615e-06,  9.7463e-07],\n",
      "         [-4.0484e-05, -3.7593e-05, -2.9815e-05, -5.2905e-06, -2.4913e-05],\n",
      "         [-3.8972e-06, -2.7422e-07,  1.5900e-05, -4.1798e-06,  5.2075e-06],\n",
      "         [-1.8876e-05, -1.9611e-05, -1.4143e-05, -1.6948e-05,  5.0980e-06],\n",
      "         [-1.8768e-06, -3.2790e-06,  3.0120e-06, -1.9838e-06, -1.5040e-06]],\n",
      "\n",
      "        [[-4.8989e-03,  3.5759e-03, -1.4842e-02,  6.1139e-03,  3.8044e-03],\n",
      "         [-1.1043e-03,  7.1084e-04, -1.8848e-03,  6.8747e-04,  1.0699e-03],\n",
      "         [-9.7304e-05,  1.4480e-03, -2.1596e-05,  9.4823e-04,  1.1046e-03],\n",
      "         [-4.2774e-04,  4.1099e-04,  8.9276e-06,  2.1473e-04,  5.4395e-04],\n",
      "         [-2.4195e-04,  2.1430e-04, -1.7770e-04,  2.8797e-05,  4.5429e-04],\n",
      "         [-2.4941e-04,  1.6909e-04, -4.1626e-05, -8.7939e-05,  2.7272e-04],\n",
      "         [ 9.9961e-06, -2.5046e-04,  1.0838e-04,  6.8392e-05,  2.9225e-04],\n",
      "         [-2.6172e-05,  3.0849e-05, -4.2399e-05, -4.6653e-05,  2.4748e-05],\n",
      "         [-5.0370e-05,  8.2600e-05, -3.1856e-05,  6.9945e-06,  1.7548e-04],\n",
      "         [-4.9701e-05,  8.8543e-05,  4.6281e-05,  1.3972e-05,  1.1183e-04],\n",
      "         [ 1.3546e-06,  1.0951e-05,  3.2145e-06,  3.0518e-06,  1.4258e-05],\n",
      "         [-3.6904e-06,  9.7658e-06,  9.1601e-06, -2.4295e-06,  1.7683e-05],\n",
      "         [-4.7197e-06,  9.2193e-08,  3.1074e-06,  7.7087e-08,  5.5671e-06],\n",
      "         [-6.5666e-06, -3.5770e-06, -3.4005e-07,  1.2965e-06,  2.2748e-06],\n",
      "         [-2.5067e-06, -1.5937e-06, -3.3098e-07, -2.9814e-06,  7.3814e-06],\n",
      "         [-3.3521e-06,  6.6325e-07, -3.8113e-06, -4.3390e-07,  2.8331e-06],\n",
      "         [-3.8304e-06, -6.2305e-06, -8.4967e-06, -2.5880e-06, -2.8057e-06],\n",
      "         [ 1.0157e-06,  3.6923e-06, -5.5699e-06,  1.1758e-05,  5.3654e-06],\n",
      "         [-1.3124e-06,  4.1080e-06, -5.7101e-06, -8.7320e-06,  4.3932e-06],\n",
      "         [ 4.5815e-07,  5.4128e-05,  3.8272e-05,  3.6091e-05,  3.3785e-05]],\n",
      "\n",
      "        [[-1.0909e-03, -1.1770e-04, -1.2192e-05,  1.5114e-03,  6.1361e-04],\n",
      "         [-2.3157e-06, -6.0909e-05,  3.4320e-05,  2.0369e-06,  4.6892e-05],\n",
      "         [ 3.3434e-05, -1.5014e-05, -1.2762e-06, -4.2008e-05,  2.9625e-05],\n",
      "         [-2.9458e-05, -4.4941e-05, -1.9811e-05, -1.9424e-05,  6.4890e-06],\n",
      "         [ 1.2063e-05,  3.1445e-06, -3.2574e-06, -5.0148e-06,  4.5517e-05],\n",
      "         [ 2.1574e-06,  9.0901e-07, -4.5342e-06, -3.0191e-06,  3.7194e-07],\n",
      "         [-3.5543e-06, -7.6547e-06, -2.5758e-06, -3.2527e-06, -2.3267e-06],\n",
      "         [ 1.0683e-06, -2.0756e-06, -3.0479e-06, -3.2232e-06, -5.6648e-06],\n",
      "         [ 3.2784e-06,  7.5547e-06,  6.5765e-06,  7.2749e-07, -4.5418e-06],\n",
      "         [ 1.5368e-06,  9.3497e-06,  1.2285e-05,  3.2290e-06,  5.2990e-07],\n",
      "         [-9.1650e-06, -6.6626e-06,  1.0945e-06, -8.1321e-08,  7.5177e-06],\n",
      "         [-7.6846e-06,  3.5366e-06,  9.3077e-06,  3.3061e-06,  1.1074e-05],\n",
      "         [ 5.2200e-07,  7.8452e-06,  1.1682e-05,  1.2233e-05,  7.1646e-07],\n",
      "         [ 4.8922e-06,  4.4966e-06,  4.0638e-06,  3.8427e-06, -2.7564e-06],\n",
      "         [-3.0755e-06,  2.4433e-07,  1.0725e-05,  1.0645e-05,  6.8446e-07],\n",
      "         [ 3.9858e-06,  3.7553e-06,  1.4612e-06, -2.9747e-06, -4.3853e-06],\n",
      "         [ 3.8368e-06, -5.6164e-06, -3.9865e-06,  1.3373e-06, -1.2035e-05],\n",
      "         [ 1.2255e-05, -1.6186e-06, -3.8098e-06,  6.9830e-06, -1.7497e-05],\n",
      "         [ 7.7816e-06,  1.0121e-05,  1.4970e-05,  2.2774e-06, -1.4197e-05],\n",
      "         [ 2.0431e-05,  7.5248e-06, -2.2923e-06, -1.1440e-06, -2.0725e-05]],\n",
      "\n",
      "        [[ 2.1580e-03,  3.3882e-04,  2.7328e-03, -2.1830e-03,  9.1509e-04],\n",
      "         [ 6.4927e-05,  3.5772e-05,  3.8641e-05, -3.1953e-05, -9.2844e-06],\n",
      "         [ 4.1492e-05,  3.6843e-05,  2.7166e-05,  1.4072e-05, -1.8847e-05],\n",
      "         [-6.0244e-07,  9.4851e-07, -3.1664e-06,  1.1954e-05, -7.0045e-06],\n",
      "         [ 2.1366e-06,  1.8412e-06, -2.7468e-06,  1.1073e-05, -3.0386e-06],\n",
      "         [-1.2762e-05, -8.4988e-06, -1.4143e-05,  2.7874e-06, -8.4388e-06],\n",
      "         [ 7.1866e-06,  8.4516e-06, -7.9100e-06,  2.5889e-05, -8.6004e-06],\n",
      "         [-8.4297e-06, -3.7164e-07,  2.7124e-06,  1.0705e-05,  3.1541e-06],\n",
      "         [-5.5506e-06, -1.8549e-06, -1.0621e-05,  1.0967e-05, -7.5108e-07],\n",
      "         [-3.5641e-07,  4.4057e-06, -1.6404e-05,  8.9829e-06, -1.4469e-06],\n",
      "         [ 2.4667e-06, -1.4252e-06,  4.0414e-06,  8.7097e-06,  6.1931e-07],\n",
      "         [ 1.2820e-06,  2.0399e-07, -1.1956e-05,  1.1537e-05, -8.1721e-06],\n",
      "         [-3.8707e-06, -3.0541e-06, -2.3454e-05,  2.7445e-05, -1.3597e-05],\n",
      "         [-1.9055e-05, -8.9976e-06, -4.3579e-05,  1.2100e-05, -1.2304e-05],\n",
      "         [ 2.1694e-06, -1.8638e-06, -1.2279e-05, -9.9773e-07,  1.1565e-06],\n",
      "         [ 7.4197e-07,  4.0427e-07, -4.9173e-06, -1.8911e-06,  3.0493e-06],\n",
      "         [-8.4068e-07, -4.1939e-06, -2.5607e-06, -5.6330e-06,  8.9782e-07],\n",
      "         [ 6.7802e-06, -1.7580e-06,  2.7575e-06, -2.2557e-06, -3.6979e-06],\n",
      "         [ 4.4102e-06,  3.5989e-06,  5.1790e-06,  9.1208e-07,  7.3157e-07],\n",
      "         [-9.8189e-06,  2.4933e-06,  9.2846e-06,  3.2430e-07, -4.9588e-06]],\n",
      "\n",
      "        [[-5.8759e-05,  1.2518e-04,  2.2512e-04,  5.4664e-04,  2.1063e-04],\n",
      "         [ 2.7433e-04, -1.5888e-04, -3.2482e-04,  1.6861e-04,  4.6790e-05],\n",
      "         [ 5.6248e-05, -3.8931e-05, -1.4647e-04, -3.3157e-05,  7.0255e-06],\n",
      "         [ 3.3191e-05,  2.7219e-05,  3.0401e-05, -2.1140e-05,  3.8406e-05],\n",
      "         [ 4.7841e-05,  2.1320e-05,  6.2599e-05, -1.0317e-05,  5.7435e-05],\n",
      "         [ 1.3014e-06, -1.0706e-05,  1.3470e-05,  1.6219e-06, -5.3742e-07],\n",
      "         [ 7.5487e-06,  3.9666e-06,  3.7263e-05, -1.1394e-06,  4.0256e-05],\n",
      "         [ 1.7607e-05, -2.2801e-05, -7.2448e-06,  7.3027e-07, -7.4558e-06],\n",
      "         [ 7.2821e-06,  5.5362e-06,  1.6301e-05, -3.3705e-06,  1.0364e-05],\n",
      "         [ 9.3881e-07, -4.5752e-06, -1.6540e-06, -4.7865e-06,  1.7263e-06],\n",
      "         [-6.7837e-07, -5.1025e-06,  2.9915e-06,  8.9991e-07,  2.3710e-06],\n",
      "         [-8.8157e-06, -4.8581e-06,  1.9250e-06, -4.2550e-07, -2.4894e-06],\n",
      "         [-1.3607e-05, -8.6569e-06, -5.1378e-06, -9.0923e-06, -1.2241e-05],\n",
      "         [-9.7844e-06, -2.8008e-06, -2.4604e-06,  3.0499e-06, -1.2505e-05],\n",
      "         [-2.1934e-06,  6.6723e-06,  4.5977e-07, -1.0282e-06, -1.6027e-06],\n",
      "         [-1.3079e-06,  1.3839e-06, -7.3314e-07, -1.0236e-06, -1.0538e-06],\n",
      "         [-4.3656e-06,  7.0711e-06,  5.8671e-06, -2.5333e-06, -2.1697e-06],\n",
      "         [ 3.6814e-07,  3.2889e-06, -5.2814e-06, -2.0576e-06, -8.7625e-06],\n",
      "         [-2.8131e-06, -1.3260e-06, -8.7925e-07, -8.2262e-06, -2.1963e-06],\n",
      "         [ 2.5419e-06,  4.4148e-06, -2.2508e-06, -1.8272e-06, -1.9946e-06]],\n",
      "\n",
      "        [[-8.6276e-04,  3.6917e-03, -2.9201e-03,  7.0942e-04,  1.7246e-03],\n",
      "         [ 4.1090e-05, -3.3601e-05,  1.9920e-04,  1.3025e-04,  2.5129e-05],\n",
      "         [-1.2405e-04, -4.4210e-04,  1.3795e-04, -2.0730e-05,  2.6600e-04],\n",
      "         [-5.7319e-05,  1.0027e-04,  1.0273e-03, -2.4236e-04,  8.2015e-04],\n",
      "         [-1.6603e-05, -3.6971e-05,  4.1004e-05, -1.5293e-04,  9.2466e-05],\n",
      "         [-9.1492e-05,  4.7996e-05,  5.2234e-04, -3.4359e-04,  4.2537e-04],\n",
      "         [ 1.8457e-05,  4.8767e-05,  1.5712e-04, -2.7861e-05,  5.9145e-05],\n",
      "         [ 1.0706e-05,  6.0338e-05,  1.6743e-04, -3.9880e-06,  1.3163e-04],\n",
      "         [ 1.1199e-05,  4.8812e-05,  1.4934e-04, -4.6565e-05,  5.2590e-05],\n",
      "         [-3.0033e-05,  1.5633e-05,  3.6775e-05, -2.0905e-05,  1.5756e-05],\n",
      "         [ 2.0393e-06,  5.6273e-05,  3.3848e-05, -3.6244e-06,  2.0269e-06],\n",
      "         [ 7.3725e-06,  1.7539e-05,  1.5764e-05, -9.0794e-07,  1.0111e-05],\n",
      "         [ 4.7538e-06,  1.2780e-05, -2.5340e-06,  1.0927e-05, -1.8285e-05],\n",
      "         [-7.7299e-06, -5.0085e-06,  5.2145e-06,  1.0007e-05,  1.0856e-06],\n",
      "         [ 2.3271e-05,  3.9087e-05,  9.5206e-06,  3.7490e-05, -4.7638e-05],\n",
      "         [ 5.9728e-06,  3.9693e-05,  2.0623e-05,  1.5534e-06, -3.4302e-06],\n",
      "         [ 6.5993e-06, -7.5720e-07, -1.9026e-05, -3.0580e-06, -6.4812e-05],\n",
      "         [-3.2932e-06,  1.6312e-05, -5.4632e-06, -1.4039e-05, -2.4150e-05],\n",
      "         [-8.4028e-06,  3.8740e-06,  5.6300e-07, -8.8992e-06,  5.9203e-06],\n",
      "         [-7.1649e-06, -5.8308e-06,  8.6448e-06, -1.2562e-05,  2.2966e-05]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 2.1951e-03, -2.2889e-03,  3.8057e-03,  5.8254e-05, -4.5365e-03,\n",
      "          -1.5063e-03,  2.5015e-03,  1.9255e-03],\n",
      "         [ 2.8545e-04, -3.3685e-05, -1.3611e-04, -3.4830e-05, -4.3562e-04,\n",
      "          -4.0867e-04,  3.3420e-04, -7.6087e-04],\n",
      "         [-2.6688e-04,  1.8594e-04, -1.4710e-04, -2.4395e-04,  6.4024e-04,\n",
      "           3.5496e-04, -5.6990e-04,  8.4313e-04],\n",
      "         [-7.2026e-03,  4.9180e-03,  2.7979e-03,  4.6659e-03,  6.4111e-03,\n",
      "           1.3186e-02, -1.3843e-02,  6.3364e-03],\n",
      "         [ 4.7449e-05, -9.9123e-04,  1.7606e-03,  1.0013e-03, -1.7604e-03,\n",
      "           1.8536e-03, -1.3488e-03,  2.9641e-04],\n",
      "         [ 8.5704e-04,  1.8461e-03, -5.3673e-05, -7.1377e-04, -5.2805e-04,\n",
      "          -1.9856e-03,  3.3572e-03, -4.1086e-03],\n",
      "         [ 8.4167e-04,  9.4750e-04,  4.8508e-04,  9.2901e-04, -1.4106e-03,\n",
      "          -6.6229e-05,  8.8119e-05, -7.2879e-04],\n",
      "         [-8.0065e-03,  6.4596e-03,  9.7765e-04, -9.0176e-04,  6.7004e-03,\n",
      "           4.5004e-03,  4.5472e-03, -3.1279e-03]],\n",
      "\n",
      "        [[ 6.8836e-03, -4.1755e-03,  8.1054e-03, -2.0074e-03, -2.7289e-03,\n",
      "           3.3458e-03,  1.1185e-02, -1.1046e-03],\n",
      "         [-2.9518e-04, -3.9726e-04,  3.9044e-04,  1.6690e-03,  1.1547e-04,\n",
      "          -9.7647e-04, -2.3981e-04,  3.9566e-04],\n",
      "         [-7.6995e-04,  6.4688e-05, -5.9497e-04,  5.5882e-04,  4.3654e-04,\n",
      "          -4.8188e-04, -5.2551e-04, -8.5102e-05],\n",
      "         [-1.3586e-02, -4.5445e-03, -4.5744e-03,  2.8665e-03,  5.0749e-03,\n",
      "          -1.1148e-02, -1.7973e-02,  1.5858e-03],\n",
      "         [-1.7056e-03, -2.0725e-03, -7.5122e-04, -1.5628e-03,  1.3845e-03,\n",
      "           3.8218e-04, -2.6216e-03,  8.5675e-04],\n",
      "         [-2.8200e-03, -7.9094e-04, -2.2289e-03, -2.2527e-03,  3.5888e-04,\n",
      "          -5.1465e-04,  2.5690e-04, -6.3610e-04],\n",
      "         [ 3.3643e-03, -2.1764e-03,  3.2888e-03,  4.4659e-05, -9.5080e-04,\n",
      "           5.9879e-04,  2.6246e-03,  1.2190e-03],\n",
      "         [-9.4860e-03,  4.1944e-03, -7.5942e-03,  2.3802e-03,  1.9136e-03,\n",
      "          -2.3653e-03, -6.8083e-03,  5.1228e-05]],\n",
      "\n",
      "        [[-4.1982e-03,  1.0680e-02, -9.9937e-03,  1.6771e-02,  1.6725e-03,\n",
      "           1.7000e-02,  1.3050e-02, -2.2139e-02],\n",
      "         [ 1.1359e-03,  3.1919e-04,  7.6699e-04, -2.3672e-03,  2.2053e-03,\n",
      "           1.5929e-03, -2.0190e-04, -2.4335e-04],\n",
      "         [ 1.3167e-03, -1.2219e-04,  5.4202e-04, -1.5618e-03,  2.0200e-03,\n",
      "           1.5754e-03, -9.9014e-06, -7.4531e-04],\n",
      "         [ 5.3411e-03, -3.3860e-03,  4.2970e-03, -8.9058e-03,  5.5838e-03,\n",
      "           2.7070e-03, -2.1184e-03,  6.2857e-03],\n",
      "         [ 4.1829e-04, -2.5056e-03,  1.5835e-03, -1.9165e-04, -8.7586e-04,\n",
      "          -1.9663e-03, -2.4294e-03,  4.4394e-03],\n",
      "         [ 1.3866e-03, -2.0942e-03,  6.8358e-04, -1.6225e-03, -2.2405e-03,\n",
      "          -5.4569e-03, -3.9169e-03,  3.8092e-03],\n",
      "         [ 5.5330e-04, -1.2045e-03, -1.1182e-05, -8.3006e-04, -1.2313e-03,\n",
      "          -2.5023e-03, -1.7250e-03,  1.6476e-03],\n",
      "         [-1.3813e-04, -1.2891e-03,  2.5729e-03, -5.0690e-03,  5.4889e-04,\n",
      "          -1.8714e-03, -1.7949e-03,  3.9000e-03]]], device='cuda:0'), tensor([[[ 2.0157e-03,  3.5742e-03,  5.1246e-03,  5.2775e-03,  2.0185e-05,\n",
      "          -1.5673e-02, -8.1027e-03,  7.6659e-04],\n",
      "         [ 1.4685e-03, -4.3760e-04,  1.6369e-03, -3.2474e-04, -2.6286e-05,\n",
      "           7.0842e-04, -6.3514e-04, -2.1958e-03],\n",
      "         [-7.7907e-04, -6.2195e-04, -3.1376e-03, -4.9371e-04,  1.0468e-04,\n",
      "           2.2397e-03, -7.4600e-04,  3.7371e-03],\n",
      "         [-1.7548e-02, -1.4097e-02, -2.0161e-02, -4.3972e-03, -4.8673e-03,\n",
      "           8.0240e-02, -1.2447e-02,  6.4153e-03],\n",
      "         [ 1.1465e-03,  3.1524e-04, -1.6514e-03,  3.1733e-03, -1.4492e-03,\n",
      "           2.2359e-03, -6.9782e-04, -2.2305e-03],\n",
      "         [ 4.5048e-04, -1.1572e-04,  7.7917e-03, -6.3714e-04, -5.4611e-05,\n",
      "          -1.2285e-03,  8.6287e-04, -6.0034e-03],\n",
      "         [ 3.5224e-03, -2.7026e-04,  2.5695e-03,  3.6831e-03, -1.2479e-04,\n",
      "           3.5479e-04, -4.2024e-03, -4.5668e-03],\n",
      "         [-6.6846e-03, -1.8650e-03,  1.3919e-02, -8.4183e-03,  3.5054e-03,\n",
      "           2.1287e-02,  4.1799e-03, -2.6311e-02]],\n",
      "\n",
      "        [[ 1.0300e-02, -2.2558e-02, -1.1139e-03,  6.8029e-03,  9.7018e-04,\n",
      "           1.3681e-03,  5.6626e-03, -2.1230e-03],\n",
      "         [-6.0770e-04,  2.5775e-04, -8.3511e-06, -7.2656e-04,  4.5634e-04,\n",
      "           1.5260e-04, -1.7656e-04,  7.1429e-04],\n",
      "         [-5.0990e-04,  6.9255e-04, -9.0267e-05, -3.9823e-04,  3.0550e-05,\n",
      "           3.2621e-05, -4.1527e-06,  2.3441e-04],\n",
      "         [-1.1042e-02,  1.2987e-02,  2.3728e-04, -1.2485e-02, -5.5593e-03,\n",
      "           8.0299e-03, -2.6818e-04,  4.9006e-03],\n",
      "         [-2.0865e-03, -1.4520e-04,  9.2070e-04, -1.4046e-04, -3.5275e-03,\n",
      "           3.2470e-03,  3.8365e-04,  1.0024e-03],\n",
      "         [-2.8712e-03,  2.6472e-04,  9.9087e-04,  8.5908e-04, -8.5756e-04,\n",
      "          -9.1239e-04,  3.4293e-03,  9.2513e-04],\n",
      "         [-3.2036e-04, -4.0992e-03,  5.9600e-04,  1.4470e-03, -1.6599e-04,\n",
      "           6.8834e-04,  7.5026e-04,  9.4788e-04],\n",
      "         [-1.0182e-03,  7.2428e-03, -3.4888e-04, -1.0370e-03, -1.6981e-03,\n",
      "          -3.3019e-03, -9.8175e-04,  1.6486e-03]],\n",
      "\n",
      "        [[-1.3385e-03,  2.3338e-03, -3.7855e-03, -6.8118e-04, -4.0586e-05,\n",
      "           1.0815e-03,  8.4294e-04, -4.9861e-04],\n",
      "         [-2.8156e-03,  2.8408e-04,  1.6536e-03, -1.4149e-05, -1.8337e-04,\n",
      "          -4.8993e-04,  4.7150e-04,  3.1072e-04],\n",
      "         [-3.0061e-03,  6.0519e-04,  1.5039e-03,  2.7111e-04, -1.3618e-04,\n",
      "           2.8248e-05, -3.4557e-04, -1.8787e-04],\n",
      "         [-4.2812e-03, -8.5323e-04,  3.1183e-03,  3.2455e-03, -2.4577e-03,\n",
      "          -1.9234e-03,  2.0367e-04,  1.3343e-04],\n",
      "         [ 1.0651e-03, -2.3513e-03, -1.0050e-04,  2.8375e-03, -5.0425e-04,\n",
      "          -8.5034e-04, -3.7001e-04,  5.5439e-04],\n",
      "         [ 4.8334e-04, -3.5995e-03,  9.6879e-04,  2.2481e-04,  5.8054e-04,\n",
      "           9.5169e-04, -8.7941e-04,  8.4511e-04],\n",
      "         [ 8.8684e-04, -3.1240e-03,  2.7041e-03, -2.9540e-04,  1.4521e-04,\n",
      "           2.4236e-04, -4.3443e-04,  1.4447e-04],\n",
      "         [-3.6830e-04, -4.2225e-03,  6.3036e-03, -1.2268e-04, -1.3342e-04,\n",
      "          -1.2462e-03,  2.8181e-04,  1.5558e-06]]], device='cuda:0'))\n",
      "tensor([-1.7625e-03,  5.5826e-04,  5.4326e-03,  1.3602e-04, -3.3164e-04,\n",
      "        -1.6660e-03, -4.3979e-05, -1.6902e-03, -2.6029e-03,  4.1292e-03,\n",
      "         5.0831e-03, -3.5170e-03, -1.5854e-03, -1.6174e-03,  3.0620e-04,\n",
      "        -1.2531e-03, -1.4330e-02, -3.6512e-03, -4.0918e-03, -2.1584e-03,\n",
      "         6.6672e-04,  7.7369e-02, -1.7840e-02, -2.2400e-02, -2.4683e-03,\n",
      "         1.3155e-03,  3.0738e-03, -1.7665e-03,  1.2936e-03, -3.4526e-04,\n",
      "        -9.2460e-04, -1.0026e-04], device='cuda:0')\n",
      "tensor([-0.0162,  0.0099,  0.0270, -0.0138,  0.0018, -0.0085, -0.0032, -0.0068],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"model_torch\")\n",
    "print(inputs_grads[0])\n",
    "print(hidden_grads[0])\n",
    "print(model_torch.lstm0.bias.grad)\n",
    "print(model_torch.lstm0.gamma_cell.grad)\n",
    "# print(model_torch.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_torch.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:34.668100Z",
     "start_time": "2019-02-06T20:06:34.422105Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cpp\n",
      "tensor([[[-2.3392e-03, -2.0866e-03,  4.1625e-03,  1.3977e-03, -6.6969e-04],\n",
      "         [ 3.0949e-06, -6.4528e-05, -4.0021e-05, -2.5677e-05, -4.5529e-05],\n",
      "         [-9.9977e-06, -4.5025e-05, -3.8840e-05, -9.1774e-06, -3.5822e-05],\n",
      "         [-1.3572e-05,  3.8746e-06, -3.8844e-05,  2.1861e-05, -4.7407e-05],\n",
      "         [-8.0598e-06, -1.4133e-05, -2.3156e-05,  1.3458e-05, -2.8517e-05],\n",
      "         [-1.5293e-05, -1.5984e-05, -4.8014e-05,  2.4379e-05, -3.9248e-05],\n",
      "         [ 6.6738e-06,  1.6129e-05, -6.1014e-05,  2.5314e-05, -2.6347e-05],\n",
      "         [ 6.0098e-06, -8.5342e-06, -1.9613e-05, -3.6052e-06, -2.2111e-05],\n",
      "         [ 6.9569e-06, -1.2978e-05, -3.1409e-05,  8.0042e-06, -2.7936e-05],\n",
      "         [ 2.1220e-05,  2.2263e-05, -7.3463e-06, -6.5337e-06, -3.5929e-05],\n",
      "         [ 1.8278e-05,  2.1283e-05, -1.6896e-05,  7.5421e-06, -1.5575e-05],\n",
      "         [ 3.8402e-05,  4.7894e-05,  1.6105e-05,  2.6976e-05,  2.1125e-05],\n",
      "         [ 9.9178e-06,  8.8280e-06, -1.7362e-05, -1.7223e-06, -7.8249e-06],\n",
      "         [ 8.0479e-06, -5.5114e-06, -1.1771e-05, -2.4512e-05, -5.5032e-06],\n",
      "         [ 1.6801e-05,  5.5495e-06, -2.1773e-05,  1.4832e-05, -8.5240e-06],\n",
      "         [ 1.5035e-05,  1.4424e-05, -2.3664e-05,  2.7109e-06, -9.2482e-06],\n",
      "         [-6.3830e-06, -7.7751e-07, -1.1653e-05,  9.8675e-07, -1.1835e-05],\n",
      "         [-2.5869e-06, -2.8699e-06, -4.1706e-06, -2.0002e-06, -2.4590e-06],\n",
      "         [ 1.0125e-05, -2.0693e-06, -8.9935e-06, -4.9151e-06,  5.6822e-07],\n",
      "         [ 4.1514e-07,  1.1544e-07, -1.7567e-06, -1.2400e-06, -1.4115e-06]],\n",
      "\n",
      "        [[ 3.6216e-04, -1.2591e-04, -3.4214e-05,  3.2623e-05, -2.6589e-04],\n",
      "         [ 5.3558e-05, -2.6146e-05,  7.1672e-05, -4.2250e-05,  3.8352e-05],\n",
      "         [ 4.0959e-06, -5.6118e-06,  2.1940e-05, -1.3798e-05,  1.3270e-05],\n",
      "         [ 9.3758e-06,  1.0194e-06,  3.3508e-05, -1.6173e-05,  1.1854e-05],\n",
      "         [ 4.3960e-06,  2.6241e-06,  2.2244e-05, -7.3918e-06,  1.9262e-06],\n",
      "         [ 3.5406e-05,  4.2495e-06,  1.2088e-05, -2.6229e-05,  8.7411e-06],\n",
      "         [ 2.7299e-05,  6.3413e-05,  1.5287e-04,  4.2795e-05,  5.3973e-05],\n",
      "         [ 3.5799e-05,  9.4383e-05,  1.8922e-04,  7.1046e-05,  7.6462e-05],\n",
      "         [ 1.6741e-05,  4.4129e-06,  1.8721e-05,  5.6250e-06, -1.7219e-06],\n",
      "         [ 5.3465e-06, -1.7291e-05, -1.0320e-05,  2.5344e-06,  1.2081e-06],\n",
      "         [-2.7839e-06, -3.4675e-06,  1.7255e-05,  3.7039e-06,  1.5067e-05],\n",
      "         [ 2.5432e-05,  3.5282e-05,  3.0678e-05,  3.3708e-05,  1.0224e-05],\n",
      "         [ 2.0974e-06,  8.1348e-07,  4.2058e-06,  1.9381e-06, -1.3289e-07],\n",
      "         [-1.8332e-05, -1.7638e-05, -6.2191e-06, -1.1145e-05, -1.4741e-05],\n",
      "         [-1.1790e-05,  4.1792e-07,  8.5721e-06, -2.3138e-06,  5.0313e-06],\n",
      "         [-1.4579e-05, -9.3607e-06, -3.8186e-05, -3.3165e-05, -2.7052e-05],\n",
      "         [-7.4170e-06,  1.3721e-05,  7.8955e-06, -1.7461e-05, -5.3853e-06],\n",
      "         [-1.1033e-05,  1.6862e-05,  3.8620e-05,  1.2925e-05,  6.4215e-06],\n",
      "         [-8.0691e-06, -2.5828e-06,  2.2202e-05,  1.7181e-05,  2.8543e-08],\n",
      "         [ 6.8577e-06,  1.1428e-05,  1.7558e-05,  1.7058e-05, -1.4939e-06]],\n",
      "\n",
      "        [[-1.3986e-04,  1.0489e-04, -6.3481e-04,  2.0674e-04, -2.5618e-04],\n",
      "         [-2.4054e-04, -1.5231e-04, -4.5791e-04,  8.5643e-05, -1.6192e-04],\n",
      "         [-3.1214e-05, -3.7849e-05, -1.6644e-04,  9.8265e-05, -1.2356e-04],\n",
      "         [-3.8048e-05, -1.4877e-05, -4.4710e-05,  1.8178e-05,  7.7644e-08],\n",
      "         [-4.0256e-05, -1.3709e-05, -7.2727e-05,  1.3682e-05, -9.0629e-06],\n",
      "         [-7.7089e-05,  6.0412e-06, -6.1820e-05,  9.2688e-05,  1.8379e-06],\n",
      "         [-6.4067e-05,  1.9810e-05, -1.4713e-05,  7.4725e-05,  2.9619e-05],\n",
      "         [-1.0907e-05,  2.2324e-04,  1.6261e-04,  7.6922e-05,  8.8309e-05],\n",
      "         [-1.1706e-05,  8.6947e-05,  3.1238e-05,  3.7810e-05,  2.2329e-05],\n",
      "         [ 5.2517e-06,  3.6641e-05, -1.1491e-05, -5.4288e-06,  2.8928e-05],\n",
      "         [-9.2090e-06,  7.0892e-06, -6.3724e-05, -3.9634e-05,  8.1281e-06],\n",
      "         [-1.7957e-05,  2.4004e-06, -3.2209e-05,  1.7014e-05,  2.7710e-05],\n",
      "         [-2.3463e-05, -2.8554e-05, -2.5340e-05,  8.1620e-06,  3.8452e-06],\n",
      "         [-2.0497e-05, -4.6591e-05, -8.8161e-05, -1.2669e-04,  5.4401e-05],\n",
      "         [-2.1529e-05, -2.2201e-05, -3.4177e-05, -7.5269e-06, -1.3445e-05],\n",
      "         [-1.4675e-06, -4.3309e-06, -1.1557e-05, -8.1615e-06,  9.7464e-07],\n",
      "         [-4.0484e-05, -3.7593e-05, -2.9815e-05, -5.2905e-06, -2.4913e-05],\n",
      "         [-3.8972e-06, -2.7422e-07,  1.5900e-05, -4.1798e-06,  5.2075e-06],\n",
      "         [-1.8876e-05, -1.9611e-05, -1.4143e-05, -1.6948e-05,  5.0980e-06],\n",
      "         [-1.8768e-06, -3.2790e-06,  3.0121e-06, -1.9838e-06, -1.5040e-06]],\n",
      "\n",
      "        [[-4.8989e-03,  3.5759e-03, -1.4842e-02,  6.1139e-03,  3.8044e-03],\n",
      "         [-1.1043e-03,  7.1084e-04, -1.8848e-03,  6.8747e-04,  1.0699e-03],\n",
      "         [-9.7304e-05,  1.4480e-03, -2.1596e-05,  9.4823e-04,  1.1046e-03],\n",
      "         [-4.2774e-04,  4.1099e-04,  8.9275e-06,  2.1473e-04,  5.4395e-04],\n",
      "         [-2.4195e-04,  2.1430e-04, -1.7770e-04,  2.8797e-05,  4.5429e-04],\n",
      "         [-2.4941e-04,  1.6909e-04, -4.1626e-05, -8.7938e-05,  2.7272e-04],\n",
      "         [ 9.9960e-06, -2.5046e-04,  1.0838e-04,  6.8392e-05,  2.9225e-04],\n",
      "         [-2.6172e-05,  3.0849e-05, -4.2399e-05, -4.6653e-05,  2.4748e-05],\n",
      "         [-5.0370e-05,  8.2600e-05, -3.1855e-05,  6.9946e-06,  1.7548e-04],\n",
      "         [-4.9701e-05,  8.8543e-05,  4.6281e-05,  1.3972e-05,  1.1183e-04],\n",
      "         [ 1.3546e-06,  1.0951e-05,  3.2145e-06,  3.0518e-06,  1.4258e-05],\n",
      "         [-3.6904e-06,  9.7658e-06,  9.1601e-06, -2.4295e-06,  1.7683e-05],\n",
      "         [-4.7197e-06,  9.2188e-08,  3.1074e-06,  7.7088e-08,  5.5671e-06],\n",
      "         [-6.5666e-06, -3.5770e-06, -3.4005e-07,  1.2965e-06,  2.2748e-06],\n",
      "         [-2.5067e-06, -1.5937e-06, -3.3098e-07, -2.9814e-06,  7.3814e-06],\n",
      "         [-3.3521e-06,  6.6325e-07, -3.8113e-06, -4.3390e-07,  2.8331e-06],\n",
      "         [-3.8304e-06, -6.2305e-06, -8.4967e-06, -2.5880e-06, -2.8057e-06],\n",
      "         [ 1.0157e-06,  3.6923e-06, -5.5699e-06,  1.1758e-05,  5.3654e-06],\n",
      "         [-1.3124e-06,  4.1080e-06, -5.7101e-06, -8.7320e-06,  4.3932e-06],\n",
      "         [ 4.5815e-07,  5.4128e-05,  3.8272e-05,  3.6091e-05,  3.3785e-05]],\n",
      "\n",
      "        [[-1.0909e-03, -1.1770e-04, -1.2192e-05,  1.5114e-03,  6.1361e-04],\n",
      "         [-2.3157e-06, -6.0909e-05,  3.4320e-05,  2.0369e-06,  4.6892e-05],\n",
      "         [ 3.3434e-05, -1.5014e-05, -1.2762e-06, -4.2008e-05,  2.9625e-05],\n",
      "         [-2.9458e-05, -4.4941e-05, -1.9811e-05, -1.9424e-05,  6.4890e-06],\n",
      "         [ 1.2063e-05,  3.1444e-06, -3.2574e-06, -5.0148e-06,  4.5517e-05],\n",
      "         [ 2.1575e-06,  9.0901e-07, -4.5342e-06, -3.0191e-06,  3.7193e-07],\n",
      "         [-3.5543e-06, -7.6547e-06, -2.5758e-06, -3.2527e-06, -2.3267e-06],\n",
      "         [ 1.0683e-06, -2.0756e-06, -3.0479e-06, -3.2232e-06, -5.6648e-06],\n",
      "         [ 3.2784e-06,  7.5547e-06,  6.5765e-06,  7.2749e-07, -4.5418e-06],\n",
      "         [ 1.5368e-06,  9.3497e-06,  1.2285e-05,  3.2290e-06,  5.2989e-07],\n",
      "         [-9.1650e-06, -6.6626e-06,  1.0945e-06, -8.1320e-08,  7.5177e-06],\n",
      "         [-7.6846e-06,  3.5366e-06,  9.3077e-06,  3.3061e-06,  1.1074e-05],\n",
      "         [ 5.2200e-07,  7.8452e-06,  1.1682e-05,  1.2233e-05,  7.1646e-07],\n",
      "         [ 4.8922e-06,  4.4966e-06,  4.0638e-06,  3.8427e-06, -2.7564e-06],\n",
      "         [-3.0755e-06,  2.4433e-07,  1.0725e-05,  1.0645e-05,  6.8446e-07],\n",
      "         [ 3.9858e-06,  3.7553e-06,  1.4612e-06, -2.9747e-06, -4.3853e-06],\n",
      "         [ 3.8368e-06, -5.6164e-06, -3.9865e-06,  1.3373e-06, -1.2035e-05],\n",
      "         [ 1.2255e-05, -1.6186e-06, -3.8098e-06,  6.9830e-06, -1.7497e-05],\n",
      "         [ 7.7816e-06,  1.0121e-05,  1.4970e-05,  2.2774e-06, -1.4197e-05],\n",
      "         [ 2.0431e-05,  7.5248e-06, -2.2923e-06, -1.1440e-06, -2.0725e-05]],\n",
      "\n",
      "        [[ 2.1580e-03,  3.3882e-04,  2.7328e-03, -2.1830e-03,  9.1509e-04],\n",
      "         [ 6.4927e-05,  3.5772e-05,  3.8641e-05, -3.1953e-05, -9.2844e-06],\n",
      "         [ 4.1491e-05,  3.6843e-05,  2.7166e-05,  1.4072e-05, -1.8847e-05],\n",
      "         [-6.0244e-07,  9.4851e-07, -3.1664e-06,  1.1954e-05, -7.0046e-06],\n",
      "         [ 2.1366e-06,  1.8412e-06, -2.7468e-06,  1.1073e-05, -3.0386e-06],\n",
      "         [-1.2762e-05, -8.4988e-06, -1.4143e-05,  2.7874e-06, -8.4388e-06],\n",
      "         [ 7.1866e-06,  8.4516e-06, -7.9100e-06,  2.5889e-05, -8.6004e-06],\n",
      "         [-8.4297e-06, -3.7163e-07,  2.7124e-06,  1.0705e-05,  3.1541e-06],\n",
      "         [-5.5506e-06, -1.8549e-06, -1.0621e-05,  1.0967e-05, -7.5108e-07],\n",
      "         [-3.5641e-07,  4.4057e-06, -1.6404e-05,  8.9829e-06, -1.4469e-06],\n",
      "         [ 2.4667e-06, -1.4252e-06,  4.0414e-06,  8.7097e-06,  6.1932e-07],\n",
      "         [ 1.2820e-06,  2.0399e-07, -1.1956e-05,  1.1537e-05, -8.1722e-06],\n",
      "         [-3.8707e-06, -3.0541e-06, -2.3454e-05,  2.7445e-05, -1.3597e-05],\n",
      "         [-1.9055e-05, -8.9976e-06, -4.3579e-05,  1.2100e-05, -1.2304e-05],\n",
      "         [ 2.1694e-06, -1.8638e-06, -1.2279e-05, -9.9772e-07,  1.1565e-06],\n",
      "         [ 7.4197e-07,  4.0427e-07, -4.9173e-06, -1.8911e-06,  3.0493e-06],\n",
      "         [-8.4068e-07, -4.1939e-06, -2.5607e-06, -5.6330e-06,  8.9782e-07],\n",
      "         [ 6.7802e-06, -1.7580e-06,  2.7575e-06, -2.2557e-06, -3.6979e-06],\n",
      "         [ 4.4102e-06,  3.5989e-06,  5.1790e-06,  9.1207e-07,  7.3158e-07],\n",
      "         [-9.8189e-06,  2.4933e-06,  9.2846e-06,  3.2429e-07, -4.9588e-06]],\n",
      "\n",
      "        [[-5.8759e-05,  1.2518e-04,  2.2512e-04,  5.4664e-04,  2.1063e-04],\n",
      "         [ 2.7433e-04, -1.5888e-04, -3.2482e-04,  1.6861e-04,  4.6790e-05],\n",
      "         [ 5.6248e-05, -3.8931e-05, -1.4647e-04, -3.3157e-05,  7.0255e-06],\n",
      "         [ 3.3191e-05,  2.7219e-05,  3.0401e-05, -2.1140e-05,  3.8406e-05],\n",
      "         [ 4.7841e-05,  2.1320e-05,  6.2599e-05, -1.0317e-05,  5.7435e-05],\n",
      "         [ 1.3013e-06, -1.0706e-05,  1.3470e-05,  1.6219e-06, -5.3741e-07],\n",
      "         [ 7.5487e-06,  3.9666e-06,  3.7263e-05, -1.1394e-06,  4.0257e-05],\n",
      "         [ 1.7607e-05, -2.2801e-05, -7.2448e-06,  7.3029e-07, -7.4558e-06],\n",
      "         [ 7.2821e-06,  5.5362e-06,  1.6301e-05, -3.3705e-06,  1.0364e-05],\n",
      "         [ 9.3881e-07, -4.5752e-06, -1.6540e-06, -4.7865e-06,  1.7263e-06],\n",
      "         [-6.7838e-07, -5.1025e-06,  2.9915e-06,  8.9992e-07,  2.3710e-06],\n",
      "         [-8.8157e-06, -4.8581e-06,  1.9250e-06, -4.2549e-07, -2.4894e-06],\n",
      "         [-1.3607e-05, -8.6569e-06, -5.1378e-06, -9.0923e-06, -1.2241e-05],\n",
      "         [-9.7844e-06, -2.8008e-06, -2.4604e-06,  3.0499e-06, -1.2505e-05],\n",
      "         [-2.1934e-06,  6.6723e-06,  4.5977e-07, -1.0282e-06, -1.6027e-06],\n",
      "         [-1.3079e-06,  1.3839e-06, -7.3314e-07, -1.0236e-06, -1.0538e-06],\n",
      "         [-4.3656e-06,  7.0711e-06,  5.8671e-06, -2.5333e-06, -2.1697e-06],\n",
      "         [ 3.6814e-07,  3.2889e-06, -5.2814e-06, -2.0576e-06, -8.7625e-06],\n",
      "         [-2.8131e-06, -1.3260e-06, -8.7925e-07, -8.2262e-06, -2.1963e-06],\n",
      "         [ 2.5419e-06,  4.4148e-06, -2.2508e-06, -1.8272e-06, -1.9946e-06]],\n",
      "\n",
      "        [[-8.6276e-04,  3.6917e-03, -2.9201e-03,  7.0943e-04,  1.7246e-03],\n",
      "         [ 4.1090e-05, -3.3601e-05,  1.9920e-04,  1.3025e-04,  2.5129e-05],\n",
      "         [-1.2405e-04, -4.4210e-04,  1.3795e-04, -2.0731e-05,  2.6600e-04],\n",
      "         [-5.7319e-05,  1.0027e-04,  1.0273e-03, -2.4236e-04,  8.2015e-04],\n",
      "         [-1.6603e-05, -3.6971e-05,  4.1004e-05, -1.5293e-04,  9.2466e-05],\n",
      "         [-9.1492e-05,  4.7996e-05,  5.2234e-04, -3.4359e-04,  4.2537e-04],\n",
      "         [ 1.8457e-05,  4.8767e-05,  1.5712e-04, -2.7861e-05,  5.9145e-05],\n",
      "         [ 1.0706e-05,  6.0338e-05,  1.6743e-04, -3.9880e-06,  1.3163e-04],\n",
      "         [ 1.1199e-05,  4.8812e-05,  1.4934e-04, -4.6565e-05,  5.2590e-05],\n",
      "         [-3.0033e-05,  1.5633e-05,  3.6775e-05, -2.0906e-05,  1.5756e-05],\n",
      "         [ 2.0393e-06,  5.6273e-05,  3.3848e-05, -3.6244e-06,  2.0269e-06],\n",
      "         [ 7.3725e-06,  1.7539e-05,  1.5764e-05, -9.0794e-07,  1.0111e-05],\n",
      "         [ 4.7538e-06,  1.2780e-05, -2.5340e-06,  1.0927e-05, -1.8285e-05],\n",
      "         [-7.7299e-06, -5.0085e-06,  5.2145e-06,  1.0007e-05,  1.0856e-06],\n",
      "         [ 2.3271e-05,  3.9087e-05,  9.5206e-06,  3.7490e-05, -4.7638e-05],\n",
      "         [ 5.9728e-06,  3.9693e-05,  2.0623e-05,  1.5534e-06, -3.4302e-06],\n",
      "         [ 6.5993e-06, -7.5720e-07, -1.9026e-05, -3.0580e-06, -6.4812e-05],\n",
      "         [-3.2932e-06,  1.6312e-05, -5.4632e-06, -1.4039e-05, -2.4150e-05],\n",
      "         [-8.4028e-06,  3.8741e-06,  5.6299e-07, -8.8992e-06,  5.9203e-06],\n",
      "         [-7.1649e-06, -5.8308e-06,  8.6448e-06, -1.2562e-05,  2.2966e-05]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 2.1952e-03, -2.2889e-03,  3.8057e-03,  5.8256e-05, -4.5365e-03,\n",
      "          -1.5063e-03,  2.5015e-03,  1.9255e-03],\n",
      "         [ 2.8545e-04, -3.3685e-05, -1.3611e-04, -3.4831e-05, -4.3562e-04,\n",
      "          -4.0867e-04,  3.3420e-04, -7.6087e-04],\n",
      "         [-2.6688e-04,  1.8594e-04, -1.4710e-04, -2.4395e-04,  6.4024e-04,\n",
      "           3.5496e-04, -5.6990e-04,  8.4313e-04],\n",
      "         [-7.2026e-03,  4.9180e-03,  2.7979e-03,  4.6659e-03,  6.4111e-03,\n",
      "           1.3186e-02, -1.3843e-02,  6.3364e-03],\n",
      "         [ 4.7450e-05, -9.9123e-04,  1.7606e-03,  1.0013e-03, -1.7604e-03,\n",
      "           1.8536e-03, -1.3488e-03,  2.9641e-04],\n",
      "         [ 8.5704e-04,  1.8461e-03, -5.3675e-05, -7.1377e-04, -5.2805e-04,\n",
      "          -1.9856e-03,  3.3572e-03, -4.1086e-03],\n",
      "         [ 8.4167e-04,  9.4750e-04,  4.8508e-04,  9.2901e-04, -1.4106e-03,\n",
      "          -6.6229e-05,  8.8119e-05, -7.2879e-04],\n",
      "         [-8.0064e-03,  6.4596e-03,  9.7765e-04, -9.0175e-04,  6.7004e-03,\n",
      "           4.5003e-03,  4.5472e-03, -3.1279e-03]],\n",
      "\n",
      "        [[ 6.8836e-03, -4.1755e-03,  8.1054e-03, -2.0074e-03, -2.7289e-03,\n",
      "           3.3458e-03,  1.1185e-02, -1.1046e-03],\n",
      "         [-2.9518e-04, -3.9726e-04,  3.9044e-04,  1.6690e-03,  1.1547e-04,\n",
      "          -9.7647e-04, -2.3981e-04,  3.9566e-04],\n",
      "         [-7.6995e-04,  6.4688e-05, -5.9497e-04,  5.5882e-04,  4.3654e-04,\n",
      "          -4.8188e-04, -5.2551e-04, -8.5102e-05],\n",
      "         [-1.3586e-02, -4.5445e-03, -4.5744e-03,  2.8665e-03,  5.0749e-03,\n",
      "          -1.1148e-02, -1.7973e-02,  1.5858e-03],\n",
      "         [-1.7056e-03, -2.0725e-03, -7.5122e-04, -1.5628e-03,  1.3845e-03,\n",
      "           3.8218e-04, -2.6216e-03,  8.5675e-04],\n",
      "         [-2.8200e-03, -7.9094e-04, -2.2289e-03, -2.2527e-03,  3.5888e-04,\n",
      "          -5.1465e-04,  2.5690e-04, -6.3610e-04],\n",
      "         [ 3.3643e-03, -2.1764e-03,  3.2888e-03,  4.4659e-05, -9.5080e-04,\n",
      "           5.9879e-04,  2.6246e-03,  1.2190e-03],\n",
      "         [-9.4860e-03,  4.1944e-03, -7.5942e-03,  2.3802e-03,  1.9136e-03,\n",
      "          -2.3653e-03, -6.8083e-03,  5.1232e-05]],\n",
      "\n",
      "        [[-4.1982e-03,  1.0680e-02, -9.9937e-03,  1.6771e-02,  1.6725e-03,\n",
      "           1.7000e-02,  1.3050e-02, -2.2139e-02],\n",
      "         [ 1.1359e-03,  3.1919e-04,  7.6699e-04, -2.3672e-03,  2.2053e-03,\n",
      "           1.5929e-03, -2.0190e-04, -2.4335e-04],\n",
      "         [ 1.3167e-03, -1.2219e-04,  5.4202e-04, -1.5618e-03,  2.0200e-03,\n",
      "           1.5754e-03, -9.9018e-06, -7.4531e-04],\n",
      "         [ 5.3411e-03, -3.3860e-03,  4.2970e-03, -8.9058e-03,  5.5838e-03,\n",
      "           2.7070e-03, -2.1184e-03,  6.2857e-03],\n",
      "         [ 4.1829e-04, -2.5056e-03,  1.5835e-03, -1.9165e-04, -8.7586e-04,\n",
      "          -1.9663e-03, -2.4294e-03,  4.4394e-03],\n",
      "         [ 1.3866e-03, -2.0942e-03,  6.8358e-04, -1.6225e-03, -2.2405e-03,\n",
      "          -5.4569e-03, -3.9169e-03,  3.8092e-03],\n",
      "         [ 5.5330e-04, -1.2045e-03, -1.1181e-05, -8.3006e-04, -1.2313e-03,\n",
      "          -2.5023e-03, -1.7250e-03,  1.6476e-03],\n",
      "         [-1.3813e-04, -1.2891e-03,  2.5729e-03, -5.0690e-03,  5.4889e-04,\n",
      "          -1.8714e-03, -1.7949e-03,  3.9000e-03]]], device='cuda:0'), tensor([[[ 2.0157e-03,  3.5742e-03,  5.1246e-03,  5.2775e-03,  2.0181e-05,\n",
      "          -1.5673e-02, -8.1027e-03,  7.6658e-04],\n",
      "         [ 1.4685e-03, -4.3760e-04,  1.6369e-03, -3.2474e-04, -2.6286e-05,\n",
      "           7.0841e-04, -6.3514e-04, -2.1958e-03],\n",
      "         [-7.7907e-04, -6.2195e-04, -3.1376e-03, -4.9371e-04,  1.0468e-04,\n",
      "           2.2397e-03, -7.4600e-04,  3.7371e-03],\n",
      "         [-1.7548e-02, -1.4097e-02, -2.0161e-02, -4.3972e-03, -4.8673e-03,\n",
      "           8.0240e-02, -1.2447e-02,  6.4153e-03],\n",
      "         [ 1.1465e-03,  3.1524e-04, -1.6514e-03,  3.1733e-03, -1.4492e-03,\n",
      "           2.2359e-03, -6.9782e-04, -2.2305e-03],\n",
      "         [ 4.5048e-04, -1.1572e-04,  7.7917e-03, -6.3714e-04, -5.4611e-05,\n",
      "          -1.2285e-03,  8.6287e-04, -6.0034e-03],\n",
      "         [ 3.5224e-03, -2.7026e-04,  2.5695e-03,  3.6831e-03, -1.2479e-04,\n",
      "           3.5479e-04, -4.2024e-03, -4.5668e-03],\n",
      "         [-6.6846e-03, -1.8650e-03,  1.3919e-02, -8.4183e-03,  3.5054e-03,\n",
      "           2.1287e-02,  4.1799e-03, -2.6311e-02]],\n",
      "\n",
      "        [[ 1.0300e-02, -2.2558e-02, -1.1139e-03,  6.8029e-03,  9.7019e-04,\n",
      "           1.3681e-03,  5.6626e-03, -2.1230e-03],\n",
      "         [-6.0770e-04,  2.5775e-04, -8.3510e-06, -7.2656e-04,  4.5634e-04,\n",
      "           1.5260e-04, -1.7656e-04,  7.1429e-04],\n",
      "         [-5.0990e-04,  6.9255e-04, -9.0267e-05, -3.9823e-04,  3.0550e-05,\n",
      "           3.2621e-05, -4.1527e-06,  2.3441e-04],\n",
      "         [-1.1042e-02,  1.2987e-02,  2.3728e-04, -1.2485e-02, -5.5593e-03,\n",
      "           8.0299e-03, -2.6818e-04,  4.9006e-03],\n",
      "         [-2.0865e-03, -1.4520e-04,  9.2070e-04, -1.4046e-04, -3.5275e-03,\n",
      "           3.2470e-03,  3.8365e-04,  1.0024e-03],\n",
      "         [-2.8712e-03,  2.6472e-04,  9.9087e-04,  8.5907e-04, -8.5756e-04,\n",
      "          -9.1239e-04,  3.4293e-03,  9.2513e-04],\n",
      "         [-3.2036e-04, -4.0992e-03,  5.9600e-04,  1.4470e-03, -1.6599e-04,\n",
      "           6.8834e-04,  7.5026e-04,  9.4788e-04],\n",
      "         [-1.0182e-03,  7.2428e-03, -3.4888e-04, -1.0370e-03, -1.6981e-03,\n",
      "          -3.3019e-03, -9.8175e-04,  1.6486e-03]],\n",
      "\n",
      "        [[-1.3385e-03,  2.3338e-03, -3.7855e-03, -6.8118e-04, -4.0586e-05,\n",
      "           1.0815e-03,  8.4294e-04, -4.9861e-04],\n",
      "         [-2.8156e-03,  2.8408e-04,  1.6536e-03, -1.4149e-05, -1.8337e-04,\n",
      "          -4.8993e-04,  4.7150e-04,  3.1072e-04],\n",
      "         [-3.0061e-03,  6.0519e-04,  1.5039e-03,  2.7111e-04, -1.3618e-04,\n",
      "           2.8249e-05, -3.4557e-04, -1.8787e-04],\n",
      "         [-4.2812e-03, -8.5323e-04,  3.1183e-03,  3.2455e-03, -2.4577e-03,\n",
      "          -1.9234e-03,  2.0367e-04,  1.3343e-04],\n",
      "         [ 1.0651e-03, -2.3513e-03, -1.0050e-04,  2.8375e-03, -5.0425e-04,\n",
      "          -8.5034e-04, -3.7001e-04,  5.5439e-04],\n",
      "         [ 4.8334e-04, -3.5995e-03,  9.6879e-04,  2.2481e-04,  5.8054e-04,\n",
      "           9.5169e-04, -8.7941e-04,  8.4511e-04],\n",
      "         [ 8.8684e-04, -3.1240e-03,  2.7041e-03, -2.9540e-04,  1.4521e-04,\n",
      "           2.4236e-04, -4.3443e-04,  1.4447e-04],\n",
      "         [-3.6830e-04, -4.2225e-03,  6.3036e-03, -1.2268e-04, -1.3342e-04,\n",
      "          -1.2462e-03,  2.8181e-04,  1.5561e-06]]], device='cuda:0'))\n",
      "tensor([-1.7625e-03,  5.5826e-04,  5.4326e-03,  1.3602e-04, -3.3164e-04,\n",
      "        -1.6660e-03, -4.3980e-05, -1.6902e-03, -2.6029e-03,  4.1292e-03,\n",
      "         5.0831e-03, -3.5170e-03, -1.5854e-03, -1.6174e-03,  3.0620e-04,\n",
      "        -1.2531e-03, -1.4330e-02, -3.6512e-03, -4.0918e-03, -2.1584e-03,\n",
      "         6.6672e-04,  7.7369e-02, -1.7840e-02, -2.2400e-02, -2.4683e-03,\n",
      "         1.3155e-03,  3.0738e-03, -1.7665e-03,  1.2936e-03, -3.4525e-04,\n",
      "        -9.2460e-04, -1.0026e-04], device='cuda:0')\n",
      "tensor([-0.0162,  0.0099,  0.0270, -0.0138,  0.0018, -0.0085, -0.0032, -0.0068],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"model_cpp\")\n",
    "print(inputs_grads[1])\n",
    "print(hidden_grads[1])\n",
    "print(model_cpp.lstm0.bias.grad)\n",
    "print(model_cpp.lstm0.gamma_cell.grad)\n",
    "# print(model_cpp.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cpp.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:35.262393Z",
     "start_time": "2019-02-06T20:06:35.254394Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3039e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cpp.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:36.095765Z",
     "start_time": "2019-02-06T20:06:35.890745Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cuda\n",
      "tensor([[[-2.3392e-03, -2.0866e-03,  4.1625e-03,  1.3977e-03, -6.6969e-04],\n",
      "         [ 3.0949e-06, -6.4528e-05, -4.0021e-05, -2.5677e-05, -4.5529e-05],\n",
      "         [-9.9979e-06, -4.5025e-05, -3.8840e-05, -9.1775e-06, -3.5822e-05],\n",
      "         [-1.3572e-05,  3.8747e-06, -3.8844e-05,  2.1861e-05, -4.7407e-05],\n",
      "         [-8.0598e-06, -1.4133e-05, -2.3156e-05,  1.3458e-05, -2.8517e-05],\n",
      "         [-1.5293e-05, -1.5984e-05, -4.8014e-05,  2.4379e-05, -3.9248e-05],\n",
      "         [ 6.6737e-06,  1.6129e-05, -6.1013e-05,  2.5314e-05, -2.6347e-05],\n",
      "         [ 6.0097e-06, -8.5343e-06, -1.9613e-05, -3.6052e-06, -2.2111e-05],\n",
      "         [ 6.9569e-06, -1.2979e-05, -3.1409e-05,  8.0042e-06, -2.7936e-05],\n",
      "         [ 2.1220e-05,  2.2263e-05, -7.3463e-06, -6.5337e-06, -3.5929e-05],\n",
      "         [ 1.8278e-05,  2.1283e-05, -1.6896e-05,  7.5421e-06, -1.5575e-05],\n",
      "         [ 3.8402e-05,  4.7894e-05,  1.6105e-05,  2.6976e-05,  2.1125e-05],\n",
      "         [ 9.9178e-06,  8.8279e-06, -1.7362e-05, -1.7223e-06, -7.8249e-06],\n",
      "         [ 8.0479e-06, -5.5114e-06, -1.1771e-05, -2.4512e-05, -5.5032e-06],\n",
      "         [ 1.6801e-05,  5.5495e-06, -2.1773e-05,  1.4832e-05, -8.5240e-06],\n",
      "         [ 1.5035e-05,  1.4424e-05, -2.3664e-05,  2.7109e-06, -9.2482e-06],\n",
      "         [-6.3830e-06, -7.7751e-07, -1.1653e-05,  9.8675e-07, -1.1835e-05],\n",
      "         [-2.5869e-06, -2.8699e-06, -4.1706e-06, -2.0002e-06, -2.4590e-06],\n",
      "         [ 1.0125e-05, -2.0693e-06, -8.9935e-06, -4.9151e-06,  5.6822e-07],\n",
      "         [ 4.1514e-07,  1.1545e-07, -1.7567e-06, -1.2400e-06, -1.4115e-06]],\n",
      "\n",
      "        [[ 3.6216e-04, -1.2591e-04, -3.4214e-05,  3.2623e-05, -2.6589e-04],\n",
      "         [ 5.3558e-05, -2.6146e-05,  7.1672e-05, -4.2250e-05,  3.8352e-05],\n",
      "         [ 4.0959e-06, -5.6118e-06,  2.1940e-05, -1.3798e-05,  1.3270e-05],\n",
      "         [ 9.3758e-06,  1.0194e-06,  3.3508e-05, -1.6173e-05,  1.1854e-05],\n",
      "         [ 4.3960e-06,  2.6241e-06,  2.2245e-05, -7.3918e-06,  1.9261e-06],\n",
      "         [ 3.5406e-05,  4.2495e-06,  1.2088e-05, -2.6229e-05,  8.7411e-06],\n",
      "         [ 2.7299e-05,  6.3413e-05,  1.5287e-04,  4.2795e-05,  5.3973e-05],\n",
      "         [ 3.5799e-05,  9.4383e-05,  1.8922e-04,  7.1046e-05,  7.6462e-05],\n",
      "         [ 1.6741e-05,  4.4129e-06,  1.8721e-05,  5.6250e-06, -1.7219e-06],\n",
      "         [ 5.3466e-06, -1.7291e-05, -1.0320e-05,  2.5344e-06,  1.2081e-06],\n",
      "         [-2.7839e-06, -3.4676e-06,  1.7255e-05,  3.7039e-06,  1.5067e-05],\n",
      "         [ 2.5432e-05,  3.5282e-05,  3.0678e-05,  3.3708e-05,  1.0224e-05],\n",
      "         [ 2.0974e-06,  8.1347e-07,  4.2058e-06,  1.9381e-06, -1.3289e-07],\n",
      "         [-1.8332e-05, -1.7638e-05, -6.2191e-06, -1.1145e-05, -1.4741e-05],\n",
      "         [-1.1790e-05,  4.1791e-07,  8.5721e-06, -2.3138e-06,  5.0313e-06],\n",
      "         [-1.4579e-05, -9.3607e-06, -3.8186e-05, -3.3165e-05, -2.7052e-05],\n",
      "         [-7.4170e-06,  1.3721e-05,  7.8955e-06, -1.7461e-05, -5.3853e-06],\n",
      "         [-1.1033e-05,  1.6862e-05,  3.8620e-05,  1.2925e-05,  6.4215e-06],\n",
      "         [-8.0691e-06, -2.5828e-06,  2.2202e-05,  1.7181e-05,  2.8537e-08],\n",
      "         [ 6.8577e-06,  1.1428e-05,  1.7558e-05,  1.7058e-05, -1.4939e-06]],\n",
      "\n",
      "        [[-1.3986e-04,  1.0489e-04, -6.3481e-04,  2.0674e-04, -2.5618e-04],\n",
      "         [-2.4054e-04, -1.5231e-04, -4.5791e-04,  8.5643e-05, -1.6192e-04],\n",
      "         [-3.1214e-05, -3.7849e-05, -1.6644e-04,  9.8265e-05, -1.2356e-04],\n",
      "         [-3.8048e-05, -1.4877e-05, -4.4710e-05,  1.8178e-05,  7.7640e-08],\n",
      "         [-4.0256e-05, -1.3709e-05, -7.2727e-05,  1.3682e-05, -9.0629e-06],\n",
      "         [-7.7089e-05,  6.0412e-06, -6.1820e-05,  9.2688e-05,  1.8379e-06],\n",
      "         [-6.4067e-05,  1.9810e-05, -1.4713e-05,  7.4725e-05,  2.9619e-05],\n",
      "         [-1.0907e-05,  2.2324e-04,  1.6261e-04,  7.6922e-05,  8.8309e-05],\n",
      "         [-1.1706e-05,  8.6947e-05,  3.1238e-05,  3.7810e-05,  2.2329e-05],\n",
      "         [ 5.2517e-06,  3.6641e-05, -1.1491e-05, -5.4288e-06,  2.8928e-05],\n",
      "         [-9.2090e-06,  7.0891e-06, -6.3724e-05, -3.9634e-05,  8.1281e-06],\n",
      "         [-1.7957e-05,  2.4004e-06, -3.2209e-05,  1.7014e-05,  2.7710e-05],\n",
      "         [-2.3463e-05, -2.8554e-05, -2.5340e-05,  8.1619e-06,  3.8452e-06],\n",
      "         [-2.0497e-05, -4.6591e-05, -8.8161e-05, -1.2669e-04,  5.4401e-05],\n",
      "         [-2.1529e-05, -2.2201e-05, -3.4177e-05, -7.5269e-06, -1.3445e-05],\n",
      "         [-1.4675e-06, -4.3309e-06, -1.1557e-05, -8.1615e-06,  9.7464e-07],\n",
      "         [-4.0484e-05, -3.7593e-05, -2.9815e-05, -5.2905e-06, -2.4913e-05],\n",
      "         [-3.8972e-06, -2.7422e-07,  1.5900e-05, -4.1798e-06,  5.2075e-06],\n",
      "         [-1.8876e-05, -1.9611e-05, -1.4143e-05, -1.6948e-05,  5.0980e-06],\n",
      "         [-1.8768e-06, -3.2790e-06,  3.0120e-06, -1.9838e-06, -1.5040e-06]],\n",
      "\n",
      "        [[-4.8989e-03,  3.5759e-03, -1.4842e-02,  6.1139e-03,  3.8044e-03],\n",
      "         [-1.1043e-03,  7.1084e-04, -1.8848e-03,  6.8747e-04,  1.0699e-03],\n",
      "         [-9.7304e-05,  1.4480e-03, -2.1596e-05,  9.4822e-04,  1.1046e-03],\n",
      "         [-4.2773e-04,  4.1099e-04,  8.9274e-06,  2.1473e-04,  5.4395e-04],\n",
      "         [-2.4195e-04,  2.1430e-04, -1.7770e-04,  2.8797e-05,  4.5429e-04],\n",
      "         [-2.4941e-04,  1.6909e-04, -4.1626e-05, -8.7938e-05,  2.7272e-04],\n",
      "         [ 9.9960e-06, -2.5046e-04,  1.0838e-04,  6.8391e-05,  2.9225e-04],\n",
      "         [-2.6172e-05,  3.0849e-05, -4.2399e-05, -4.6653e-05,  2.4748e-05],\n",
      "         [-5.0370e-05,  8.2600e-05, -3.1855e-05,  6.9946e-06,  1.7548e-04],\n",
      "         [-4.9701e-05,  8.8543e-05,  4.6281e-05,  1.3972e-05,  1.1183e-04],\n",
      "         [ 1.3546e-06,  1.0951e-05,  3.2145e-06,  3.0518e-06,  1.4258e-05],\n",
      "         [-3.6904e-06,  9.7658e-06,  9.1601e-06, -2.4295e-06,  1.7683e-05],\n",
      "         [-4.7197e-06,  9.2184e-08,  3.1074e-06,  7.7090e-08,  5.5671e-06],\n",
      "         [-6.5666e-06, -3.5770e-06, -3.4005e-07,  1.2965e-06,  2.2748e-06],\n",
      "         [-2.5067e-06, -1.5937e-06, -3.3098e-07, -2.9814e-06,  7.3814e-06],\n",
      "         [-3.3521e-06,  6.6325e-07, -3.8113e-06, -4.3389e-07,  2.8331e-06],\n",
      "         [-3.8304e-06, -6.2305e-06, -8.4967e-06, -2.5880e-06, -2.8057e-06],\n",
      "         [ 1.0157e-06,  3.6923e-06, -5.5699e-06,  1.1758e-05,  5.3654e-06],\n",
      "         [-1.3124e-06,  4.1080e-06, -5.7101e-06, -8.7320e-06,  4.3932e-06],\n",
      "         [ 4.5815e-07,  5.4128e-05,  3.8272e-05,  3.6091e-05,  3.3785e-05]],\n",
      "\n",
      "        [[-1.0909e-03, -1.1770e-04, -1.2192e-05,  1.5114e-03,  6.1361e-04],\n",
      "         [-2.3157e-06, -6.0909e-05,  3.4320e-05,  2.0369e-06,  4.6892e-05],\n",
      "         [ 3.3434e-05, -1.5014e-05, -1.2762e-06, -4.2008e-05,  2.9625e-05],\n",
      "         [-2.9458e-05, -4.4941e-05, -1.9811e-05, -1.9424e-05,  6.4890e-06],\n",
      "         [ 1.2063e-05,  3.1445e-06, -3.2574e-06, -5.0148e-06,  4.5517e-05],\n",
      "         [ 2.1574e-06,  9.0901e-07, -4.5342e-06, -3.0191e-06,  3.7194e-07],\n",
      "         [-3.5543e-06, -7.6547e-06, -2.5758e-06, -3.2527e-06, -2.3267e-06],\n",
      "         [ 1.0683e-06, -2.0756e-06, -3.0479e-06, -3.2232e-06, -5.6648e-06],\n",
      "         [ 3.2784e-06,  7.5547e-06,  6.5765e-06,  7.2749e-07, -4.5418e-06],\n",
      "         [ 1.5368e-06,  9.3497e-06,  1.2285e-05,  3.2290e-06,  5.2991e-07],\n",
      "         [-9.1650e-06, -6.6626e-06,  1.0945e-06, -8.1322e-08,  7.5177e-06],\n",
      "         [-7.6846e-06,  3.5366e-06,  9.3077e-06,  3.3061e-06,  1.1074e-05],\n",
      "         [ 5.2200e-07,  7.8452e-06,  1.1682e-05,  1.2233e-05,  7.1646e-07],\n",
      "         [ 4.8922e-06,  4.4966e-06,  4.0638e-06,  3.8427e-06, -2.7563e-06],\n",
      "         [-3.0755e-06,  2.4432e-07,  1.0725e-05,  1.0645e-05,  6.8447e-07],\n",
      "         [ 3.9858e-06,  3.7553e-06,  1.4612e-06, -2.9747e-06, -4.3853e-06],\n",
      "         [ 3.8368e-06, -5.6164e-06, -3.9865e-06,  1.3373e-06, -1.2035e-05],\n",
      "         [ 1.2255e-05, -1.6186e-06, -3.8098e-06,  6.9830e-06, -1.7497e-05],\n",
      "         [ 7.7816e-06,  1.0121e-05,  1.4970e-05,  2.2774e-06, -1.4197e-05],\n",
      "         [ 2.0431e-05,  7.5248e-06, -2.2923e-06, -1.1440e-06, -2.0725e-05]],\n",
      "\n",
      "        [[ 2.1580e-03,  3.3882e-04,  2.7328e-03, -2.1830e-03,  9.1509e-04],\n",
      "         [ 6.4927e-05,  3.5772e-05,  3.8641e-05, -3.1953e-05, -9.2844e-06],\n",
      "         [ 4.1491e-05,  3.6843e-05,  2.7166e-05,  1.4072e-05, -1.8847e-05],\n",
      "         [-6.0244e-07,  9.4851e-07, -3.1664e-06,  1.1954e-05, -7.0046e-06],\n",
      "         [ 2.1366e-06,  1.8412e-06, -2.7468e-06,  1.1073e-05, -3.0386e-06],\n",
      "         [-1.2762e-05, -8.4988e-06, -1.4143e-05,  2.7874e-06, -8.4388e-06],\n",
      "         [ 7.1866e-06,  8.4516e-06, -7.9100e-06,  2.5889e-05, -8.6004e-06],\n",
      "         [-8.4297e-06, -3.7164e-07,  2.7124e-06,  1.0705e-05,  3.1541e-06],\n",
      "         [-5.5506e-06, -1.8549e-06, -1.0621e-05,  1.0967e-05, -7.5108e-07],\n",
      "         [-3.5641e-07,  4.4057e-06, -1.6404e-05,  8.9829e-06, -1.4469e-06],\n",
      "         [ 2.4667e-06, -1.4252e-06,  4.0414e-06,  8.7097e-06,  6.1932e-07],\n",
      "         [ 1.2820e-06,  2.0399e-07, -1.1956e-05,  1.1537e-05, -8.1721e-06],\n",
      "         [-3.8707e-06, -3.0541e-06, -2.3454e-05,  2.7445e-05, -1.3597e-05],\n",
      "         [-1.9055e-05, -8.9976e-06, -4.3579e-05,  1.2100e-05, -1.2304e-05],\n",
      "         [ 2.1694e-06, -1.8638e-06, -1.2279e-05, -9.9774e-07,  1.1565e-06],\n",
      "         [ 7.4197e-07,  4.0427e-07, -4.9173e-06, -1.8911e-06,  3.0493e-06],\n",
      "         [-8.4067e-07, -4.1939e-06, -2.5607e-06, -5.6330e-06,  8.9782e-07],\n",
      "         [ 6.7802e-06, -1.7580e-06,  2.7575e-06, -2.2557e-06, -3.6979e-06],\n",
      "         [ 4.4102e-06,  3.5989e-06,  5.1790e-06,  9.1207e-07,  7.3158e-07],\n",
      "         [-9.8189e-06,  2.4933e-06,  9.2846e-06,  3.2429e-07, -4.9588e-06]],\n",
      "\n",
      "        [[-5.8759e-05,  1.2518e-04,  2.2512e-04,  5.4664e-04,  2.1063e-04],\n",
      "         [ 2.7433e-04, -1.5887e-04, -3.2483e-04,  1.6861e-04,  4.6789e-05],\n",
      "         [ 5.6248e-05, -3.8931e-05, -1.4647e-04, -3.3157e-05,  7.0254e-06],\n",
      "         [ 3.3191e-05,  2.7219e-05,  3.0401e-05, -2.1140e-05,  3.8406e-05],\n",
      "         [ 4.7841e-05,  2.1320e-05,  6.2599e-05, -1.0317e-05,  5.7435e-05],\n",
      "         [ 1.3014e-06, -1.0706e-05,  1.3470e-05,  1.6219e-06, -5.3743e-07],\n",
      "         [ 7.5487e-06,  3.9666e-06,  3.7263e-05, -1.1394e-06,  4.0256e-05],\n",
      "         [ 1.7607e-05, -2.2801e-05, -7.2448e-06,  7.3025e-07, -7.4557e-06],\n",
      "         [ 7.2821e-06,  5.5362e-06,  1.6301e-05, -3.3705e-06,  1.0364e-05],\n",
      "         [ 9.3880e-07, -4.5752e-06, -1.6540e-06, -4.7865e-06,  1.7263e-06],\n",
      "         [-6.7837e-07, -5.1025e-06,  2.9915e-06,  8.9992e-07,  2.3710e-06],\n",
      "         [-8.8157e-06, -4.8581e-06,  1.9250e-06, -4.2548e-07, -2.4894e-06],\n",
      "         [-1.3607e-05, -8.6569e-06, -5.1378e-06, -9.0923e-06, -1.2241e-05],\n",
      "         [-9.7844e-06, -2.8008e-06, -2.4604e-06,  3.0500e-06, -1.2505e-05],\n",
      "         [-2.1935e-06,  6.6723e-06,  4.5976e-07, -1.0282e-06, -1.6027e-06],\n",
      "         [-1.3079e-06,  1.3839e-06, -7.3315e-07, -1.0236e-06, -1.0538e-06],\n",
      "         [-4.3656e-06,  7.0711e-06,  5.8670e-06, -2.5333e-06, -2.1697e-06],\n",
      "         [ 3.6814e-07,  3.2889e-06, -5.2814e-06, -2.0576e-06, -8.7625e-06],\n",
      "         [-2.8131e-06, -1.3260e-06, -8.7927e-07, -8.2262e-06, -2.1963e-06],\n",
      "         [ 2.5419e-06,  4.4148e-06, -2.2508e-06, -1.8272e-06, -1.9946e-06]],\n",
      "\n",
      "        [[-8.6275e-04,  3.6917e-03, -2.9201e-03,  7.0943e-04,  1.7246e-03],\n",
      "         [ 4.1090e-05, -3.3601e-05,  1.9920e-04,  1.3025e-04,  2.5129e-05],\n",
      "         [-1.2405e-04, -4.4211e-04,  1.3795e-04, -2.0731e-05,  2.6600e-04],\n",
      "         [-5.7319e-05,  1.0027e-04,  1.0273e-03, -2.4237e-04,  8.2015e-04],\n",
      "         [-1.6603e-05, -3.6971e-05,  4.1004e-05, -1.5293e-04,  9.2466e-05],\n",
      "         [-9.1492e-05,  4.7996e-05,  5.2234e-04, -3.4359e-04,  4.2537e-04],\n",
      "         [ 1.8457e-05,  4.8767e-05,  1.5712e-04, -2.7861e-05,  5.9145e-05],\n",
      "         [ 1.0706e-05,  6.0338e-05,  1.6743e-04, -3.9881e-06,  1.3163e-04],\n",
      "         [ 1.1199e-05,  4.8812e-05,  1.4934e-04, -4.6566e-05,  5.2590e-05],\n",
      "         [-3.0033e-05,  1.5633e-05,  3.6776e-05, -2.0906e-05,  1.5756e-05],\n",
      "         [ 2.0393e-06,  5.6274e-05,  3.3848e-05, -3.6244e-06,  2.0269e-06],\n",
      "         [ 7.3725e-06,  1.7539e-05,  1.5764e-05, -9.0795e-07,  1.0111e-05],\n",
      "         [ 4.7538e-06,  1.2780e-05, -2.5340e-06,  1.0927e-05, -1.8285e-05],\n",
      "         [-7.7299e-06, -5.0085e-06,  5.2145e-06,  1.0007e-05,  1.0856e-06],\n",
      "         [ 2.3271e-05,  3.9087e-05,  9.5206e-06,  3.7490e-05, -4.7638e-05],\n",
      "         [ 5.9728e-06,  3.9693e-05,  2.0623e-05,  1.5533e-06, -3.4302e-06],\n",
      "         [ 6.5994e-06, -7.5720e-07, -1.9026e-05, -3.0580e-06, -6.4812e-05],\n",
      "         [-3.2932e-06,  1.6312e-05, -5.4633e-06, -1.4039e-05, -2.4151e-05],\n",
      "         [-8.4028e-06,  3.8741e-06,  5.6300e-07, -8.8992e-06,  5.9203e-06],\n",
      "         [-7.1649e-06, -5.8308e-06,  8.6448e-06, -1.2562e-05,  2.2966e-05]]],\n",
      "       device='cuda:0')\n",
      "(tensor([[[ 2.1952e-03, -2.2889e-03,  3.8057e-03,  5.8255e-05, -4.5365e-03,\n",
      "          -1.5063e-03,  2.5015e-03,  1.9255e-03],\n",
      "         [ 2.8545e-04, -3.3685e-05, -1.3611e-04, -3.4830e-05, -4.3562e-04,\n",
      "          -4.0867e-04,  3.3420e-04, -7.6087e-04],\n",
      "         [-2.6688e-04,  1.8594e-04, -1.4710e-04, -2.4395e-04,  6.4024e-04,\n",
      "           3.5496e-04, -5.6990e-04,  8.4313e-04],\n",
      "         [-7.2026e-03,  4.9180e-03,  2.7979e-03,  4.6658e-03,  6.4111e-03,\n",
      "           1.3186e-02, -1.3843e-02,  6.3364e-03],\n",
      "         [ 4.7450e-05, -9.9123e-04,  1.7606e-03,  1.0013e-03, -1.7604e-03,\n",
      "           1.8536e-03, -1.3488e-03,  2.9641e-04],\n",
      "         [ 8.5704e-04,  1.8461e-03, -5.3675e-05, -7.1377e-04, -5.2805e-04,\n",
      "          -1.9856e-03,  3.3572e-03, -4.1086e-03],\n",
      "         [ 8.4166e-04,  9.4749e-04,  4.8508e-04,  9.2900e-04, -1.4106e-03,\n",
      "          -6.6228e-05,  8.8117e-05, -7.2879e-04],\n",
      "         [-8.0064e-03,  6.4596e-03,  9.7765e-04, -9.0175e-04,  6.7004e-03,\n",
      "           4.5003e-03,  4.5472e-03, -3.1279e-03]],\n",
      "\n",
      "        [[ 6.8836e-03, -4.1755e-03,  8.1054e-03, -2.0074e-03, -2.7289e-03,\n",
      "           3.3458e-03,  1.1185e-02, -1.1046e-03],\n",
      "         [-2.9518e-04, -3.9726e-04,  3.9044e-04,  1.6690e-03,  1.1547e-04,\n",
      "          -9.7647e-04, -2.3981e-04,  3.9566e-04],\n",
      "         [-7.6995e-04,  6.4688e-05, -5.9497e-04,  5.5882e-04,  4.3654e-04,\n",
      "          -4.8188e-04, -5.2551e-04, -8.5102e-05],\n",
      "         [-1.3586e-02, -4.5445e-03, -4.5744e-03,  2.8665e-03,  5.0749e-03,\n",
      "          -1.1148e-02, -1.7973e-02,  1.5858e-03],\n",
      "         [-1.7056e-03, -2.0725e-03, -7.5122e-04, -1.5628e-03,  1.3845e-03,\n",
      "           3.8218e-04, -2.6216e-03,  8.5675e-04],\n",
      "         [-2.8200e-03, -7.9094e-04, -2.2289e-03, -2.2527e-03,  3.5888e-04,\n",
      "          -5.1465e-04,  2.5690e-04, -6.3610e-04],\n",
      "         [ 3.3643e-03, -2.1764e-03,  3.2888e-03,  4.4658e-05, -9.5079e-04,\n",
      "           5.9878e-04,  2.6246e-03,  1.2190e-03],\n",
      "         [-9.4860e-03,  4.1944e-03, -7.5942e-03,  2.3802e-03,  1.9136e-03,\n",
      "          -2.3653e-03, -6.8083e-03,  5.1234e-05]],\n",
      "\n",
      "        [[-4.1982e-03,  1.0680e-02, -9.9937e-03,  1.6771e-02,  1.6725e-03,\n",
      "           1.7000e-02,  1.3050e-02, -2.2139e-02],\n",
      "         [ 1.1359e-03,  3.1919e-04,  7.6699e-04, -2.3672e-03,  2.2053e-03,\n",
      "           1.5929e-03, -2.0190e-04, -2.4335e-04],\n",
      "         [ 1.3167e-03, -1.2219e-04,  5.4202e-04, -1.5618e-03,  2.0200e-03,\n",
      "           1.5754e-03, -9.9015e-06, -7.4531e-04],\n",
      "         [ 5.3411e-03, -3.3860e-03,  4.2970e-03, -8.9058e-03,  5.5838e-03,\n",
      "           2.7070e-03, -2.1184e-03,  6.2857e-03],\n",
      "         [ 4.1829e-04, -2.5056e-03,  1.5835e-03, -1.9165e-04, -8.7586e-04,\n",
      "          -1.9663e-03, -2.4294e-03,  4.4394e-03],\n",
      "         [ 1.3866e-03, -2.0942e-03,  6.8358e-04, -1.6225e-03, -2.2405e-03,\n",
      "          -5.4569e-03, -3.9169e-03,  3.8092e-03],\n",
      "         [ 5.5330e-04, -1.2045e-03, -1.1182e-05, -8.3006e-04, -1.2313e-03,\n",
      "          -2.5023e-03, -1.7250e-03,  1.6476e-03],\n",
      "         [-1.3813e-04, -1.2891e-03,  2.5729e-03, -5.0690e-03,  5.4889e-04,\n",
      "          -1.8714e-03, -1.7949e-03,  3.9000e-03]]], device='cuda:0'), tensor([[[ 2.0157e-03,  3.5742e-03,  5.1246e-03,  5.2775e-03,  2.0183e-05,\n",
      "          -1.5673e-02, -8.1027e-03,  7.6659e-04],\n",
      "         [ 1.4685e-03, -4.3760e-04,  1.6369e-03, -3.2474e-04, -2.6286e-05,\n",
      "           7.0842e-04, -6.3514e-04, -2.1958e-03],\n",
      "         [-7.7907e-04, -6.2195e-04, -3.1376e-03, -4.9371e-04,  1.0468e-04,\n",
      "           2.2397e-03, -7.4600e-04,  3.7371e-03],\n",
      "         [-1.7548e-02, -1.4097e-02, -2.0160e-02, -4.3972e-03, -4.8673e-03,\n",
      "           8.0240e-02, -1.2447e-02,  6.4153e-03],\n",
      "         [ 1.1465e-03,  3.1524e-04, -1.6514e-03,  3.1733e-03, -1.4492e-03,\n",
      "           2.2359e-03, -6.9782e-04, -2.2305e-03],\n",
      "         [ 4.5048e-04, -1.1572e-04,  7.7917e-03, -6.3715e-04, -5.4611e-05,\n",
      "          -1.2285e-03,  8.6287e-04, -6.0034e-03],\n",
      "         [ 3.5224e-03, -2.7026e-04,  2.5695e-03,  3.6831e-03, -1.2479e-04,\n",
      "           3.5480e-04, -4.2024e-03, -4.5668e-03],\n",
      "         [-6.6846e-03, -1.8650e-03,  1.3919e-02, -8.4183e-03,  3.5054e-03,\n",
      "           2.1287e-02,  4.1799e-03, -2.6311e-02]],\n",
      "\n",
      "        [[ 1.0300e-02, -2.2558e-02, -1.1139e-03,  6.8029e-03,  9.7018e-04,\n",
      "           1.3681e-03,  5.6626e-03, -2.1230e-03],\n",
      "         [-6.0770e-04,  2.5775e-04, -8.3510e-06, -7.2656e-04,  4.5634e-04,\n",
      "           1.5260e-04, -1.7656e-04,  7.1429e-04],\n",
      "         [-5.0990e-04,  6.9255e-04, -9.0267e-05, -3.9823e-04,  3.0550e-05,\n",
      "           3.2621e-05, -4.1527e-06,  2.3441e-04],\n",
      "         [-1.1042e-02,  1.2987e-02,  2.3728e-04, -1.2485e-02, -5.5593e-03,\n",
      "           8.0299e-03, -2.6818e-04,  4.9006e-03],\n",
      "         [-2.0865e-03, -1.4520e-04,  9.2070e-04, -1.4046e-04, -3.5275e-03,\n",
      "           3.2470e-03,  3.8365e-04,  1.0024e-03],\n",
      "         [-2.8712e-03,  2.6472e-04,  9.9087e-04,  8.5907e-04, -8.5756e-04,\n",
      "          -9.1239e-04,  3.4293e-03,  9.2513e-04],\n",
      "         [-3.2036e-04, -4.0992e-03,  5.9600e-04,  1.4470e-03, -1.6599e-04,\n",
      "           6.8833e-04,  7.5026e-04,  9.4787e-04],\n",
      "         [-1.0182e-03,  7.2428e-03, -3.4888e-04, -1.0370e-03, -1.6981e-03,\n",
      "          -3.3019e-03, -9.8175e-04,  1.6486e-03]],\n",
      "\n",
      "        [[-1.3385e-03,  2.3338e-03, -3.7855e-03, -6.8118e-04, -4.0586e-05,\n",
      "           1.0815e-03,  8.4294e-04, -4.9861e-04],\n",
      "         [-2.8156e-03,  2.8408e-04,  1.6536e-03, -1.4149e-05, -1.8337e-04,\n",
      "          -4.8993e-04,  4.7150e-04,  3.1072e-04],\n",
      "         [-3.0061e-03,  6.0519e-04,  1.5039e-03,  2.7111e-04, -1.3618e-04,\n",
      "           2.8248e-05, -3.4557e-04, -1.8787e-04],\n",
      "         [-4.2812e-03, -8.5323e-04,  3.1183e-03,  3.2455e-03, -2.4577e-03,\n",
      "          -1.9234e-03,  2.0367e-04,  1.3343e-04],\n",
      "         [ 1.0651e-03, -2.3513e-03, -1.0050e-04,  2.8375e-03, -5.0425e-04,\n",
      "          -8.5034e-04, -3.7001e-04,  5.5439e-04],\n",
      "         [ 4.8334e-04, -3.5995e-03,  9.6879e-04,  2.2481e-04,  5.8054e-04,\n",
      "           9.5169e-04, -8.7941e-04,  8.4511e-04],\n",
      "         [ 8.8684e-04, -3.1240e-03,  2.7041e-03, -2.9540e-04,  1.4521e-04,\n",
      "           2.4236e-04, -4.3443e-04,  1.4447e-04],\n",
      "         [-3.6830e-04, -4.2225e-03,  6.3036e-03, -1.2268e-04, -1.3342e-04,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          -1.2462e-03,  2.8181e-04,  1.5558e-06]]], device='cuda:0'))\n",
      "tensor([-1.7625e-03,  5.5826e-04,  5.4326e-03,  1.3602e-04, -3.3164e-04,\n",
      "        -1.6660e-03, -4.3980e-05, -1.6902e-03, -2.6029e-03,  4.1292e-03,\n",
      "         5.0831e-03, -3.5170e-03, -1.5854e-03, -1.6174e-03,  3.0620e-04,\n",
      "        -1.2531e-03, -1.4330e-02, -3.6512e-03, -4.0917e-03, -2.1584e-03,\n",
      "         6.6673e-04,  7.7368e-02, -1.7839e-02, -2.2400e-02, -2.4683e-03,\n",
      "         1.3155e-03,  3.0737e-03, -1.7665e-03,  1.2936e-03, -3.4525e-04,\n",
      "        -9.2460e-04, -1.0026e-04], device='cuda:0')\n",
      "tensor([-0.0162,  0.0099,  0.0270, -0.0138,  0.0018, -0.0085, -0.0032, -0.0068],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"model_cuda\")\n",
    "print(inputs_grads[2])\n",
    "print(hidden_grads[2])\n",
    "print(model_cuda.lstm0.bias.grad)\n",
    "print(model_cuda.lstm0.gamma_cell.grad)\n",
    "# print(model_cuda.lstm0.weight_ih.grad[0 * hidden_size:1 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[1 * hidden_size:2 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[2 * hidden_size:3 * hidden_size])\n",
    "# print(model_cuda.lstm0.weight_ih.grad[3 * hidden_size:4 * hidden_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:06:36.751857Z",
     "start_time": "2019-02-06T20:06:36.742869Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0159e-06, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model_torch.lstm0.weight_ih.grad.sub(model_cuda.lstm0.weight_ih.grad).abs().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:33.879854Z",
     "start_time": "2019-02-06T21:13:32.891572Z"
    },
    "tags": [
     "#forward-time-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [],
   "source": [
    "dataset_size = 1000 #Test 1000\n",
    "sequence_length = 500 #Test 20\n",
    "batch_size = 32 #Test 32\n",
    "\n",
    "for model in models:\n",
    "    model.train()\n",
    "del model\n",
    "\n",
    "fake_loader = create_fake_loader(dataset_size, sequence_length, batch_size, drop_last=True)\n",
    "\n",
    "hidden = (torch.zeros(n_layers, batch_size, hidden_size, device=device), torch.zeros(n_layers, batch_size, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:16:20.774254Z",
     "start_time": "2019-02-06T20:15:09.078259Z"
    },
    "tags": [
     "#forward-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.58 s  203 ms per loop (mean  std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_torch(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:18:09.501253Z",
     "start_time": "2019-02-06T20:16:20.942252Z"
    },
    "scrolled": true,
    "tags": [
     "#forward-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.43 s  301 ms per loop (mean  std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cpp(inputs, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:18:37.251252Z",
     "start_time": "2019-02-06T20:18:09.503256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 s  88.6 ms per loop (mean  std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 20\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in fake_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        model_cuda(inputs, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## +Backward time comparison\n",
    "[go to top](#Peephole-LSTM-Test-&-Performance-Comparison-(Speed-&-Memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:34.042579Z",
     "start_time": "2019-02-06T21:13:34.027574Z"
    },
    "tags": [
     "#overall-time-prep",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'executed'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\"executed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:23:33.918275Z",
     "start_time": "2019-02-06T20:18:37.636254Z"
    },
    "tags": [
     "#overall-time-1",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1 s  470 ms per loop (mean  std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_torch.zero_grad()\n",
    "    criterion(model_torch(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T20:27:04.619645Z",
     "start_time": "2019-02-06T20:23:34.085271Z"
    },
    "tags": [
     "#overall-time-2",
     "=>generate-fake"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 s  414 ms per loop (mean  std. dev. of 20 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cpp.zero_grad()\n",
    "    criterion(model_cpp(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-06T21:13:53.068952Z",
     "start_time": "2019-02-06T21:13:34.675954Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-84514c9d6ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-r 20'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'for inputs, targets in fake_loader:\\n    inputs = inputs.to(device)\\n    targets = targets.to(device)\\n    model_cuda.zero_grad()\\n    criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2321\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2322\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2323\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2324\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-62>\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1129\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[1;34m(self, number)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[1;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch1.0\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%timeit -r 20\n",
    "for inputs, targets in fake_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    model_cuda.zero_grad()\n",
    "    criterion(model_cuda(inputs, hidden)[0].flatten(0, 1), targets.flatten(0, 1)).backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 807,
   "position": {
    "height": "548px",
    "left": "1116px",
    "right": "20px",
    "top": "99px",
    "width": "752px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
